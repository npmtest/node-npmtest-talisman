{"/home/travis/build/npmtest/node-npmtest-talisman/test.js":"/* istanbul instrument in package npmtest_talisman */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-talisman/lib.npmtest_talisman.js":"/* istanbul instrument in package npmtest_talisman */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_talisman = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_talisman = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-talisman/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-talisman && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_talisman */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_talisman\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_talisman.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_talisman.rollup.js'] =\n            local.assetsDict['/assets.npmtest_talisman.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_talisman.__dirname + '/lib.npmtest_talisman.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/babel-plugin.js":"module.exports = function(context) {\n  const t = context.types;\n\n  return {\n    visitor: {\n      Program: {\n        exit(path) {\n          if (path.BABEL_PLUGIN_ADD_MODULE_EXPORTS) {\n            return;\n          }\n\n          let hasExportDefault = false;\n          const namedExports = new Set();\n          path.get('body').forEach(function(p) {\n\n            if (p.isExportDefaultDeclaration()) {\n              hasExportDefault = true;\n              return;\n            }\n\n            if (p.isExportNamedDeclaration()) {\n              if (p.node.specifiers.length === 1 && p.node.specifiers[0].exported.name === 'default') {\n                hasExportDefault = true;\n              }\n              else if (p.node.declaration && t.isFunctionDeclaration(p.node.declaration)) {\n                namedExports.add(p.node.declaration.id.name);\n              }\n              else {\n                p.node.specifiers.forEach(function(specifier) {\n                  namedExports.add(specifier.exported.name);\n                });\n              }\n              return;\n            }\n\n            // NOTE: this is not ideal & kinda loops on Punkt\n            if (p.isVariableDeclaration()) {\n              p.container.forEach(function(node) {\n\n                if (\n                  t.isExportNamedDeclaration(node) &&\n                  node.declaration &&\n                  node.declaration.declarations\n                ) {\n                  namedExports.add(node.declaration.declarations[0].id.name);\n                }\n\n                if (\n                  t.isExportNamedDeclaration(node) &&\n                  node.declaration &&\n                  t.isFunctionDeclaration(node.declaration)\n                ) {\n                  namedExports.add(node.declaration.id.name)\n                }\n              });\n            }\n          });\n\n          if (hasExportDefault) {\n            path.pushContainer('body', [\n              t.expressionStatement(t.assignmentExpression(\n                '=',\n                t.memberExpression(t.identifier('module'), t.identifier('exports')),\n                t.memberExpression(t.identifier('exports'), t.stringLiteral('default'), true)\n              ))\n            ]);\n\n            if (namedExports.size) {\n              namedExports.forEach(function(name) {\n                path.pushContainer('body', [\n                  t.expressionStatement(t.assignmentExpression(\n                    '=',\n                    t.memberExpression(\n                      t.memberExpression(t.identifier('exports'), t.stringLiteral('default'), true),\n                      t.identifier(name)\n                    ),\n                    t.memberExpression(\n                      t.identifier('exports'),\n                      t.identifier(name)\n                    )\n                  ))\n                ]);\n              });\n\n              path.BABEL_PLUGIN_NEED_TO_SHIFT_MODULE = true;\n            }\n          }\n\n          path.BABEL_PLUGIN_ADD_MODULE_EXPORTS = true;\n        }\n      }\n    },\n    post(state) {\n      if (!state.path.BABEL_PLUGIN_NEED_TO_SHIFT_MODULE)\n        return;\n\n      const program = state.path.get('body')[0].node;\n      program.expression.arguments[2].properties[0].value = t.booleanLiteral(false);\n    }\n  };\n};\n","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/classification/perceptron.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _vectors = require('../helpers/vectors');\n\nvar _random = require('lodash/random');\n\nvar _random2 = _interopRequireDefault(_random);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } } /**\n                                                                                                                                                           * Talisman classification/perceptron\n                                                                                                                                                           * ===================================\n                                                                                                                                                           *\n                                                                                                                                                           * Implementation of the Perceptron linear classifier.\n                                                                                                                                                           *\n                                                                                                                                                           * [Reference]: https://en.wikipedia.org/wiki/Perceptron\n                                                                                                                                                           */\n\n\n/**\n * The Heaviside step function.\n */\nvar step = function step(x) {\n  return x < 0 ? 0 : 1;\n};\n\n/**\n * Getting a random index from the given list.\n */\nfunction randomIndex(list) {\n  return (0, _random2.default)(0, list.length - 1);\n}\n\n/**\n * The Perceptron classifier.\n *\n * @constructor\n */\n\nvar Perceptron = function () {\n  function Perceptron(options) {\n    _classCallCheck(this, Perceptron);\n\n    var _ref = options || {},\n        _ref$learningRate = _ref.learningRate,\n        learningRate = _ref$learningRate === undefined ? 1 : _ref$learningRate,\n        _ref$iterations = _ref.iterations,\n        iterations = _ref$iterations === undefined ? 5 : _ref$iterations;\n\n    if (learningRate <= 0 || learningRate > 1) throw Error('talisman/classification/perceptron: the learning rate should be comprised between 0 and 1 inclusive.');\n\n    this.options = {\n      learningRate: learningRate,\n      iterations: iterations\n    };\n  }\n\n  /**\n   * Method used to reset the internal state of the Perceptron.\n   *\n   * @return {Perceptron}           - Returns itself for chaining purposes.\n   */\n\n\n  Perceptron.prototype.reset = function reset() {\n    this.dimensions = 0;\n    this.weights = null;\n  };\n\n  /**\n   * Method used to train the Perceptron.\n   *\n   * @param  {array}       features - Training vectors.\n   * @param  {array}       labels   - Target value (0 or 1).\n   * @return {Perceptron}           - Returns itself for chaining purposes.\n   *\n   * @throws {Error} - Will throw if features and labels are not of same length.\n   */\n\n\n  Perceptron.prototype.fit = function fit(features, labels) {\n    if (features.length !== labels.length) throw Error('talisman/classification/perceptron.fit: given arrays have different lengths.');\n\n    // Resetting internal state\n    this.reset();\n\n    var dimensions = features[0].length;\n\n    var weights = new Array(dimensions);\n\n    for (var i = 0; i < dimensions; i++) {\n      weights[i] = Math.random();\n    } // Performing iterations\n    for (var _i = 0, l = this.options.iterations; _i < l; _i++) {\n      var index = randomIndex(features),\n          vector = features[index],\n          expected = +!!labels[index],\n          result = (0, _vectors.dot)(weights, vector),\n          error = expected - step(result);\n\n      // Adjusting weights\n      var adjustment = (0, _vectors.scale)(vector, this.options.learningRate * error);\n      weights = (0, _vectors.add)(weights, adjustment);\n    }\n\n    this.dimensions = dimensions;\n    this.weights = weights;\n\n    return this;\n  };\n\n  /**\n   * Method used to classify a new vector.\n   *\n   * @param  {array} vector - The vector to classify.\n   * @return {number}       - The predicted label (0 or 1).\n   *\n   * @throw {Error} - The classifier cannot predict if not yet fitted.\n   * @throw {Error} - The classifier expects a vector of correct dimension.\n   */\n\n\n  Perceptron.prototype.predict = function predict(vector) {\n\n    if (!this.weights) throw Error('talisman/classification/perceptron.probabilities: the classifier is not yet fitted');\n\n    if (vector.length !== this.dimensions) throw Error('talisman/classification/perceptron.probabilities: the given vector is not of correct dimension (' + vector.length + ' instead of ' + this.dimensions + ').');\n\n    return step((0, _vectors.dot)(vector, this.weights));\n  };\n\n  return Perceptron;\n}();\n\nexports.default = Perceptron;\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/helpers/vectors.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.vec = vec;\nexports.add = add;\nexports.scale = scale;\nexports.mean = mean;\nexports.dot = dot;\n/**\n * Talisman helpers/vectors\n * =========================\n *\n * Compilation of various helpers to deal with vectors.\n */\n\n/**\n * Function creating a vector of n dimensions and filling it with a single\n * value if required.\n *\n * @param  {number} n    - Dimensions of the vector to create.\n * @param  {mixed}  fill - Value to be used to fill the vector.\n * @return {array}       - The resulting vector.\n */\nfunction vec(n, fill) {\n  var vector = new Array(n);\n\n  if (arguments.length > 1) {\n    for (var i = 0; i < n; i++) {\n      vector[i] = fill;\n    }\n  }\n\n  return vector;\n}\n\n/**\n * Function adding two vectors.\n *\n * @param  {array} a - The first vector.\n * @param  {array} b - The second vector.\n * @return {array}   - The resulting vector.\n */\nfunction add(a, b) {\n  var dimensions = a.length,\n      vector = vec(dimensions);\n\n  for (var i = 0; i < dimensions; i++) {\n    vector[i] = a[i] + b[i];\n  }return vector;\n}\n\n/**\n * Function multiplying a vector & a scalar.\n *\n * @param  {array} v - The first vector.\n * @param  {array} s - The scalar.\n * @return {array}   - The resulting vector.\n */\nfunction scale(v, s) {\n  var dimensions = v.length,\n      vector = vec(dimensions);\n\n  for (var i = 0; i < dimensions; i++) {\n    vector[i] = v[i] * s;\n  }return vector;\n}\n\n/**\n * Function returning the mean of a list of vectors.\n *\n * @param  {array} vectors - The list of vectors to process.\n * @return {array}         - A mean vector.\n */\nfunction mean(vectors) {\n  var sum = vec(vectors[0].length, 0);\n\n  for (var i = 0, l = vectors.length; i < l; i++) {\n    var vector = vectors[i];\n\n    for (var j = 0, m = vector.length; j < m; j++) {\n      sum[j] += vector[j];\n    }\n  }\n\n  for (var _i = 0, _l = sum.length; _i < _l; _i++) {\n    sum[_i] /= vectors.length;\n  }return sum;\n}\n\n/**\n * Function returning the scalar product of two vectors.\n *\n * @param  {array}  a - The first vector.\n * @param  {array}  b - The second vector.\n * @return {number}   - The scalar product.\n */\nfunction dot(a, b) {\n  var product = 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    product += a[i] * b[i];\n  }return product;\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/k-means.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.KMeans = undefined;\nexports.default = kMeans;\n\nvar _euclidean = require('../metrics/distance/euclidean');\n\nvar _euclidean2 = _interopRequireDefault(_euclidean);\n\nvar _vectors = require('../helpers/vectors');\n\nvar _random = require('pandemonium/random');\n\nvar _sample = require('pandemonium/sample');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } } /**\n                                                                                                                                                           * Talisman clustering/k-means\n                                                                                                                                                           * ============================\n                                                                                                                                                           *\n                                                                                                                                                           * Function related to k-means clustering.\n                                                                                                                                                           *\n                                                                                                                                                           * [Reference]: https://en.wikipedia.org/wiki/K-means_clustering\n                                                                                                                                                           */\n\n\n/**\n * Default options for k-means clustering.\n */\nvar DEFAULTS = {\n  k: 8,\n  distance: _euclidean2.default,\n  maxIterations: 300,\n  initialCentroids: null,\n  rng: Math.random,\n  vector: null\n};\n\n/**\n * Helpers.\n */\nfunction compareCentroids(a, b) {\n  for (var i = 0, l = a.length; i < l; i++) {\n    for (var j = 0, m = a[i].length; j < m; j++) {\n      if (a[i][j] !== b[i][j]) return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * KMeans class used to fine tune the clustering when needed & handling\n * the internal state of the process.\n *\n * @constructor\n * @param {array}          data                       - Array of vectors.\n * @param {object}         options                    - Possible options:\n * @param {number}            [k]                     - Number of clusters.\n * @param {function}          [distance]              - Distance function.\n * @param {number}            [maxIterations]\n *   - Maximum number of iterations.\n * @param {array|function}    [initialCentroids]\n *   - Either an array of initial centroids or a function computing them.\n * @param {function}          [rng]                   - RNG function to use.\n * @param {function}          [vector]                - Returning the vector.\n */\n\nvar KMeans = exports.KMeans = function () {\n  function KMeans(data) {\n    var _this = this;\n\n    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n    _classCallCheck(this, KMeans);\n\n    // Enforcing data validity\n    if (!Array.isArray(data)) throw Error('talisman/clustering/k-means: dataset should be an array of vectors.');\n\n    // Properties\n    this.data = data;\n    this.dimension = this.data[0].length;\n    this.iterations = 0;\n    this.centroids = null;\n    this.previousCentroids = null;\n\n    // Options\n    var rng = options.rng || DEFAULTS.rng;\n\n    if (typeof rng !== 'function') throw new Error('talisman/clustering/k-means: `rng` should be a function.');\n\n    var vectorGetter = 'vector' in options ? options.vector : null;\n\n    if (vectorGetter && typeof vectorGetter !== 'function') throw new Error('talisman/clustering/k-means: `vector` should be a function.');\n\n    if (vectorGetter) this.vectorGetter = vectorGetter;\n\n    this.k = options.k || DEFAULTS.k;\n    this.distance = options.distance || DEFAULTS.distance;\n    this.maxIterations = options.maxIterations || DEFAULTS.maxIterations;\n    this.sampler = (0, _sample.createSample)(rng).bind(null, this.k);\n    this.randomVectorIndex = (0, _random.createRandom)(rng).bind(null, 0, this.data.length);\n\n    // Enforcing correct options\n    if (typeof this.k !== 'number' || this.k <= 0) throw Error('talisman/clustering/k-means: `k` should be > 0.');\n\n    if (this.data.length < this.k) throw Error('talisman/clustering/k-means: k is greater than the number of provided vectors.');\n\n    if (typeof this.distance !== 'function') throw Error('talisman/clustering/k-means: the `distance` option should be a function.');\n\n    if (typeof this.maxIterations !== 'number' || this.maxIterations <= 0) throw Error('talisman/clustering/k-means: the `maxIterations` option should be > 0.');\n\n    this.clusters = new Uint16Array(this.data.length);\n\n    // Computing initial centroids\n    var initialCentroids = options.initialCentroids;\n\n    if (initialCentroids) {\n\n      // The user is giving the initial centroids:\n      if (typeof initialCentroids === 'function') initialCentroids = initialCentroids(this.data, {\n        k: this.k,\n        distance: this.distance,\n        maxIterations: this.maxIterations\n      });\n    } else {\n\n      // Else, we're gonna choose the initial centroids randomly\n      initialCentroids = this.sampler(this.data);\n    }\n\n    // Ensuring the starting centroids are correct\n    if (!Array.isArray(initialCentroids)) throw Error('talisman/clustering/k-means: `initialCentroids` are not an array or the function you provided to compute them returned invalid data (could be your `sampler`).');\n\n    if (initialCentroids.length !== this.k) throw Error('talisman/clustering/k-means: you should provide k centroids (got ' + initialCentroids.length + ' instead of ' + this.k + ').');\n\n    if (!initialCentroids.every(function (centroid) {\n      return Array.isArray(centroid) && centroid.length === _this.dimension;\n    })) throw Error('talisman/clustering/k-means: at least one of the provided or computed centroids is not of the correct dimension.');\n\n    this.centroids = initialCentroids;\n  }\n\n  /**\n   * Method used to perform one iteration of the clustering algorithm.\n   *\n   * @return {KMeans} - Returns itself for chaining.\n   */\n\n\n  KMeans.prototype.iterate = function iterate() {\n\n    // If the clustering has already converged, we break\n    if (this.converged) return this;\n\n    // Initializing clusters states\n    var clusterStates = new Uint8Array(this.k);\n\n    // Iterating through the dataset's vectors\n    for (var i = 0, l = this.data.length; i < l; i++) {\n      var vector = this.data[i];\n\n      // Finding the closest centroid\n      var min = Infinity,\n          centroidIndex = 0;\n\n      for (var j = 0; j < this.k; j++) {\n        var d = this.distance(vector, this.centroids[j]);\n\n        if (d < min) {\n          min = d;\n          centroidIndex = j;\n        }\n      }\n\n      // Mapping the vector to the correct centroid index\n      this.clusters[i] = centroidIndex;\n\n      // Indicating our cluster isn't empty anymore\n      clusterStates[centroidIndex] = 1;\n    }\n\n    // If any of the clusters is empty, we need to give it a random vector\n    var alreadyPluckedVectors = new Set();\n\n    for (var _i = 0; _i < this.k; _i++) {\n      if (!clusterStates[_i]) {\n\n        // Finding a random vector\n        var randomVectorIndex = void 0;\n        do {\n          randomVectorIndex = this.randomVectorIndex();\n        } while (alreadyPluckedVectors.has(randomVectorIndex));\n\n        alreadyPluckedVectors.add(randomVectorIndex);\n\n        // Let's put it in our empty cluster\n        this.clusters[randomVectorIndex] = _i;\n      }\n    }\n\n    // We now find the new centroids\n    this.previousCentroids = this.centroids;\n    this.centroids = new Array(this.k);\n\n    for (var _i2 = 0; _i2 < this.k; _i2++) {\n      this.centroids[_i2] = (0, _vectors.vec)(this.dimension, 0);\n    }var sizes = (0, _vectors.vec)(this.dimension, 0);\n\n    for (var _i3 = 0, _l = this.data.length; _i3 < _l; _i3++) {\n      var _vector = this.data[_i3],\n          clusterIndex = this.clusters[_i3];\n\n      for (var _j = 0; _j < this.dimension; _j++) {\n        this.centroids[clusterIndex][_j] += _vector[_j];\n      }sizes[clusterIndex]++;\n    }\n\n    for (var _i4 = 0; _i4 < this.k; _i4++) {\n      for (var _j2 = 0; _j2 < this.dimension; _j2++) {\n        this.centroids[_i4][_j2] /= sizes[_i4];\n      }\n    }\n\n    this.iterations++;\n\n    // Checking if the clustering has converged\n    this.converged = compareCentroids(this.previousCentroids, this.centroids);\n\n    return this;\n  };\n\n  /**\n   * Method used to start the clustering process.\n   *\n   * @return {array} - The resulting clusters.\n   */\n\n\n  KMeans.prototype.run = function run() {\n\n    // While we don't converge or haven't performed the allowed iterations:\n    while (!this.converged && this.iterations < this.maxIterations) {\n      this.iterate();\n    } // Now we need to \"compile\" the clusters\n    var clusters = new Array(this.k);\n\n    for (var i = 0; i < this.k; i++) {\n      clusters[i] = [];\n    }for (var _i5 = 0, l = this.data.length; _i5 < l; _i5++) {\n      clusters[this.clusters[_i5]].push(this.data[_i5]);\n    }return clusters;\n  };\n\n  return KMeans;\n}();\n\n/**\n * Exporting a convenient function to perform simple k-means clustering.\n *\n * @param  {object} options - Clustering options.\n * @param  {array}  data    - Target dataset.\n * @param  {array}          - Resulting clusters.\n */\n\n\nfunction kMeans(options, data) {\n  var clusterer = new KMeans(data, options);\n\n  var clusters = clusterer.run();\n\n  return clusters;\n}\nmodule.exports = exports['default'];\nexports['default'].KMeans = exports.KMeans;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/euclidean.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.squared = squared;\nexports.default = euclidean;\n/**\n * Talisman metrics/distance/euclidean\n * ====================================\n *\n * Function computing the euclidean distance.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Euclidean_distance\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Function returning the squared euclidean distance between two vectors.\n *\n * @param  {mixed}  a - The first vector.\n * @param  {mixed}  b - The second vector.\n * @return {number}   - The squared euclidean distance between a & b.\n *\n * @throws {Error} The function expects vectors of same dimension.\n */\nfunction squared(a, b) {\n  if (a.length !== b.length) throw Error('talisman/metrics/distance/euclidean: the given vectors are not of the same dimension.');\n\n  var distance = 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    distance += Math.pow(a[i] - b[i], 2);\n  }return distance;\n}\n\n/**\n * Function returning the euclidean distance between two vectors.\n *\n * @param  {mixed}  a - The first vector.\n * @param  {mixed}  b - The second vector.\n * @return {number}   - The euclidean distance between a & b.\n *\n * @throws {Error} The function expects vector of same dimensions.\n */\nfunction euclidean(a, b) {\n  return Math.sqrt(squared(a, b));\n}\nmodule.exports = exports['default'];\nexports['default'].squared = exports.squared;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/hash/crc32.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = crc32;\n/**\n * Talisman hash/crc32\n * ====================\n *\n * JavaScript implementation of the CRC32 hash for UTF-8 strings.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Cyclic_redundancy_check\n */\n\n/**\n * Constants.\n */\nvar TABLE = new Int32Array(256);\n\nfor (var c = 0, n = 0; n !== 256; n++) {\n  c = n;\n  c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;\n  c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;\n  c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;\n  c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;\n  c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;\n  c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;\n  c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;\n  c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;\n  TABLE[n] = c;\n}\n\n/**\n * Computes the CRC32 hash for the given UTF-8 string.\n *\n * @param  {string} string - The string to hash.\n * @return {number}        - The signed CRC32 hash.\n */\nfunction crc32(string) {\n  var C = -1;\n\n  for (var i = 0, l = string.length, _c, d; i < l;) {\n    _c = string.charCodeAt(i++);\n\n    if (_c < 0x80) {\n      C = C >>> 8 ^ TABLE[(C ^ _c) & 0xFF];\n    } else if (_c < 0x800) {\n      C = C >>> 8 ^ TABLE[(C ^ (192 | _c >> 6 & 31)) & 0xFF];\n      C = C >>> 8 ^ TABLE[(C ^ (128 | _c & 63)) & 0xFF];\n    } else if (_c >= 0xD800 && _c < 0xE000) {\n      _c = (_c & 1023) + 64;\n      d = string.charCodeAt(i++) & 1023;\n      C = C >>> 8 ^ TABLE[(C ^ (240 | _c >> 8 & 7)) & 0xFF];\n      C = C >>> 8 ^ TABLE[(C ^ (128 | _c >> 2 & 63)) & 0xFF];\n      C = C >>> 8 ^ TABLE[(C ^ (128 | d >> 6 & 15 | (_c & 3) << 4)) & 0xFF];\n      C = C >>> 8 ^ TABLE[(C ^ (128 | d & 63)) & 0xFF];\n    } else {\n      C = C >>> 8 ^ TABLE[(C ^ (224 | _c >> 12 & 15)) & 0xFF];\n      C = C >>> 8 ^ TABLE[(C ^ (128 | _c >> 6 & 63)) & 0xFF];\n      C = C >>> 8 ^ TABLE[(C ^ (128 | _c & 63)) & 0xFF];\n    }\n  }\n\n  return C ^ -1;\n}\nmodule.exports = exports[\"default\"];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/hash/minhash.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.default = createMinHash;\nexports.binning = binning;\n\nvar _crc = require('./crc32');\n\nvar _crc2 = _interopRequireDefault(_crc);\n\nvar _random = require('pandemonium/random');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// TODO: cleanup the type specification to be able to return an Int32Array\n// rather than what I feel seems to be buggy.\n\n// TODO: seems to be possible to use some XOR optimization to compute random\n// hashes faster beyound first one.\n\n/**\n * Constants.\n */\n/**\n * Talisman hash/minhash\n * ======================\n *\n * JavaScript implementation of the MinHash signature.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/MinHash\n *\n * [Article]:\n * Broder, Andrei Z. (1997), \"On the resemblance and containment of documents\",\n * Compression and Complexity of Sequences: Proceedings, Positano,\n * Amalfitan Coast, Salerno, Italy, June 11-13, 1997.\n */\nvar MAX_I32 = Math.pow(2, 32) - 1,\n    NEXT_PRIME = 4294967311;\n\n/**\n * Defaults.\n */\nvar DEFAULTS = {\n  hashes: 128,\n  rng: Math.random\n};\n\n/**\n * Factory creating the hashing function.\n *\n * @param  {object}   options  - Options:\n * @param  {number}     hashes - Number of hashes of the produced signature.\n * @return {function}          - The hash function.\n */\nfunction createMinHash(options) {\n  options = options || {};\n\n  var pi = options.hashes || DEFAULTS.hashes,\n      rng = options.rng || DEFAULTS.rng,\n      random = (0, _random.createRandom)(rng);\n\n  // Picking random coefficient & numbers\n  var A = new Set(),\n      B = new Set();\n\n  while (A.size < pi) {\n    A.add(random(0, MAX_I32));\n  }while (B.size < pi) {\n    B.add(random(0, MAX_I32));\n  }A = Array.from(A);\n  B = Array.from(B);\n\n  /**\n   * Function returning the MinHash signature for the given sequence. If the\n   * sequence is a string, tokens will be mapped to char codes while if the\n   * sequence is an array of arbitrary strings, the tokens will be mapped to\n   * CRC32 hashes.\n   *\n   * @param  {string|array} sequence - Target sequence.\n   * @return {array}                 - The MinHash signature.\n   */\n  return function (sequence) {\n    var tokens = {},\n        isString = typeof sequence === 'string';\n\n    // Keeping track of unique tokens\n    for (var i = 0, l = sequence.length; i < l; i++) {\n\n      // Using char code if hashing\n      if (isString) tokens[sequence.charCodeAt(i)] = true;else tokens[(0, _crc2.default)(sequence[i]) & 0xffffffff] = true;\n    }\n\n    // Creating the signature\n    var signature = new Float64Array(pi);\n\n    for (var _i = 0; _i < pi; _i++) {\n      var min = Infinity;\n\n      // Iterating over tokens & keeping track of min\n      for (var token in tokens) {\n        var hash = (A[_i] * token + B[_i]) % NEXT_PRIME;\n\n        if (hash < min) min = hash;\n      }\n\n      signature[_i] = min;\n    }\n\n    return signature;\n  };\n}\n\nfunction binning(options, items) {\n  var minhash = options.minhash,\n      rows = options.rows;\n\n  if (typeof minhash !== 'function') throw new Error('talisman/hash/minhash#binning: given minhash is not a function.');\n\n  var typicalSignature = minhash(items[0]);\n\n  if (typicalSignature.length % rows !== 0) throw new Error('talisman/hash/minhash#binning: the size of your minhash signatures should be divisible by rows.');\n\n  var bins = new Array(items.length),\n      bands = typicalSignature.length / rows,\n      identifiers = new Map();\n\n  var integer = 0;\n\n  for (var i = 0, l = items.length; i < l; i++) {\n    var item = items[i],\n        signature = minhash(item);\n\n    for (var j = 0; j < bands; j++) {\n      var key = '' + j + '§';\n\n      for (var k = j * rows, m = (j + 1) * rows; k < m; k++) {\n        key += signature[k] + (k < m - 1 ? '$' : '');\n      }if (!identifiers.has(key)) identifiers.set(key, integer++);\n\n      bins[i] = bins[i] || [];\n      bins[i].push(identifiers.get(key));\n    }\n  }\n\n  return bins;\n}\nmodule.exports = exports['default'];\nexports['default'].binning = exports.binning;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/helpers/matrices.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.mat = mat;\nexports.transpose = transpose;\n/**\n * Talisman helpers/matrices\n * ==========================\n *\n * Compilation of various helpers to deal with matrices.\n */\n\n/**\n * Function creating a matrix of m lines & n columns.\n *\n * @param  {number} m    - Number of lines.\n * @param  {number} n    - Number of columns.\n * @return {array}       - The resulting matrix.\n */\nfunction mat(m, n) {\n  var matrix = new Array(m);\n\n  for (var i = 0; i < m; i++) {\n    matrix[i] = new Array(n);\n  }return matrix;\n}\n\n/**\n * Function transposing the given matrix.\n *\n * @param  {array} target - The target matrix.\n * @return {array}        - The transposed matrix.\n */\nfunction transpose(target) {\n  var m = target.length,\n      n = target[0].length;\n\n  var transposed = new Array(n);\n\n  for (var j = 0; j < n; j++) {\n    transposed[j] = new Array(m);\n\n    for (var i = 0; i < m; i++) {\n      transposed[j][i] = target[i][j];\n    }\n  }\n\n  return transposed;\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/keyers/fingerprint.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.nameFingerprint = exports.ngramsFingerprint = undefined;\nexports.createKeyer = createKeyer;\n\nvar _fingerprint = require('../tokenizers/fingerprint');\n\nvar _name = require('../tokenizers/fingerprint/name');\n\nvar _name2 = _interopRequireDefault(_name);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Talisman keyers/fingerprint\n * ============================\n *\n * Keyer based on the fingerprint tokenizer.\n */\nfunction createKeyer(options) {\n  options = options || {};\n\n  var tokenizer = (0, _fingerprint.createTokenizer)(options);\n\n  if (options.ngrams) return function (n, string) {\n    return tokenizer(n, string).join('');\n  };\n\n  return function (string) {\n    return tokenizer(string).join(' ');\n  };\n}\n\nexports.default = createKeyer();\n\n\nvar ngramsFingerprint = createKeyer({ ngrams: true });\n\nvar nameFingerprint = function nameFingerprint(name) {\n  return (0, _name2.default)(name).join(' ');\n};\n\nexports.ngramsFingerprint = ngramsFingerprint;\nexports.nameFingerprint = nameFingerprint;\nmodule.exports = exports['default'];\nexports['default'].createKeyer = exports.createKeyer;\nexports['default'].ngramsFingerprint = exports.ngramsFingerprint;\nexports['default'].nameFingerprint = exports.nameFingerprint;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/fingerprint/index.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.ngramsFingerprint = undefined;\nexports.createTokenizer = createTokenizer;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _uniq = require('lodash/uniq');\n\nvar _uniq2 = _interopRequireDefault(_uniq);\n\nvar _ngrams = require('../ngrams');\n\nvar _ngrams2 = _interopRequireDefault(_ngrams);\n\nvar _regexp = require('../../regexp');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\n/* eslint no-control-regex: 0 */\n/**\n * Talisman tokenizers/fingerprint\n * ================================\n *\n * Fingerprint tokenizer aiming at outputing meaningful sorted tokens for the\n * given string which can later be used for similarity measures.\n */\nvar WHITESPACE = /\\s+/g,\n    DIGITS = /\\d/g,\n    PUNCTUATION_CONTROL = new RegExp('[\\\\u2000-\\\\u206F\\\\u2E00-\\\\u2E7F\\'!\"#$%&()*+,\\\\-.\\\\/:;<=>?@\\\\[\\\\]^_`{|}~\\\\x00-\\\\x08\\\\x0A-\\\\x1F\\\\x7F]', 'g');\n\n/**\n * Defaults.\n */\nvar DEFAULTS = {\n  digits: true,\n  minTokenSize: 1,\n  ngrams: false,\n  sort: true,\n  split: null,\n  stopwords: null\n};\n\n/**\n * Tokenizer function factory aiming at building the required function.\n *\n * @param  {object}   options        - Possible options:\n * @param  {boolean}    digits       - Whether to keep digits.\n * @param  {number}     minTokenSize - Minimum token size.\n * @param  {number}     ngrams       - Tokenize ngrams rather than words.\n * @param  {array}      split        - List of token-splitting characters.\n * @param  {array}      stopwords    - List of stopwords.\n * @return {function}                - The tokenizer function.\n */\nfunction createTokenizer(options) {\n  options = options || {};\n\n  var ngramsTokenize = options.ngrams || DEFAULTS.ngrams,\n      stripDigits = options.digits === false || !DEFAULTS.digits,\n      minTokenSize = options.minTokenSize || DEFAULTS.minTokenSize,\n      dontSort = options.sort === false;\n\n  var stopwords = options.stopwords || DEFAULTS.stopwords;\n\n  // Compiling stopwords\n  if (stopwords) stopwords = new RegExp('(?:' + stopwords.map(function (word) {\n    return '\\\\b' + (0, _regexp.escapeRegexp)(word) + '\\\\b';\n  }).join('|') + ')', 'gi');\n\n  var split = options.split || DEFAULTS.split;\n\n  // Compiling split\n  if (split) split = new RegExp('[' + (0, _regexp.escapeRegexp)(split.join('')) + ']', 'g');\n\n  var sizeFilter = void 0;\n  if (minTokenSize > 1) sizeFilter = new RegExp('\\\\b\\\\S{1,' + minTokenSize + '}\\\\b', 'g');\n\n  // Returning the function\n  return function (n, string) {\n\n    if (!ngramsTokenize) string = n;\n\n    //-- Splitting\n    if (split) string = string.replace(split, ' ');\n\n    //-- Stopwords\n    if (stopwords) string = string.replace(stopwords, '');\n\n    //-- Digits\n    if (stripDigits) string = string.replace(DIGITS, '');\n\n    //-- Case normalization\n    string = string.toLowerCase();\n\n    //-- Minimum token size\n    if (sizeFilter) string = string.replace(sizeFilter, '');\n\n    //-- Dropping punctuation & control characters\n    string = string.replace(PUNCTUATION_CONTROL, '');\n\n    //-- Deburring\n    string = (0, _deburr2.default)(string);\n\n    //-- Trimming\n    string = string.trim();\n\n    //-- Tokenizing\n    var tokens = void 0;\n\n    if (!ngramsTokenize) tokens = string.split(WHITESPACE);else tokens = (0, _ngrams2.default)(n, string.replace(WHITESPACE, ''));\n\n    //-- Keeping only unique tokens\n    tokens = (0, _uniq2.default)(tokens);\n\n    //-- Sorting tokens\n    if (!dontSort) tokens.sort();\n\n    return tokens;\n  };\n}\n\nexports.default = createTokenizer();\nvar ngramsFingerprint = exports.ngramsFingerprint = createTokenizer({ ngrams: true });\nmodule.exports = exports['default'];\nexports['default'].createTokenizer = exports.createTokenizer;\nexports['default'].ngramsFingerprint = exports.ngramsFingerprint;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/ngrams/index.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.default = ngrams;\n/**\n * Talisman tokenizers/ngrams\n * ===========================\n *\n * Functions related to ngrams' computation.\n *\n * [Reference]: https://en.wikipedia.org/wiki/N-gram\n */\n\n/**\n * Function taking a sequence and computing its ngrams.\n *\n * @param  {number}   n         - Nb of elements in the subsequence.\n * @param  {mixed}    sequence  - The sequence to process.\n * @return {array}              - The array of resulting ngrams.\n *\n * @throws {Error} The function expects a positive n > 0.\n */\nfunction ngrams(n, sequence) {\n  if (n < 1) throw Error('talisman/tokenizers/ngrams: first argument should be a positive integer > 0.');\n\n  var isString = typeof sequence === 'string';\n\n  var subsequences = [];\n\n  for (var i = 0, l = sequence.length; i < l - n + 1; i++) {\n    var subsequence = [];\n\n    for (var j = 0; j < n; j++) {\n      subsequence.push(sequence[i + j]);\n    }subsequences.push(isString ? subsequence.join('') : subsequence);\n  }\n\n  return subsequences;\n}\n\n/**\n * Creating popular aliases.\n */\nvar bigrams = ngrams.bind(null, 2),\n    trigrams = ngrams.bind(null, 3),\n    quadrigrams = ngrams.bind(null, 4);\n\nexports.bigrams = bigrams;\nexports.trigrams = trigrams;\nexports.quadrigrams = quadrigrams;\nmodule.exports = exports['default'];\nexports['default'].bigrams = exports.bigrams;\nexports['default'].trigrams = exports.trigrams;\nexports['default'].quadrigrams = exports.quadrigrams;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/regexp/index.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.escapeRegexp = escapeRegexp;\nexports.createFuzzyPattern = createFuzzyPattern;\n/**\n * Talisman regexp\n * ================\n *\n * Some RegExp-related helpers.\n */\n\n/**\n * Function escaping a string for insertion in a regular expression.\n *\n * @param  {string} string - The string to escape.\n * @return {string}        - The escaped string.\n */\nvar RE = /([|\\\\{}()[\\]^$+*?.\\-])/g;\n\nfunction escapeRegexp(string) {\n  return string.replace(RE, '\\\\$1');\n}\n\n/**\n * Function creating a fuzzy matching pattern from the given query.\n *\n * @param  {string} string - The string to escape.\n * @return {string}        - The created pattern.\n */\nfunction createFuzzyPattern(query) {\n  return query.split('').map(function (character) {\n    return '(' + escapeRegexp(character) + ')';\n  }).join('.*?');\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/fingerprint/name.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = nameFingerprint;\n\nvar _ = require('./');\n\nvar _helpers = require('../../helpers');\n\n/**\n * Talisman tokenizers/fingerprint/name\n * =====================================\n *\n * Variant of the fingerprint tokenizer but with opinionated options and\n * transformations known to work better with occidental names.\n */\nvar RULES = [\n\n// McCallister / MacCallister\n[/\\bmc(?=\\w)/g, 'mac'], [/\\b(ma?c\\s+)(?=\\w)/g, 'mac'],\n\n// Lee / Li\n[/\\blee\\b/g, 'li'],\n\n// Moussorgski / Moussorgsky\n[/ski\\b/g, 'sky'],\n\n// Van Hoff / Von Hoff\n[/\\bvan\\b/g, 'von'],\n\n// Doerk / Dörk\n[/ö/g, 'oe'],\n\n// Düring / Duering\n[/ü/g, 'ue']];\n\nvar OPTIONS = {\n  digits: false,\n  split: ['-'],\n  stopwords: [\n\n  // Articles\n  'the', 'le', 'la',\n\n  // Title\n  'dr', 'mgr', 'prof', 'md', 'phd', 'sir', 'lord',\n\n  // Civility\n  'mr', 'mrs', 'ms', 'mme', 'mlle', 'jr', 'junior', 'sr', 'senior']\n};\n\nvar tokenizer = (0, _.createTokenizer)(OPTIONS);\n\n/**\n * Function returning the fingerprint of the given name.\n *\n * @param  {string} name - Target name.\n * @param  {array}\n */\nfunction nameFingerprint(name) {\n  name = name.toLowerCase();\n\n  // Applying rules\n  for (var i = 0, l = RULES.length; i < l; i++) {\n    name = name.replace(RULES[i][0], RULES[i][1]);\n  }return tokenizer(name).map(_helpers.squeeze);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/helpers/index.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.findall = findall;\nexports.seq = seq;\nexports.squeeze = squeeze;\nexports.translation = translation;\n/* eslint no-cond-assign: 0 */\n/**\n * Talisman helpers\n * =================\n *\n * Miscellaneous helper functions.\n */\n\n/**\n * Function returning all the matches of a regular expression over the given\n * string.\n *\n * @param  {RegExp} pattern - The regular expression to apply.\n * @param  {string} string  - The string to match.\n * @return {array}          - An array of matches.\n */\nfunction findall(pattern, string) {\n  var matches = [];\n\n  if (!pattern.global) {\n    var result = pattern.exec(string);\n\n    if (result) matches.push(result);\n\n    return matches;\n  }\n\n  var match = void 0;\n  while (match = pattern.exec(string)) {\n    matches.push(match);\n  } // Resetting state of the Regex for safety\n  pattern.lastIndex = 0;\n\n  return matches;\n}\n\n/**\n * Function normalizing the given variable into a proper array sequence.\n *\n * @param  {mixed} target - The variable to normalize as a sequence.\n * @return {array}        - The resulting sequence.\n */\nfunction seq(target) {\n  return typeof target === 'string' ? target.split('') : target;\n}\n\n/**\n * Function squeezing the given sequence by dropping consecutive duplicates.\n *\n * Note: the name was actually chosen to mimic Ruby's naming since I did not\n * find any equivalent in other standard libraries.\n *\n * @param  {mixed} target - The sequence to squeeze.\n * @return {array}        - The resulting sequence.\n */\nfunction squeeze(target) {\n  var isString = typeof target === 'string',\n      sequence = seq(target),\n      squeezed = [sequence[0]];\n\n  for (var i = 1, l = sequence.length; i < l; i++) {\n    if (sequence[i] !== sequence[i - 1]) squeezed.push(sequence[i]);\n  }\n\n  return isString ? squeezed.join('') : squeezed;\n}\n\n/**\n * Function creating an index of mapped letters.\n *\n * @param  {string} first  - First letters.\n * @param  {string} second - Second letters.\n * @return {object}        - The resulting index.\n */\nfunction translation(first, second) {\n  var index = {};\n\n  first = first.split('');\n  second = second.split('');\n\n  if (first.length !== second.length) throw Error('talisman/helpers#translation: given strings don\\'t have the same length.');\n\n  for (var i = 0, l = first.length; i < l; i++) {\n    index[first[i]] = second[i];\n  }return index;\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/keyers/name-power-set.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; /**\n                                                                                                                                                                                                                                                                               * Talisman keyers/name-power-set\n                                                                                                                                                                                                                                                                               * ===============================\n                                                                                                                                                                                                                                                                               *\n                                                                                                                                                                                                                                                                               * Keyer returning an opinionated power set of what might be the ways to\n                                                                                                                                                                                                                                                                               * write the given name so that one can try to perform fuzzy matching on\n                                                                                                                                                                                                                                                                               * partial names such as \"P. Henry\" & \"Philip Henry\", for instance.\n                                                                                                                                                                                                                                                                               */\n\n\nexports.default = namePowerSet;\n\nvar _generatorics = require('generatorics');\n\nvar _generatorics2 = _interopRequireDefault(_generatorics);\n\nvar _uniq = require('lodash/uniq');\n\nvar _uniq2 = _interopRequireDefault(_uniq);\n\nvar _words = require('../tokenizers/words');\n\nvar _words2 = _interopRequireDefault(_words);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// TODO: option for full initials? (else if solution involves only abbrev, we skip)\n// TODO: disallow single token (on option)\n// TODO: option to skip or not\n// TODO: possibility to pass tokens rather than a string\n// TODO: tweak power set token number threshold (heuristic function genre n or n - 1 etc.)\n\n/**\n * Function expanding token by multiplexing tokens that are not initials.\n *\n * @param  {array} tokens - List of tokens.\n * @param  {array}\n */\nfunction expand(tokens) {\n  for (var i = 0, l = tokens.length; i < l; i++) {\n    if (tokens[i].length > 1) tokens[i] = [tokens[i], tokens[i][0]];\n  }\n\n  return tokens;\n}\n\n/**\n * Permutation helper that will expand token possibilities.\n *\n * @param  {array} code - List of possibly expanded tokens.\n * @param  {array}\n */\nfunction permutations(code) {\n  var codes = [[]];\n\n  for (var i = 0, l = code.length; i < l; i++) {\n    var current = code[i];\n\n    if ((typeof current === 'undefined' ? 'undefined' : _typeof(current)) === 'object') {\n\n      // Doubling the codes\n      for (var j = 0, m = codes.length * (current.length - 1); j < m; j++) {\n        codes.push(codes[j].slice());\n      } // Filling the codes\n      var offset = codes.length / current.length;\n\n      for (var _j = 0, k = 0, _m = current.length; _j < _m; _j++) {\n        var encoding = current[_j];\n\n        while (k < offset) {\n          codes[k + _j * offset].push(encoding);\n          k++;\n        }\n\n        k = 0;\n      }\n    } else {\n\n      for (var _j2 = 0, _m2 = codes.length; _j2 < _m2; _j2++) {\n        codes[_j2].push(current);\n      }\n    }\n  }\n\n  return codes;\n}\n\n/**\n * Function returning the name power set.\n *\n * @param  {string|array} name - Target name.\n * @param  {array}\n */\nfunction namePowerSet(name) {\n\n  // If the name is not yet tokenized, we do so\n  if (typeof name === 'string') name = (0, _words2.default)(name);\n\n  // Gathering items which are the sorted unique tokens of the name\n  var tokens = (0, _uniq2.default)(name).sort();\n\n  if (tokens.length < 2) return [tokens];\n\n  var powerSet = Array.from(_generatorics2.default.clone.powerSet(tokens)).filter(function (set) {\n    return set.length > 1;\n  }).map(expand).map(permutations);\n\n  var possibilities = [];\n\n  for (var i = 0, l = powerSet.length; i < l; i++) {\n    var set = powerSet[i];\n\n    for (var j = 0, m = set.length; j < m; j++) {\n      if (!set[j].every(function (token) {\n        return token.length < 2;\n      })) possibilities.push(set[j]);\n    }\n  }\n\n  return possibilities;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/words/index.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _naive = require('./naive');\n\nvar _naive2 = _interopRequireDefault(_naive);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nexports.default = _naive2.default;\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/words/naive.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _words = require('lodash/words');\n\nvar _words2 = _interopRequireDefault(_words);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nexports.default = _words2.default; /**\n                                    * Talisman tokenizers/words/naive\n                                    * ================================\n                                    *\n                                    * Exporting the Lodash's words function for convenience.\n                                    *\n                                    * [Reference]: https://github.com/lodash/lodash\n                                    */\n\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/keyers/normalize.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.createNormalizer = createNormalizer;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _classes = require('../regexp/classes');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Regular expressions.\n */\n/* eslint no-control-regex: 0 */\n/**\n * Talisman keyers/normalize\n * ==========================\n *\n * Generic function used to normalize strings to make them a good basis for\n * fuzzy comparisons.\n */\nvar CONTROL_CHARACTERS = new RegExp('[\\\\x00-\\\\x08\\\\x0A-\\\\x1F\\\\x7F]', 'g'),\n    SINGLE_QUOTES = new RegExp('[' + _classes.SINGLE_QUOTES + ']', 'g'),\n    DOUBLE_QUOTES = new RegExp('[' + _classes.DOUBLE_QUOTES + ']', 'g'),\n    HYPHENS = new RegExp('[' + _classes.HYPHENS + ']', 'g'),\n    COMMAS = new RegExp('[' + _classes.COMMAS + ']', 'g'),\n    WHITESPACE_COMPRESSION = /\\s+/g;\n\nvar CONVERSIONS = [[/…/g, '...'], [/æ/g, 'ae'], [/œ/g, 'oe'], [/ß/g, 'ss']];\n\n/**\n * Function creating a normalizer function.\n *\n * @param  {object}  params        - Options:\n * @param  {boolean}   keepAccents - Whether to keep accents.\n * @param  {boolean}   keepCase    - Whether to keep the case.\n * @return {function}\n */\nfunction createNormalizer(params) {\n  params = params || {};\n\n  var keepAccents = params.keepAccents === true,\n      keepCase = params.keepCase === true;\n\n  /**\n   * Function returning a normalized string.\n   *\n   * @param  {string} string - String to normalize.\n   * @return {string}\n   */\n  return function normalizer(string) {\n    if (!keepCase) string = string.toLowerCase();\n\n    string = string.trim().replace(WHITESPACE_COMPRESSION, ' ').replace(CONTROL_CHARACTERS, '').replace(SINGLE_QUOTES, '\\'').replace(DOUBLE_QUOTES, '\"').replace(HYPHENS, '-').replace(COMMAS, ',');\n\n    for (var i = 0, l = CONVERSIONS.length; i < l; i++) {\n      var pattern = CONVERSIONS[i][0],\n          replacement = CONVERSIONS[i][1];\n\n      string = string.replace(pattern, replacement);\n    }\n\n    if (!keepAccents) string = (0, _deburr2.default)(string);\n\n    return string;\n  };\n}\n\nexports.default = createNormalizer();\nmodule.exports = exports['default'];\nexports['default'].createNormalizer = exports.createNormalizer;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/regexp/classes.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n/**\n * Talisman regexp/classes\n * ========================\n *\n * A collection of handy character classes.\n */\nvar SINGLE_QUOTES = exports.SINGLE_QUOTES = '’‘`‛\\'';\nvar DOUBLE_QUOTES = exports.DOUBLE_QUOTES = '«»„‟“”\"';\nvar HYPHENS = exports.HYPHENS = '\\\\-‐‒–—―−‑⁃';\nvar COMMAS = exports.COMMAS = ',،、';","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/keyers/omission.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = omission;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\nvar UNDESIRABLES = /[^A-Z]/g,\n    CONSONANTS = 'JKQXZVWYBFMGPDHCLNTSR',\n    CONSONANTS_SET = new Set(CONSONANTS);\n\n/**\n * omission key function.\n *\n * @param  {string} string - Target string.\n * @return {string}        - The omission key.\n */\n/**\n * Talisman keyers/omission\n * =========================\n *\n * Keyer taking a string and normalizing it into a \"omission key\".\n *\n * [Reference]:\n * http://dl.acm.org/citation.cfm?id=358048\n * http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.12.385&rep=rep1&type=pdf\n *\n * [Article]:\n * Pollock, Joseph J. and Antonio Zamora. 1984. \"Automatic Spelling Correction\n * in Scientific and Scholarly Text.\" Communications of the ACM, 27(4).\n * 358--368.\n */\nfunction omission(string) {\n\n  // Normalizing case\n  string = string.toUpperCase();\n\n  // Deburring\n  string = (0, _deburr2.default)(string);\n\n  // Dropping useless characters\n  string = string.replace(UNDESIRABLES, '');\n\n  // Composing the key\n  var key = '';\n  var vowels = new Set();\n\n  // Add consonants in order\n  var letters = new Set(string);\n\n  for (var i = 0, l = CONSONANTS.length; i < l; i++) {\n    var consonant = CONSONANTS[i];\n\n    if (letters.has(consonant)) key += consonant;\n  }\n\n  // Add vowels in order they appeared in the word\n  for (var _i = 0, _l = string.length; _i < _l; _i++) {\n    var letter = string[_i];\n\n    if (!CONSONANTS_SET.has(letter) && !vowels.has(letter)) {\n      vowels.add(letter);\n      key += letter;\n    }\n  }\n\n  return key;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/keyers/skeleton.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = skeleton;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\nvar UNDESIRABLES = /[^A-Z]/g,\n    VOWELS = new Set('AEIOU');\n\n/**\n * Helpers.\n */\n/**\n * Talisman keyers/skeleton\n * =========================\n *\n * Keyer taking a string and normalizing it into a \"skeleton key\".\n *\n * [Reference]:\n * http://dl.acm.org/citation.cfm?id=358048\n * http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.12.385&rep=rep1&type=pdf\n *\n * [Article]:\n * Pollock, Joseph J. and Antonio Zamora. 1984. \"Automatic Spelling Correction\n * in Scientific and Scholarly Text.\" Communications of the ACM, 27(4).\n * 358--368.\n */\nfunction consume(set) {\n  return Array.from(set).join('');\n}\n\n/**\n * Skeleton key function.\n *\n * @param  {string} string - Target string.\n * @return {string}        - The skeleton key.\n */\nfunction skeleton(string) {\n\n  // Normalizing case\n  string = string.toUpperCase();\n\n  // Deburring\n  string = (0, _deburr2.default)(string);\n\n  // Dropping useless characters\n  string = string.replace(UNDESIRABLES, '');\n\n  // Composing the key\n  var firstLetter = string[0];\n\n  if (!firstLetter) return '';\n\n  var consonants = new Set(),\n      vowels = new Set();\n\n  for (var i = 1, l = string.length; i < l; i++) {\n    var letter = string[i];\n\n    if (letter === firstLetter) continue;\n\n    if (VOWELS.has(letter)) vowels.add(letter);else consonants.add(letter);\n  }\n\n  return firstLetter + consume(consonants) + consume(vowels);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/keyword-extraction/rake.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = createExtractor;\n\nvar _heap = require('mnemonist/heap');\n\nvar _heap2 = _interopRequireDefault(_heap);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// TODO: mitigation strategy to implement\n// TODO: tokenizer option, stemmer option\n// TODO: option for keyword merging\n// TODO: configure T\n// TODO: handle numbers\n\n/**\n * Constants.\n */\nvar PUNCTUATION = /^[^\\w\\s]+$/,\n    HASH_DELIMITER = '\\x01';\n\n/**\n * Helpers.\n */\n/**\n * Talisman keyword-extraction/rake\n * =================================\n *\n * JavaScript implementation of the \"Rapid Automatic Keyword Extraction\" (RAKE).\n *\n * [Article]:\n * Rose, S., Engel, D., Cramer, N., & Cowley, W. (2010). Automatic Keyword\n * Extraction from Individual Documents. In M. W. Berry & J. Kogan (Eds.),\n * Text Mining: Theory and Applications: John Wiley & Sons.\n *\n * [Notes]:\n * The article use the term \"degree\" in a somewhat incorrect way. It's more\n * of the propension of a given word to find itself in a long keyword.\n */\nfunction comparator(a, b) {\n  if (a.score < b.score) return -1;\n  if (a.score > b.score) return 1;\n  return 0;\n}\n\n/**\n * Factory function taking some options & returning a custom RAKE function.\n *\n * @param  {object} options     - Options:\n * @param  {array}    stopwords - List of stopwords to use.\n */\nfunction createExtractor(options) {\n  options = options || {};\n\n  var stopwords = options.stopwords;\n\n  if (!Array.isArray(stopwords)) throw new Error('talisman/keyword-extraction/rake: expecting a list of stopwords.');\n\n  var stopwordsSet = new Set(stopwords);\n\n  /**\n   * RAKE function taking an array of sentences being tokenized as words.\n   * Note that the tokenization must keep punctuation in order to be able\n   * to extract keywords.\n   *\n   * Alternatively, one can also stem the given tokens beforehand to minimize\n   * the number of distinct keyword words.\n   *\n   * @param  {array}  doc - Target document.\n   * @return {array}      - Resulting keywords.\n   */\n  return function (doc) {\n\n    // First we need to find candidate keywords & score individual words\n    var candidateKeywords = new Set(),\n        wordFrequencies = {},\n        wordDegrees = {};\n\n    for (var i = 0, l = doc.length; i < l; i++) {\n      var sentence = doc[i];\n\n      var keyword = [];\n\n      for (var j = 0, m = sentence.length; j < m; j++) {\n        var word = sentence[j];\n\n        if (stopwordsSet.has(word) || PUNCTUATION.test(word)) {\n          if (keyword.length) {\n\n            // Storing the hashed keyword for later\n            candidateKeywords.add(keyword.join(HASH_DELIMITER));\n\n            // Updating the degrees\n            var degree = keyword.length - 1;\n\n            for (var k = 0, n = keyword.length; k < n; k++) {\n              wordDegrees[keyword[k]] = wordDegrees[keyword[k]] || 0;\n              wordDegrees[keyword[k]] += degree;\n            }\n\n            keyword = [];\n          }\n        } else {\n\n          // Updating word frequency\n          wordFrequencies[word] = wordFrequencies[word] || 0;\n          wordFrequencies[word]++;\n\n          // Adding the word to the current keyword\n          keyword.push(word);\n        }\n      }\n    }\n\n    // Now we need to score the keywords and retrieve the best one\n    var heap = new _heap2.default(comparator),\n        T = candidateKeywords.size / 3 | 0;\n\n    candidateKeywords.forEach(function (keyword) {\n      var words = keyword.split(HASH_DELIMITER);\n      var score = 0;\n\n      for (var _i = 0, _l = words.length; _i < _l; _i++) {\n        var _word = words[_i];\n        score += wordDegrees[_word] / wordFrequencies[_word];\n      }\n\n      heap.push({ score: score, keyword: words });\n\n      if (heap.size > T) heap.pop();\n    });\n\n    // Returning the results\n    var result = new Array(T);\n\n    for (var _i2 = heap.size - 1; _i2 >= 0; _i2--) {\n      result[_i2] = heap.pop().keyword;\n    }return result;\n  };\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/parsers/brown.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = brown;\n/**\n * Talisman parsers/brown\n * =======================\n *\n * A parser for Brown corpus files.\n */\nvar TOKEN_REGEX = /([^/\\n\\t\\r\\s]+)\\/([^\\s\\n]+)/g;\n\n/**\n * Function taking text from the Brown corpus and outputting an array of\n * (word, tag) tuples.\n *\n * @param  {string} text - The text to parse.\n * @return {array}       - The tokens.\n */\nfunction brown(text) {\n  var tokens = [];\n  var match = void 0;\n\n  while (match = TOKEN_REGEX.exec(text)) {\n    tokens.push([match[1], match[2]]);\n  }\n\n  TOKEN_REGEX.lastIndex = 0;\n\n  return tokens;\n}\nmodule.exports = exports[\"default\"];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/parsers/conll.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = conll;\n/**\n * Talisman parsers/conll\n * =======================\n *\n * A parser for the CONLL corpus files.\n */\n\n/**\n * Function taking a CONLL corpus' text and returning an array of sentences\n * being arrays of (word, brill_tag, wsj_tag).\n *\n * @param  {string} text - The text to parse.\n * @return {array}       - The tokens.\n */\nfunction conll(text) {\n  var sentences = [],\n      lines = text.split('\\n');\n\n  var sentence = [];\n  for (var i = 0, l = lines.length; i < l; i++) {\n    var line = lines[i];\n\n    if (!line) {\n      if (sentence.length) {\n        sentences.push(sentence);\n        sentence = [];\n      }\n    } else {\n      sentence.push(line.split(' '));\n    }\n  }\n\n  if (sentence.length) sentences.push(sentence);\n\n  return sentences;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/alpha-sis.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; /**\n                                                                                                                                                                                                                                                                               * Talisman phonetics/alpha-sis\n                                                                                                                                                                                                                                                                               * =============================\n                                                                                                                                                                                                                                                                               *\n                                                                                                                                                                                                                                                                               * IBM Alpha Search Inquiry System.\n                                                                                                                                                                                                                                                                               *\n                                                                                                                                                                                                                                                                               * [Reference]:\n                                                                                                                                                                                                                                                                               * https://archive.org/stream/accessingindivid00moor#page/15/mode/1up\n                                                                                                                                                                                                                                                                               *\n                                                                                                                                                                                                                                                                               * [Article]:\n                                                                                                                                                                                                                                                                               * Accessing individual records from personal data files using non-unique\n                                                                                                                                                                                                                                                                               * identifiers\" / Gwendolyn B. Moore, et al.; prepared for the Institute for\n                                                                                                                                                                                                                                                                               * Computer Sciences and Technology, National Bureau of Standards,\n                                                                                                                                                                                                                                                                               * Washington, D.C (1977)\n                                                                                                                                                                                                                                                                               */\n\n\nexports.default = alphaSis;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _helpers = require('../helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\nvar INITIALS = [['GF', '08'], ['GM', '03'], ['GN', '02'], ['KN', '02'], ['PF', '08'], ['PN', '02'], ['PS', '00'], ['WR', '04'], ['A', '1'], ['E', '1'], ['H', '2'], ['I', '1'], ['J', '3'], ['O', '1'], ['U', '1'], ['W', '4'], ['Y', '5']];\n\nvar BASICS = [['SCH', '6'], ['CZ', ['70', '6', '0']], ['CH', ['6', '70', '0']], ['CK', ['7', '6']], ['DS', ['0', '10']], ['DZ', ['0', '10']], ['TS', ['0', '10']], ['TZ', ['0', '10']], ['CI', '0'], ['CY', '0'], ['CE', '0'], ['SH', '6'], ['DG', '7'], ['PH', '8'], ['C', ['7', '6']], ['K', ['7', '6']], ['Z', '0'], ['S', '0'], ['D', '1'], ['T', '1'], ['N', '2'], ['M', '3'], ['R', '4'], ['L', '5'], ['J', '6'], ['G', '7'], ['Q', '7'], ['X', '7'], ['F', '8'], ['V', '8'], ['B', '9'], ['P', '9']];\n\n/**\n * Helpers.\n */\nfunction pad(code) {\n  return (code + '00000000000000').slice(0, 14);\n}\n\nfunction permutations(code) {\n  var codes = [''];\n\n  for (var i = 0, l = code.length; i < l; i++) {\n    var current = code[i];\n\n    if ((typeof current === 'undefined' ? 'undefined' : _typeof(current)) === 'object') {\n\n      // Doubling the codes\n      for (var j = 0, m = codes.length * (current.length - 1); j < m; j++) {\n        codes.push(codes[j]);\n      } // Filling the codes\n      var offset = codes.length / current.length;\n\n      for (var _j = 0, k = 0, _m = current.length; _j < _m; _j++) {\n        var encoding = current[_j];\n\n        while (k < offset) {\n          codes[k + _j * offset] += encoding;\n          k++;\n        }\n\n        k = 0;\n      }\n    } else {\n\n      for (var _j2 = 0, _m2 = codes.length; _j2 < _m2; _j2++) {\n        codes[_j2] += current;\n      }\n    }\n  }\n\n  return codes;\n}\n\n/**\n * Function taking a single name and computing its Alpha SIS value.\n *\n * @param  {string}  name - The name to process.\n * @return {array}        - List of the possible Alpha SIS values.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction alphaSis(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/alpha-sis: the given name is not a string.');\n\n  name = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z]/g, '');\n\n  var code = [];\n\n  var position = 0;\n\n  // Handling inital substring\n  for (var i = 0, l = INITIALS.length; i < l; i++) {\n    var _INITIALS$i = INITIALS[i],\n        substring = _INITIALS$i[0],\n        encoding = _INITIALS$i[1];\n\n\n    if (name.startsWith(substring)) {\n      code.push(encoding);\n      position += substring.length;\n      break;\n    }\n  }\n\n  // If the beginning of the string is not present in initial, we put '0'\n  if (!code[0]) code.push('0');\n\n  // Encoding the remaining\n  var length = name.length;\n\n  main: while (position < length) {\n\n    for (var _i = 0, _l = BASICS.length; _i < _l; _i++) {\n      var _BASICS$_i = BASICS[_i],\n          substring = _BASICS$_i[0],\n          encoding = _BASICS$_i[1];\n\n\n      if (name.slice(position).startsWith(substring)) {\n        code.push(encoding);\n        position += substring.length;\n        continue main;\n      }\n    }\n\n    code.push('_');\n    position++;\n  }\n\n  return permutations(code).map(function (c) {\n    return pad((0, _helpers.squeeze)(c).replace(/_/g, ''));\n  });\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/caverphone.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.revisited = exports.original = undefined;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Rules.\n */\nvar RULES = {\n  original: [[/e$/g, ''], [/^(cou|rou|tou|enou|trou)gh/g, '$12f'], [/^gn/g, '2n'], [/^mb/g, 'm2'], [/cq/g, '2q'], [/ci/g, 'si'], [/ce/g, 'se'], [/cy/g, 'sy'], [/tch/g, '2ch'], [/c/g, 'k'], [/q/g, 'k'], [/x/g, 'k'], [/v/g, 'f'], [/dg/g, '2g'], [/tio/g, 'sio'], [/tia/g, 'sia'], [/d/g, 't'], [/ph/g, 'fh'], [/b/g, 'p'], [/sh/g, 's2'], [/z/g, 's'], [/^[aieou]/g, 'A'], [/[aeiou]/g, '3'], [/i/g, 'y'], [/^y3/g, 'Y3'], [/^y/g, 'A'], [/y/g, '3'], [/3gh3/g, '3kh3'], [/gh/g, '22'], [/g/g, 'k'], [/s+/g, 'S'], [/t+/g, 'T'], [/p+/g, 'P'], [/k+/g, 'K'], [/f+/g, 'F'], [/m+/g, 'M'], [/n+/g, 'N'], [/w3/g, 'W3'], [/wh3/g, 'Wh3'], [/w$/g, '3'], [/w/g, '2'], [/^h/g, 'A'], [/h/g, '2'], [/r3/g, 'R3'], [/r$/g, '3'], [/r/g, '2'], [/l3/g, 'L3'], [/l$/g, '3'], [/l/g, '2'], [/2/g, ''], [/3$/g, 'A'], [/3/g, '']],\n  revisited: [[/e$/g, ''], [/^(cou|rou|tou|enou|trou)gh/g, '$12f'], [/^gn/g, '2n'], [/mb$/g, 'mb'], [/cq/g, '2q'], [/c([iey])/g, 's$1'], [/tch/g, '2ch'], [/[cqx]/g, 'k'], [/v/g, 'f'], [/dg/g, '2g'], [/ti([oa])/g, 'si$1'], [/d/g, 't'], [/ph/g, 'fh'], [/b/g, 'p'], [/sh/g, 's2'], [/z/g, 's'], [/^[aeiou]/g, 'A'], [/[aeiou]/g, '3'], [/j/g, 'y'], [/^y3/g, 'Y3'], [/^y/g, 'A'], [/y/g, '3'], [/3gh3/g, '3kh3'], [/gh/g, '22'], [/g/g, 'k'], [/s+/g, 'S'], [/t+/g, 'T'], [/p+/g, 'P'], [/k+/g, 'K'], [/f+/g, 'F'], [/m+/g, 'M'], [/n+/g, 'N'], [/w3/g, 'W3'], [/wh3/g, 'Wh3'], [/w$/g, '3'], [/w/g, '2'], [/^h/g, 'A'], [/h/g, '2'], [/r3/g, 'R3'], [/r$/g, '3'], [/r/g, '2'], [/l3/g, 'L3'], [/l$/g, '3'], [/l/g, '2'], [/2/g, ''], [/3$/g, 'A'], [/3/g, '']]\n};\n\n/**\n * Helpers.\n */\n/**\n * Talisman phonetics/caverphone\n * ==============================\n *\n * The caverphone algorithm, original & revisited.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Caverphone\n *\n * Original algorithm:\n * http://caversham.otago.ac.nz/files/working/ctp060902.pdf\n * Revisited algorithm:\n * http://caversham.otago.ac.nz/files/working/ctp150804.pdf\n *\n * [Author]:\n * David Hood (Caversham project)\n * http://caversham.otago.ac.nz/\n */\nfunction pad(code) {\n  while (code.length < 10) {\n    code += '1';\n  }return code.slice(0, 10);\n}\n\n/**\n * Function taking a single name and computing its caverphone code.\n *\n * @param  {array}  rules - The rules to use.\n * @param  {string} name  - The name to process.\n * @return {string}       - The caverphone code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction caverphone(rules, name) {\n\n  if (typeof name !== 'string') throw Error('talisman/phonetics/caverphone: the given name is not a string.');\n\n  // Preparing the name\n  name = (0, _deburr2.default)(name).toLowerCase().replace(/[^a-z]/g, '');\n\n  // Applying the rules\n  for (var i = 0, l = rules.length; i < l; i++) {\n    var _rules$i = rules[i],\n        match = _rules$i[0],\n        replacement = _rules$i[1];\n\n    name = name.replace(match, replacement);\n  }\n\n  // Returning the padded code\n  return pad(name);\n}\n\n/**\n * Exporting functions.\n */\nvar original = caverphone.bind(null, RULES.original),\n    revisited = caverphone.bind(null, RULES.revisited);\n\nexports.default = original;\nexports.original = original;\nexports.revisited = revisited;\nmodule.exports = exports['default'];\nexports['default'].original = exports.original;\nexports['default'].revisited = exports.revisited;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/daitch-mokotoff.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; /**\n                                                                                                                                                                                                                                                                               * Talisman phonetics/daitch-mokotoff\n                                                                                                                                                                                                                                                                               * ===================================\n                                                                                                                                                                                                                                                                               *\n                                                                                                                                                                                                                                                                               * The Daitch-Mokotoff Soundex.\n                                                                                                                                                                                                                                                                               *\n                                                                                                                                                                                                                                                                               * [Reference]:\n                                                                                                                                                                                                                                                                               * https://en.wikipedia.org/wiki/Daitch%E2%80%93Mokotoff_Soundex\n                                                                                                                                                                                                                                                                               */\n\n\nexports.default = daitchMokotoff;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Rules.\n *\n * [Note]:\n * For the (RS|RZ) part, the original algo says (94, 4) but most\n * implementations drop it to only (94). This implementation follows the\n * original algo.\n */\nvar MNNM = /^(MN|NM)/,\n    MN = /^(M|N)/;\n\nvar RULES = {\n  A: [[/^(AI|AJ|AY)/, 0, 1, null], [/^AU/, 0, 7, null], [null, 0, null, null]],\n  Ą: [[null, null, null, [6, null]]],\n  B: [[null, 7, 7, 7]],\n  C: [[/^CHS/, 5, 54, 54], [/^CH/, [5, 4], [5, 4], [5, 4]], [/^CK/, [5, 45], [5, 45], [5, 45]], [/^(CSZ|CZS|CZ|CS)/, 4, 4, 4], [null, [5, 4], [5, 4], [5, 4]]],\n  D: [[/^(DRZ|DRS|DSH|DSZ|DZH|DZS|DS|DZ)/, 4, 4, 4], [/^(DT|D)/, 3, 3, 3]],\n  E: [[/^(EI|EJ|EY)/, 0, 1, null], [/^EU/, 1, 1, null], [null, 0, null, null]],\n  Ę: [[null, null, null, [6, null]]],\n  F: [[/^(FB|F)/, 7, 7, 7]],\n  G: [[null, 5, 5, 5]],\n  H: [[null, 5, 5, null]],\n  I: [[/^(IA|IE|IO|IU)/, 1, null, null], [null, 0, null, null]],\n  J: [[null, [1, 4], [null, 4], [null, 4]]],\n  K: [[/^KS/, 5, 54, 54], [/^(KH|K)/, 5, 5, 5]],\n  L: [[null, 8, 8, 8]],\n  M: [[MNNM, null, 66, 66], [MN, 6, 6, 6]],\n  N: [[MNNM, null, 66, 66], [MN, 6, 6, 6]],\n  O: [[/^(OI|OJ|OY)/, 0, 1, null], [null, 0, null, null]],\n  P: [[/^(PF|PH|P)/, 7, 7, 7]],\n  Q: [[null, 5, 5, 5]],\n  R: [[/^(RZ|RS)/, [94, 4], [94, 4], [94, 4]], [null, 9, 9, 9]],\n  S: [[/^(SCHTSCH|SCHTSH|SCHTCH|SHTCH|SHCH|SHTSH)/, 2, 4, 4], [/^SCH/, 4, 4, 4], [/^(SHT|SCHT|SCHD)/, 2, 43, 43], [/^SH/, 4, 4, 4], [/^(STCH|STSCH|SC|STRZ|STRS|STSH)/, 2, 4, 4], [/^ST/, 2, 43, 43], [/^(SZCZ|SZCS)/, 2, 4, 4], [/^(SZT|SHD|SZD|SD)/, 2, 43, 43], [/^(SZ|S)/, 4, 4, 4]],\n  T: [[/^(TCH|TTCH|TTSCH)/, 4, 4, 4], [/^TH/, 3, 3, 3], [/^(TRZ|TRS|TSCH|TSH|TS|TTS|TTSZ|TC|TZ|TTZ|TZS|TSZ)/, 4, 4, 4], [null, 3, 3, 3]],\n  Ţ: [[null, [3, 4], [3, 4], [3, 4]]],\n  U: [[/^(UI|UJ|UY)/, 0, 1, null], [/^(UE|U)/, 0, null, null]],\n  V: [[null, 7, 7, 7]],\n  W: [[null, 7, 7, 7]],\n  X: [[null, 5, 54, 54]],\n  Y: [[null, 1, null, null]],\n  Z: [[/^(ZHDZH|ZDZH|ZDZ)/, 2, 4, 4], [/^(ZHD|ZD)/, 2, 43, 43], [/^(ZSCH|ZSH|ZH|ZS|Z)/, 4, 4, 4]]\n};\n\n/**\n * Helpers.\n */\nfunction pad(code) {\n  return (code + '000000').slice(0, 6);\n}\n\nfunction permutations(code) {\n  var codes = [''];\n\n  for (var i = 0, l = code.length; i < l; i++) {\n    var current = code[i];\n\n    if ((typeof current === 'undefined' ? 'undefined' : _typeof(current)) === 'object') {\n\n      // Doubling the codes\n      for (var j = 0, m = codes.length; j < m; j++) {\n        codes.push(codes[j]);\n      } // Filling the codes\n      for (var _j = 0, _m = codes.length; _j < _m; _j++) {\n        var s = current[_j < _m / 2 ? 0 : 1];\n        codes[_j] += s !== null ? s : '';\n      }\n    } else {\n\n      for (var _j2 = 0, _m2 = codes.length; _j2 < _m2; _j2++) {\n        codes[_j2] += current;\n      }\n    }\n  }\n\n  return codes;\n}\n\nvar VOWELS = new Set(['A', 'E', 'I', 'O', 'U', 'Y']);\n\n/**\n * Function taking a single name and computing its Daitch-Mokotoff soundex code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The Daitch-Mokotoff code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction daitchMokotoff(name) {\n\n  if (typeof name !== 'string') throw Error('talisman/phonetics/daitch-mokotoff: the given name is not a string.');\n\n  var code = [];\n\n  var current = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-ZĄĘŢ]/g, '');\n\n  var start = true,\n      lastPattern = void 0;\n\n  // Applying the rules\n  while (current.length) {\n\n    // Find the subset of rules applying to the current letter\n    var firstLetter = current.charAt(0),\n        rules = RULES[firstLetter];\n\n    for (var i = 0, l = rules.length; i < l; i++) {\n      var _rules$i = rules[i],\n          pattern = _rules$i[0],\n          ifFirstLetter = _rules$i[1],\n          vowelNext = _rules$i[2],\n          usual = _rules$i[3];\n\n\n      var match = pattern ? current.match(pattern) : [firstLetter];\n\n      if (match) {\n        var offset = match[0].length;\n\n        var correctCode = usual;\n\n        if (start) correctCode = ifFirstLetter;else if (VOWELS.has(current.charAt(offset))) correctCode = vowelNext;\n\n        if (lastPattern !== pattern && correctCode !== null) code.push(correctCode);\n\n        lastPattern = pattern || firstLetter;\n\n        current = current.slice(offset);\n        break;\n      }\n    }\n\n    start = false;\n  }\n\n  return permutations(code).map(pad);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/double-metaphone.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = doubleMetaphone;\n/* eslint no-constant-condition: 0 */\n/**\n * Talisman phonetics/double-metaphone\n * ====================================\n *\n * The double metaphone algorithm.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Metaphone#Double_Metaphone\n *\n * [Author]:\n * Lawrence Philips, 2000\n */\n\n/**\n * Helpers.\n */\nvar STARTING_REGEX = /^GN|KN|PN|WR|PS$/;\n\nvar SLAVO_GERMANIC_REGEX = /W|K|CZ|WITZ/;\n\nfunction isSlavoGermanic(string) {\n  return SLAVO_GERMANIC_REGEX.test(string);\n}\n\nvar VOWELS = new Set(['A', 'E', 'I', 'O', 'U', 'Y']);\n\nfunction isVowel(string) {\n  return string.length === 1 && VOWELS.has(string);\n}\n\n/**\n * Lookups.\n */\nvar CHSet1 = new Set(['HARAC', 'HARIS']),\n    CHSet2 = new Set(['HOR', 'HYM', 'HIA', 'HEM']),\n    CHSet3 = new Set(['VAN ', 'VON ']),\n    CHSet4 = new Set(['ORCHES', 'ARCHIT', 'ORCHID']),\n    ChSet5 = new Set(['T', 'S']),\n    CHSet6 = new Set(['A', 'O', 'U', 'E']),\n    CHSet7 = new Set(['L', 'R', 'N', 'M', 'B', 'H', 'F', 'V', 'W', ' ']),\n    CSet1 = new Set(['CE', 'CI']);\n\nvar LOOKUPS = {\n  B: function B(string, pos) {\n    return ['P', 'P', string.substr(pos + 1, 1) === 'B' ? 2 : 1];\n  },\n  CH: function CH(string, pos) {\n    if (pos && string.substr(pos, 4) === 'CHAE') {\n      return ['K', 'X', 2];\n    } else if (!pos && (CHSet1.has(string.substr(pos + 1, 5)) || CHSet2.has(string.substr(pos + 1, 3))) && string.substr(0, 5) !== 'CHORE') {\n      return ['K', 'K', 2];\n    } else if (CHSet3.has(string.substr(0, 4)) || string.substr(0, 3) === 'SCH' || CHSet4.has(string.substr(pos - 2, 6)) || ChSet5.has(string.substr(pos + 2, 1)) || (!pos || CHSet6.has(string.substr(pos - 1, 1))) && CHSet7.has(string.substr(pos + 2, 1))) {\n      return ['K', 'K', 2];\n    } else if (pos) {\n      return [string.substr(0, 2) === 'MC' ? 'K' : 'X', 'K', 2];\n    }\n\n    return ['X', 'X', 2];\n  },\n  CC: function CC(string, pos) {\n    if (/^I|E|H$/.test(string.substr(pos + 2, 1)) && string.substr(pos + 2, 2) !== 'HU') {\n      if (pos === 1 && string.substr(pos - 1, 1) === 'A' || /^UCCE(E|S)$/.test(string.substr(pos - 1, 5))) {\n        return [['K', 'S'], ['K', 'S'], 3];\n      } else {\n        return ['X', 'X', 3];\n      }\n    }\n\n    return ['K', 'K', 2];\n  },\n  C: function C(string, pos) {\n    if (pos > 1 && isVowel(string.substr(pos - 2, 1)) && string.substr(pos - 1, 3) === 'ACH' && string.substr(pos + 2, 1) !== 'I' && (string.substr(pos + 2, 1) !== 'E' || /^(B|M)ACHER$/.test(string.substr(pos - 2, 6)))) {\n      return ['K', 'K', 2];\n    }\n\n    if (!pos && string.substr(pos, 6) === 'CAESAR') {\n      return ['S', 'S', 2];\n    }\n\n    if (string.substr(pos, 4) === 'CHIA') {\n      return ['K', 'K', 2];\n    }\n\n    if (string.substr(pos, 2) === 'CH') {\n      return LOOKUPS.CH(string, pos);\n    }\n\n    if (string.substr(pos, 2) === 'CZ' && string.substr(pos - 2, 4) !== 'WICZ') {\n      return ['S', 'X', 2];\n    }\n\n    if (string.substr(pos + 1, 3) === 'CIA') {\n      return ['X', 'X', 3];\n    }\n\n    if (string.substr(pos, 2) === 'CC' && !(pos === 1 || string.substr(0, 1) === 'M')) {\n      return LOOKUPS.CC(string, pos);\n    }\n\n    if (/^C(K|G|Q)$/.test(string.substr(pos, 2))) {\n      return ['K', 'K', 2];\n    }\n\n    if (/^C(I|E|Y)$/.test(string.substr(pos, 2))) {\n      return ['S', /^CI(O|E|A)$/.test(string.substr(pos, 3)) ? 'X' : 'S', 2];\n    }\n\n    if (/^ (C|Q|G)$/.test(string.substr(pos + 1, 2))) {\n      return ['K', 'K', 3];\n    }\n\n    var offset = 1;\n\n    if (/^C|K|Q$/.test(string.substr(pos + 1, 1)) && !CSet1.has(string.substr(pos + 1, 2))) {\n      offset = 2;\n    }\n\n    return ['K', 'K', offset];\n  },\n  Ç: function _() {\n    return ['S', 'S', 1];\n  },\n  D: function D(string, pos) {\n    if (string.substr(pos, 2) === 'DG') {\n      return (/^I|E|Y$/.test(string.substr(pos + 2, 1)) ? ['J', 'J', 3] : [['T', 'K'], ['T', 'K'], 2]\n      );\n    }\n\n    return ['T', 'T', /^D(T|D)$/.test(string.substr(pos, 2)) ? 2 : 1];\n  },\n  F: function F(string, pos) {\n    return ['F', 'F', string.substr(pos + 1, 1) === 'F' ? 2 : 1];\n  },\n  GH: function GH(string, pos) {\n    if (pos && !isVowel(string.substr(pos - 1, 1))) {\n      return ['K', 'K', 2];\n    }\n\n    if (!pos) {\n      return string.substr(pos + 2, 1) === 'I' ? ['J', 'J', 2] : ['K', 'K', 2];\n    }\n\n    if (pos > 1 && /^B|H|D$/.test(string.substr(pos - 2, 1)) || pos > 2 && /^B|H|D$/.test(string.substr(pos - 3, 1)) || pos > 3 && /^B|H$/.test(string.substr(pos - 4, 1))) {\n      return [null, null, 2];\n    }\n\n    if (pos > 2 && string.substr(pos - 1, 1) === 'U' && /^C|G|L|R|T$/.test(string.substr(pos - 3, 1))) {\n      return ['F', 'F', 2];\n    }\n\n    if (pos && string.substr(pos - 1, 1) !== 'I') {\n      return ['K', 'K', 2];\n    }\n\n    return [null, null, 2];\n  },\n  GN: function GN(string, pos) {\n    if (pos === 1 && isVowel(string.substr(0, 1)) && !isSlavoGermanic(string)) {\n      return [['K', 'N'], 'N', 2];\n    }\n\n    if (string.substr(pos + 2, 2) !== 'EY' && string.substr(pos + 1, 1) !== 'Y' && !isSlavoGermanic(string)) {\n      return ['N', ['K', 'N'], 2];\n    }\n\n    return [['K', 'N'], ['K', 'N'], 2];\n  },\n  G: function G(string, pos) {\n    var nextLetter = string.substr(pos + 1, 1),\n        nextPair = string.substr(pos + 1, 2);\n\n    if (nextLetter === 'H') {\n      return LOOKUPS.GH(string, pos);\n    }\n\n    if (nextLetter === 'N') {\n      return LOOKUPS.GN(string, pos);\n    }\n\n    if (nextPair === 'LI' && !isSlavoGermanic(string)) {\n      return [['K', 'L'], 'L', 2];\n    }\n\n    if (!pos && (nextLetter === 'Y' || /^(E(S|P|B|L|Y|I|R)|I(B|L|N|E))$/.test(nextPair))) {\n      return ['K', 'J', 2];\n    }\n\n    if ((nextPair === 'ER' || nextLetter === 'Y') && !/^(D|R|M)ANGER$/.test(string.substr(0, 6)) && !/^E|I$/.test(string.substr(pos - 1, 1)) && !/^(R|O)GY$/.test(string.substr(pos - 1, 3))) {\n      return ['K', 'J', 2];\n    }\n\n    if (/^E|I|Y$/.test(nextLetter) || /^(A|O)GGI$/.test(string.substr(pos - 1, 4))) {\n\n      if (/^V(A|O)N /.test(string.substr(0, 4)) || string.substr(0, 3) === 'SCH' || string.substr(pos + 1, 2 === 'ET')) {\n        return ['K', 'K', 2];\n      }\n\n      return string.substr(pos + 1, 4) === 'IER ' ? ['J', 'J', 2] : ['J', 'K', 2];\n    }\n\n    return ['K', 'K', nextLetter === 'G' ? 2 : 1];\n  },\n  H: function H(string, pos) {\n    if ((!pos || isVowel(string.substr(pos - 1, 1))) && isVowel(string.substr(pos + 1, 1))) {\n      return ['H', 'H', 2];\n    }\n\n    return [null, null, 1];\n  },\n  J: function J(string, pos, lastIndex) {\n    if (string.substr(pos, 4) === 'JOSE' || string.substr(0, 4) === 'SAN ') {\n\n      if (!pos && string.substr(pos + 4, 1) === ' ' || string.substr(0, 4) === 'SAN ') {\n        return ['H', 'H', 1];\n      }\n\n      return ['J', 'H', 1];\n    }\n\n    var offset = string.substr(pos + 1, 1) === 'J' ? 2 : 1;\n\n    if (!pos && string.substr(pos, 4) !== 'JOSE') {\n      return ['J', 'A', offset];\n    }\n\n    if (isVowel(string.substr(pos - 1, 1)) && !isSlavoGermanic(string) && /^A|O$/.test(string.substr(pos + 1, 1))) {\n      return ['J', 'H', offset];\n    }\n\n    if (lastIndex === pos) {\n      return ['J', null, offset];\n    }\n\n    if (!/^L|T|K|S|N|M|B|Z$/.test(string.substr(pos + 1, 1)) && !/^S|K|L$/.test(string.substr(pos - 1, 1))) {\n      return ['J', 'J', offset];\n    }\n\n    return [null, null, offset];\n  },\n  K: function K(string, pos) {\n    return ['K', 'K', string.substr(pos + 1, 1) === 'K' ? 2 : 1];\n  },\n  L: function L(string, pos, lastIndex, length) {\n    if (string.substr(pos + 1, 1) === 'L') {\n\n      if (pos === length - 3 && /^(ILL(O|A)|ALLE)$/.test(string.substr(pos - 1, 4)) || /^(A|O)S$/.test(string.substr(lastIndex - 1, 2) || /^A|O$/.test(string.substr(lastIndex, 1))) && string.substr(pos - 1, 4) === 'ALLE') {\n        return ['L', null, 2];\n      }\n\n      return ['L', 'L', 2];\n    }\n\n    return ['L', 'L', 1];\n  },\n  M: function M(string, pos, lastIndex) {\n    if (string.substr(pos - 1, 3) === 'UMB' && (pos === lastIndex - 1 || string.substr(pos + 2, 2) === 'ER') || string.substr(pos + 1, 1) === 'M') {\n      return ['M', 'M', 2];\n    }\n\n    return ['M', 'M', 1];\n  },\n  N: function N(string, pos) {\n    return ['N', 'N', string.substr(pos + 1, 1) === 'N' ? 2 : 1];\n  },\n  Ñ: function _() {\n    return ['N', 'N', 1];\n  },\n  P: function P(string, pos) {\n    if (string.substr(pos + 1, 1) === 'H') {\n      return ['F', 'F', 2];\n    }\n\n    return ['P', 'P', /^P|B$/.test(string.substr(pos + 1, 1)) ? 2 : 1];\n  },\n  Q: function Q(string, pos) {\n    return ['K', 'K', string.substr(pos + 1, 1) === 'Q' ? 2 : 1];\n  },\n  R: function R(string, pos, lastIndex) {\n    var offset = string.substr(pos + 1, 1) === 'R' ? 2 : 1;\n\n    if (pos === lastIndex && !isSlavoGermanic(string) && string.substr(pos - 2, 2) === 'IE' && !/^M(E|A)$/.test(string.substr(pos - 4, 2))) {\n      return [null, 'R', offset];\n    }\n\n    return ['R', 'R', offset];\n  },\n  SH: function SH(string, pos) {\n    return (/^H(EIM|OEK|OLM|OLZ)$/.test(string.substr(pos + 1, 4)) ? ['S', 'S', 2] : ['X', 'X', 2]\n    );\n  },\n  SC: function SC(string, pos) {\n    if (string.substr(pos + 2, 1) === 'H') {\n      if (/^OO|ER|EN|UY|ED|EM$/.test(string.substr(pos + 3, 2))) {\n        return [/^E(R|N)$/.test(string.substr(pos + 3, 2)) ? 'X' : ['S', 'K'], ['S', 'K'], 3];\n      }\n\n      return ['X', !pos && !isVowel(string.substr(3, 1)) && string.substr(pos + 3, 1) !== 'W' ? 'S' : 'X', 3];\n    }\n\n    if (/^I|E|Y$/.test(string.substr(pos + 2, 1))) {\n      return ['S', 'S', 3];\n    }\n\n    return [['S', 'K'], ['S', 'K'], 3];\n  },\n  S: function S(string, pos, lastIndex) {\n    if (/^(I|Y)SL$/.test(string.substr(pos - 1, 3))) {\n      return [null, null, 1];\n    }\n\n    if (!pos && string.substr(pos, 5) === 'SUGAR') {\n      return ['X', 'S', 1];\n    }\n\n    if (string.substr(pos, 2) === 'SH') {\n      return LOOKUPS.SH(string, pos);\n    }\n\n    if (/^SI(O|A)$/.test(string.substr(pos, 3)) || string.substr(pos, 4) === 'SIAN') {\n      return ['S', isSlavoGermanic(string) ? 'S' : 'X', 3];\n    }\n\n    if (!pos && /^M|N|L|W$/.test(string.substr(pos + 1, 1)) || string.substr(pos + 1, 1) === 'Z') {\n      return ['S', 'X', string.substr(pos + 1, 1) === 'Z' ? 2 : 1];\n    }\n\n    if (string.substr(pos, 2) === 'SC') {\n      return LOOKUPS.SC(string, pos);\n    }\n\n    return [!(lastIndex === pos && /^(A|O)I$/.test(string.substr(pos - 2, 2))) ? 'S' : null, 'S', /^S|Z$/.test(string.substr(pos + 1, 1)) ? 2 : 1];\n  },\n  TH: function TH(string, pos) {\n    if (/^(O|A)M$/.test(string.substr(pos + 2, 2)) || /^V(A|O)N /.test(string.substr(0, 4)) || string.substr(0, 3) === 'SCH') {\n      return ['T', 'T', 2];\n    }\n\n    return ['0', 'T', 2];\n  },\n  T: function T(string, pos) {\n    if (string.substr(pos, 4) === 'TION' || /^T(IA|CH)$/.test(string.substr(pos, 3))) {\n      return ['X', 'X', 3];\n    }\n\n    if (string.substr(pos, 2) === 'TH' || string.substr(pos, 3) === 'TTH') {\n      return LOOKUPS.TH(string, pos);\n    }\n\n    return ['T', 'T', /^T|D$/.test(string.substr(pos + 1, 1)) ? 2 : 1];\n  },\n  V: function V(string, pos) {\n    return ['F', 'F', string.substr(pos + 1, 1) === 'V' ? 2 : 1];\n  },\n  W: function W(string, pos, lastIndex) {\n    if (string.substr(pos, 2) === 'WR') {\n      return ['R', 'R', 2];\n    }\n\n    var primary = [],\n        secondary = [];\n\n    if (!pos && isVowel(string.substr(pos + 1, 1) || string.substr(pos, 2) === 'WH')) {\n      primary.push('A');\n      secondary.push(isVowel(string.substr(pos + 1, 1)) ? 'F' : 'A');\n    }\n\n    if (pos === lastIndex && isVowel(string.substr(pos - 1, 1)) || string.substr(0, 3) === 'SCH' || /^EWSKI|EWSKY|OWSKI|OWSKY$/.test(string.substr(pos - 1, 5))) {\n      return [primary, secondary.concat('F'), 1];\n    }\n\n    if (/^WI(C|T)Z$/.test(string.substr(pos, 4))) {\n      return [primary.concat(['T', 'S']), secondary.concat(['F', 'X']), 4];\n    }\n\n    return [primary, secondary, 1];\n  },\n  X: function X(string, pos, lastIndex) {\n    if (!pos) {\n      return ['S', 'S', 1];\n    }\n\n    var offset = /^C|X$\"/.test(string.substr(pos + 1, 1)) ? 2 : 1;\n\n    if (pos === lastIndex && /^(I|E)AU$/.test(string.substr(pos - 3, 3)) || /^(A|O)U$/.test(string.substr(pos - 2, 2))) {\n      return [null, null, offset];\n    }\n\n    return [['K', 'S'], ['K', 'S'], offset];\n  },\n  Z: function Z(string, pos) {\n    if (string.substr(pos + 1, 1) === 'H') {\n      return ['J', 'J', 2];\n    }\n\n    var offset = string.substr(pos + 1, 1) === 'Z' ? 2 : 1;\n\n    if (/^Z(O|I|A)$/.test(string.substr(pos + 1, 2)) || pos && isSlavoGermanic(string) && string.substr(pos - 1, 1) === 'T') {\n      return ['S', ['T', 'S'], offset];\n    }\n\n    return ['S', 'S', offset];\n  }\n};\n\n/**\n * Function taking a single word and computing its double metaphone code.\n *\n * @param  {string}  word - The word to process.\n * @return {array}        - The double metaphone codes.\n *\n * @throws {Error} The function expects the word to be a string.\n */\nfunction doubleMetaphone(word) {\n  if (typeof word !== 'string') throw Error('talisman/phonetics/doubleMetaphone: the given word is not a string.');\n\n  // Preparing the word\n  var preparedWord = word.toUpperCase() + '     ';\n\n  // Defining the start position & finding necessary indexes\n  var startPosition = STARTING_REGEX.test(preparedWord.slice(0, 2)) ? 1 : 0,\n      length = word.length,\n      lastIndex = length - 1;\n\n  // Codes\n  var primary = [],\n      secondary = [];\n\n  // Iterating\n  var pos = startPosition;\n\n  while (true) {\n\n    if (pos > length || primary.length >= 4 && secondary.length >= 4) break;\n\n    // Lookup the current letter\n    var letter = preparedWord[pos];\n\n    var offset = 1;\n\n    // Vowel lookup\n    if (isVowel(letter)) {\n      if (!pos) {\n        primary.push('A');\n        secondary.push('A');\n      }\n    }\n\n    // Consonant lookup\n    var method = LOOKUPS[letter];\n\n    if (method) {\n      var _method = method(preparedWord, pos, lastIndex, length),\n          _method$ = _method[0],\n          one = _method$ === undefined ? null : _method$,\n          _method$2 = _method[1],\n          two = _method$2 === undefined ? null : _method$2,\n          _method$3 = _method[2],\n          newOffset = _method$3 === undefined ? 1 : _method$3;\n\n      offset = newOffset;\n\n      if (one) primary = primary.concat(one);\n      if (two) secondary = secondary.concat(two);\n    }\n\n    // Incrementing position\n    pos += offset;\n  }\n\n  return [primary.join('').slice(0, 4), secondary.join('').slice(0, 4)];\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/eudex.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = eudex;\n\nvar _long = require('long');\n\nvar _long2 = _interopRequireDefault(_long);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Maps.\n */\nvar binary = function binary(str) {\n  return typeof str === 'string' ? parseInt(str, 2) : str;\n},\n    charCode = function charCode(char) {\n  return char.charCodeAt(0);\n},\n    charArray = function charArray(str) {\n  return str.split('').map(charCode);\n}; /* eslint no-confusing-arrow: 0 */\n/**\n * Talisman phonetics/eudex\n * =========================\n *\n * JavaScript implementation of the Eudex phonetic hashing algorithm.\n *\n * [Reference]:\n * https://github.com/ticki/eudex\n *\n * [Author]:\n * @ticki (https://github.com/ticki)\n */\n\n\nvar PHONES = ['0', // a\n// +--------- Confident\n// |+-------- Labial\n// ||+------- Liquid\n// |||+------ Dental\n// ||||+----- Plosive\n// |||||+---- Fricative\n// ||||||+--- Nasal\n// |||||||+-- Discriminant\n// ||||||||\n'01001000', // b\n'00001100', // c\n'00011000', // d\n'0', // e\n'01000100', // f\n'00001000', // g\n'00000100', // h\n'1', // i\n'00000101', // j\n'00001001', // k\n'10100000', // l\n'00000010', // m\n'00010010', // n\n'0', // o\n'01001001', // p\n'10101000', // q\n'10100001', // r\n'00010100', // s\n'00011101', // t\n'1', // u\n'01000101', // v\n'00000000', // w\n'10000100', // x\n'1', // y\n'10010100'].map(binary);\n\nvar LETTERS = PHONES.length;\n\nvar PHONES_C1 = [PHONES[charCode('s') - charCode('a')] ^ 1, // ß\n'0', // à\n'0', // á\n'0', // â\n'0', // ã\n'0', // ä [æ]\n'1', // å [oː]\n'0', // æ [æ]\nPHONES[charCode('z') - charCode('a')] ^ 1, // ç [t͡ʃ]\n'1', // è\n'1', // é\n'1', // ê\n'1', // ë\n'1', // ì\n'1', // í\n'1', // î\n'1', // ï\n'00010101', // ð [ð̠] (represented as a non-plosive T)\n'00010111', // ñ [nj] (represented as a combination of n and j)\n'0', // ò\n'0', // ó\n'0', // ô\n'0', // õ\n'1', // ö [ø]\n'1', // ÷\n'1', // ø [ø]\n'1', // ù\n'1', // ú\n'1', // û\n'1', // ü\n'1', // ý\n'00010101', // þ [ð̠] (represented as a non-plosive T)\n'1'].map(binary);\n\nvar INJECTIVE_PHONES = [\n// +--------- Vowel\n// |+-------- Closer than ɜ\n// ||+------- Close\n// |||+------ Front\n// ||||+----- Close-mid\n// |||||+---- Central\n// ||||||+--- Open-mid\n// |||||||+-- Discriminant\n// ||||||||   (*=vowel)\n'10000100', // a*\n'00100100', // b\n'00000110', // c\n'00001100', // d\n'11011000', // e*\n'00100010', // f\n'00000100', // g\n'00000010', // h\n'11111000', // i*\n'00000011', // j\n'00000101', // k\n'01010000', // l\n'00000001', // m\n'00001001', // n\n'10010100', // o*\n'00100101', // p\n'01010100', // q\n'01010001', // r\n'00001010', // s\n'00001110', // t\n'11100000', // u*\n'00100011', // v\n'00000000', // w\n'01000010', // x\n'11100100', // y*\n'01001010'].map(binary);\n\nvar INJECTIVE_PHONES_C1 = [INJECTIVE_PHONES[charCode('s') - charCode('a')] ^ 1, // ß\nINJECTIVE_PHONES[charCode('a') - charCode('a')] ^ 1, // à\nINJECTIVE_PHONES[charCode('a') - charCode('a')] ^ 1, // á\n// +--------- Vowel\n// |+-------- Closer than ɜ\n// ||+------- Close\n// |||+------ Front\n// ||||+----- Close-mid\n// |||||+---- Central\n// ||||||+--- Open-mid\n// |||||||+-- Discriminant\n// ||||||||\n'10000000', // â\n'10000110', // ã\n'10100110', // ä [æ]\n'11000010', // å [oː]\n'10100111', // æ [æ]\n'01010100', // ç [t͡ʃ]\nINJECTIVE_PHONES[charCode('e') - charCode('a')] ^ 1, // è\nINJECTIVE_PHONES[charCode('e') - charCode('a')] ^ 1, // é\nINJECTIVE_PHONES[charCode('e') - charCode('a')] ^ 1, // ê\n'11000110', // ë [ə] or [œ]\nINJECTIVE_PHONES[charCode('i') - charCode('a')] ^ 1, // ì\nINJECTIVE_PHONES[charCode('i') - charCode('a')] ^ 1, // í\nINJECTIVE_PHONES[charCode('i') - charCode('a')] ^ 1, // î\nINJECTIVE_PHONES[charCode('i') - charCode('a')] ^ 1, // ï\n'00001011', // ð [ð̠] (represented as a non-plosive T)\n'00001011', // ñ [nj] (represented as a combination of n and j)\nINJECTIVE_PHONES[charCode('o') - charCode('a')] ^ 1, // ò\nINJECTIVE_PHONES[charCode('o') - charCode('a')] ^ 1, // ó\nINJECTIVE_PHONES[charCode('o') - charCode('a')] ^ 1, // ô\nINJECTIVE_PHONES[charCode('o') - charCode('a')] ^ 1, // õ\n'11011100', // ö [œ] or [ø]\n'1', // ÷\n'11011101', // ø [œ] or [ø]\nINJECTIVE_PHONES[charCode('u') - charCode('a')] ^ 1, // ù\nINJECTIVE_PHONES[charCode('u') - charCode('a')] ^ 1, // ú\nINJECTIVE_PHONES[charCode('u') - charCode('a')] ^ 1, // û\nINJECTIVE_PHONES[charCode('y') - charCode('a')] ^ 1, // ü\nINJECTIVE_PHONES[charCode('y') - charCode('a')] ^ 1, // ý\n'00001011', // þ [ð̠] (represented as a non-plosive T)\nINJECTIVE_PHONES[charCode('y') - charCode('a')] ^ 1].map(binary);\n\n/**\n * Function taking a single word and computing its Eudex hash.\n *\n * @param  {string} word - The word to process.\n * @return {number}      - The Eudex hash.\n */\nvar A = charCode('a'),\n    Z = charCode('z');\n\nfunction eudex(word) {\n  var array = charArray(word);\n\n  var entry = array.length > 0 ? (array[0] | 32) - A & 0xFF : 0;\n\n  var firstByte = 0;\n\n  if (entry < LETTERS) firstByte = INJECTIVE_PHONES[entry];else if (entry >= 0xDF && entry < 0xFF) firstByte = INJECTIVE_PHONES_C1[entry - 0xDF];\n\n  firstByte = new _long2.default(firstByte);\n\n  var res = _long2.default.UZERO,\n      n = 0,\n      b = 1;\n\n  while (n < 8 && b < array.length) {\n    entry = (array[b] | 32) - A & 0xFF;\n\n    if (entry <= Z) {\n      var x = void 0;\n\n      if (entry < LETTERS) x = PHONES[entry];else if (entry >= 0xDF && entry < 0xFF) x = PHONES_C1[entry - 0xDF];else continue;\n\n      if (!res.and(0xFE).equals(x & 0xFE)) {\n        res = res.shiftLeft(8);\n        res = res.or(x);\n        n++;\n      }\n    }\n\n    b++;\n  }\n\n  return res.or(firstByte.shiftLeft(56));\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/fuzzy-soundex.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = fuzzySoundex;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _helpers = require('../helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } } /**\n                                                                                                                                                                                                     * Talisman phonetics/fuzzy-soundex\n                                                                                                                                                                                                     * =================================\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * Implementation of the \"Fuzzy Soundex\" algorithm.\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * [Reference]:\n                                                                                                                                                                                                     * http://wayback.archive.org/web/20100629121128/http://www.ir.iit.edu/publications/downloads/IEEESoundexV5.pdf\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * [Article]:\n                                                                                                                                                                                                     * Holmes, David and M. Catherine McCabe. \"Improving Precision and Recall for\n                                                                                                                                                                                                     * Soundex Retrieval.\"\n                                                                                                                                                                                                     */\n\n\n/**\n * Constants.\n */\nvar TRANSLATION = (0, _helpers.translation)('ABCDEFGHIJKLMNOPQRSTUVWXYZ', '0193017-07745501769301-7-9');\n\nvar SET1 = new Set(['CS', 'CZ', 'TS', 'TZ']),\n    SET2 = new Set(['HR', 'WR']),\n    SET3 = new Set(['KN', 'NG']),\n    SET4 = new Set('HWY');\n\nvar RULES = [[/CA/g, 'KA'], [/CC/g, 'KK'], [/CK/g, 'KK'], [/CE/g, 'SE'], [/CHL/g, 'KL'], [/CL/g, 'KL'], [/CHR/g, 'KR'], [/CR/g, 'KR'], [/CI/g, 'SI'], [/CO/g, 'KO'], [/CU/g, 'KU'], [/CY/g, 'SY'], [/DG/g, 'GG'], [/GH/g, 'HH'], [/MAC/g, 'MK'], [/MC/g, 'MK'], [/NST/g, 'NSS'], [/PF/g, 'FF'], [/PH/g, 'FF'], [/SCH/g, 'SSS'], [/TIO/g, 'SIO'], [/TIA/g, 'SIO'], [/TCH/g, 'CHH']];\n\n/**\n * Function taking a single name and computing its fuzzy Soundex code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The fuzzy Soundex code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction fuzzySoundex(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/fuzzy-soundex: the given name is not a string.');\n\n  if (!name) return '';\n\n  // Deburring the string & dropping any non-alphabetical character\n  name = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z]/g, '');\n\n  // Applying some substitutions for beginnings\n  var firstTwoLetters = name.slice(0, 2),\n      rest = name.slice(2);\n\n  if (SET1.has(firstTwoLetters)) name = 'SS' + rest;else if (firstTwoLetters === 'GN') name = 'NN' + rest;else if (SET2.has(firstTwoLetters)) name = 'RR' + rest;else if (firstTwoLetters === 'HW') name = 'WW' + rest;else if (SET3.has(firstTwoLetters)) name = 'NN' + rest;\n\n  // Applying some substitutions for endings\n  var lastTwoLetters = name.slice(-2),\n      initial = name.slice(0, -2);\n\n  if (lastTwoLetters === 'CH') name = initial + 'KK';else if (lastTwoLetters === 'NT') name = initial + 'TT';else if (lastTwoLetters === 'RT') name = initial + 'RR';else if (name.slice(-3) === 'RDT') name = name.slice(0, -3) + 'RR';\n\n  // Applying the rules\n  for (var i = 0, l = RULES.length; i < l; i++) {\n    var _name;\n\n    name = (_name = name).replace.apply(_name, _toConsumableArray(RULES[i]));\n  } // Caching the first letter\n  var firstLetter = name[0];\n\n  // Translating\n  var code = '';\n  for (var _i = 0, _l = name.length; _i < _l; _i++) {\n    code += TRANSLATION[name[_i]] || name[_i];\n  } // Removing hyphens\n  code = code.replace(/-/g, '');\n\n  // Squeezing the code\n  code = (0, _helpers.squeeze)(code);\n\n  // Dealing with some initials\n  if (SET4.has(code[0])) code = firstLetter + code;else code = firstLetter + code.slice(1);\n\n  // Dropping vowels\n  code = code.replace(/0/g, '');\n\n  return code;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/lein.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = lein;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _helpers = require('../helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\n/**\n * Talisman phonetics/lein\n * ========================\n *\n * The Lein name coding procedure.\n *\n * [Reference]:\n * http://naldc.nal.usda.gov/download/27833/PDF\n */\nvar DROPPED = /[AEIOUYWH]/g;\n\nvar TRANSLATION = (0, _helpers.translation)('DTMNLRBFPVCJKGQSXZ', '112233444455555555');\n\n/**\n * Helpers.\n */\nfunction pad(code) {\n  return (code + '0000').slice(0, 4);\n}\n\n/**\n * Function taking a single name and computing its lein code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The lein code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction lein(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/lein: the given name is not a string.');\n\n  var code = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z\\s]/g, '');\n\n  // 1-- Keeping the first letter\n  var first = code[0];\n  code = code.slice(1);\n\n  // 2-- Dropping vowels and Y, W & H\n  code = code.replace(DROPPED, '');\n\n  // 3-- Dropping consecutive duplicates and truncating to 4 characters\n  code = (0, _helpers.squeeze)(code).slice(0, 4);\n\n  // 4-- Translations\n  var backup = code;\n  code = '';\n\n  for (var i = 0, l = backup.length; i < l; i++) {\n    code += TRANSLATION[backup[i]] || backup[i];\n  }return pad(first + code);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/metaphone.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = metaphone;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Series of rules to apply.\n */\nvar RULES = [[/([bcdfhjklmnpqrstvwxyz])\\1+/g, '$1'], [/^ae/g, 'E'], [/^[gkp]n/g, 'N'], [/^wr/g, 'R'], [/^x/g, 'S'], [/^wh/g, 'W'], [/mb$/g, 'M'], [/(?!^)sch/g, 'SK'], [/th/g, '0'], [/t?ch|sh/g, 'X'], [/c(?=ia)/g, 'X'], [/[st](?=i[ao])/g, 'X'], [/s?c(?=[iey])/g, 'S'], [/[cq]/g, 'K'], [/dg(?=[iey])/g, 'J'], [/d/g, 'T'], [/g(?=h[^aeiou])/g, ''], [/gn(ed)?/g, 'N'], [/([^g]|^)g(?=[iey])/g, '$1J'], [/g+/g, 'K'], [/ph/g, 'F'], [/([aeiou])h(?=\\b|[^aeiou])/g, '$1'], [/[wy](?![aeiou])/g, ''], [/z/g, 'S'], [/v/g, 'F'], [/(?!^)[aeiou]+/g, '']];\n\n/**\n * Function taking a single word and computing its metaphone code.\n *\n * @param  {string}  word - The word to process.\n * @return {string}       - The metaphone code.\n *\n * @throws {Error} The function expects the word to be a string.\n */\n/**\n * Talisman phonetics/metaphone\n * =============================\n *\n * The metaphone algorithm.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Metaphone\n *\n * [Author]:\n * Lawrence Philips, 1990\n */\nfunction metaphone(word) {\n  if (typeof word !== 'string') throw Error('talisman/phonetics/metaphone: the given word is not a string.');\n\n  // Deburring the string & dropping any non-alphabetical character\n  var code = (0, _deburr2.default)(word).toLowerCase().replace(/[^a-z]/g, '');\n\n  // Applying the rules\n  for (var i = 0, l = RULES.length; i < l; i++) {\n    code = code.replace(RULES[i][0], RULES[i][1]);\n  }return code.toUpperCase();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/mra.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = mra;\n\nvar _helpers = require('../helpers');\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Function taking a single name and computing its MRA codex.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The MRA codex.\n *\n * @throws {Error} The function expects the name to be a string.\n */\n/**\n * Talisman phonetics/mra\n * =======================\n *\n * Functions related to the computation of the Match Rating Approach codex.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Match_rating_approach\n *\n * [Article]:\n * Moore, G B.; Kuhns, J L.; Treffzs, J L.; Montgomery, C A. (Feb 1, 1977).\n * Accessing Individual Records from Personal Data Files Using Nonunique\n * Identifiers.\n * US National Institute of Standards and Technology. p. 17. NIST SP - 500-2.\n */\nfunction mra(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/mra: the given name is not a string.');\n\n  // Preparing the name\n  var codex = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z]/g, '');\n\n  // Dropping non-leading vowels\n  codex = codex.charAt(0) + codex.slice(1).replace(/[AEIOU]/g, '');\n\n  // Dropping consecutive consonants\n  codex = (0, _helpers.squeeze)(codex);\n\n  // Returning the codex\n  var offset = Math.min(3, codex.length - 3);\n\n  return codex.slice(0, 3) + codex.substr(codex.length - offset, offset);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/nysiis.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.refined = exports.original = undefined;\n\nvar _helpers = require('../helpers');\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Patterns.\n */\n/**\n * Talisman phonetics/nysiis\n * ==========================\n *\n * The nysiis algorithm, original & refined.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/New_York_State_Identification_and_Intelligence_System\n */\nvar PATTERNS = {\n  original: {\n    first: [[/JR$/g, ''], [/SR$/g, ''], [/^MAC/g, 'MCC'], [/^KN/g, 'NN'], [/^K/g, 'C'], [/^(PH|PF)/g, 'FF'], [/^SCH/g, 'SSS'], [/(EE|IE)$/g, 'Y'], [/(DT|RT|RD|NT|ND)$/g, 'D']],\n    second: [[/EV/g, 'AF'], [/[EIOU]/g, 'A'], [/Q/g, 'G'], [/Z/g, 'S'], [/(M|KN)/g, 'N'], [/K/g, 'C'], [/SCH/g, 'SSS'], [/PH/g, 'FF'], [/([^A])H/g, '$1'], [/(.)H[^A]/g, '$1'], [/AW/g, 'A'], [/S$/g, ''], [/AY$/g, 'Y'], [/A$/g, '']]\n  },\n  refined: {\n    first: [[/JR$/g, ''], [/SR$/g, ''], [/(S|Z)$/g, ''], [/MAC/g, 'MC'], [/PH/g, 'F'], [/IX$/g, 'IC'], [/EX$/g, 'EC'], [/(YE|EE|IE)/g, 'Y'], [/(DT|RT|RD|NT|ND)$/g, 'D'], [/(.+)EV/g, '$1EF']],\n    second: [[/([AEIOU]+)W/g, '$1'], [/[EIOU]/g, 'A'], [/AA+/g, 'A'], [/GHT/g, 'GT'], [/DG/g, 'G'], [/PH/g, 'F'], [/(.+)HA/g, '$1A'], [/A+H/g, 'A'], [/KN/g, 'N'], [/K/g, 'C'], [/(.+)M/g, '$1N'], [/(.+)Q/g, '$1G'], [/(SH|SCH)/g, 'S'], [/YW/g, 'Y'], [/(.+)Y(.+)/g, '$1A$2'], [/WR/g, 'R'], [/(.+)Z/g, '$1S'], [/AY$/g, 'Y'], [/A+$/g, ''], [/^\\w/g, '']]\n  }\n};\n\n/**\n * Function taking a single name and computing its NYSIIS code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The NYSIIS code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction nysiis(type, name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/nysiis: the given name is not a string.');\n\n  // Preparing the string\n  name = (0, _deburr2.default)(name).toUpperCase().trim().replace(/[^A-Z]/g, '');\n\n  // Getting the proper patterns\n  var patterns = PATTERNS[type];\n\n  // Applying the first substitutions\n  for (var i = 0, l = patterns.first.length; i < l; i++) {\n    var _patterns$first$i = patterns.first[i],\n        match = _patterns$first$i[0],\n        replacement = _patterns$first$i[1];\n\n\n    name = name.replace(match, replacement);\n  }\n\n  // Storing the first letter\n  var firstLetter = name.charAt(0);\n\n  // Eating the first letter if applying the original algorithm\n  if (type === 'original') name = name.slice(1);\n\n  // Applying the second substitutions\n  for (var _i = 0, _l = patterns.second.length; _i < _l; _i++) {\n    var _patterns$second$_i = patterns.second[_i],\n        match = _patterns$second$_i[0],\n        replacement = _patterns$second$_i[1];\n\n\n    name = name.replace(match, replacement);\n  }\n\n  // Returning the squeezed code\n  return firstLetter + (0, _helpers.squeeze)(name);\n}\n\n/**\n * Exporting functions.\n */\nvar original = nysiis.bind(null, 'original'),\n    refined = nysiis.bind(null, 'refined');\n\nexports.default = original;\nexports.original = original;\nexports.refined = refined;\nmodule.exports = exports['default'];\nexports['default'].original = exports.original;\nexports['default'].refined = exports.refined;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/onca.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = onca;\n\nvar _soundex = require('./soundex');\n\nvar _soundex2 = _interopRequireDefault(_soundex);\n\nvar _nysiis = require('./nysiis');\n\nvar _nysiis2 = _interopRequireDefault(_nysiis);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Function taking a single name and computing its ONCA code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The ONCA code.\n */\n/**\n * Talisman phonetics/onca\n * ========================\n *\n * The Oxford Name Compression Algorithm. This is basically a glorified\n * NYSIIS + Soundex combination.\n */\nfunction onca(name) {\n  return (0, _soundex2.default)((0, _nysiis2.default)(name));\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/soundex.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.default = soundex;\nexports.refined = refined;\n\nvar _helpers = require('../helpers');\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Translations.\n */\n/**\n * Talisman phonetics/soundex\n * ===========================\n *\n * The Soundex algorithm.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Soundex\n *\n * [Authors]:\n * Robert C. Russel\n * Margaret King Odell\n */\nvar TRANSLATIONS = (0, _helpers.translation)('AEIOUYWHBPFVCSKGJQXZDTLMNR', '000000DD111122222222334556');\n\nvar REFINED_TRANSLATIONS = (0, _helpers.translation)('AEIOUYWHBPFVCKSGJQXZDTLMNR', '000000DD112233344555667889');\n\n/**\n * Helpers.\n */\nfunction pad(code) {\n  return (code + '0000').slice(0, 4);\n}\n\n/**\n * Function taking a single name and computing its Soundex code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The Soundex code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction soundex(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/soundex: the given name is not a string.');\n\n  name = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z]/g, '');\n\n  var firstLetter = name.charAt(0);\n\n  // Process the code for the name's tail\n  var tail = '';\n\n  for (var i = 1, l = name.length; i < l; i++) {\n    if (TRANSLATIONS[name[i]] !== 'D') tail += TRANSLATIONS[name[i]];\n  }\n\n  // Dropping first code's letter if duplicate\n  if (tail.charAt(0) === TRANSLATIONS[firstLetter]) tail = tail.slice(1);\n\n  // Composing the code from the tail\n  var code = (0, _helpers.squeeze)(tail).replace(/0/g, '');\n\n  return pad(firstLetter + code);\n}\n\n/**\n * Function taking a single name and computing its refined Soundex code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The refined Soundex code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction refined(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/soundex#refined: the given name is not a string.');\n\n  name = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z]/g, '');\n\n  var firstLetter = name.charAt(0);\n\n  // Process the code for the name's tail\n  var tail = '';\n\n  for (var i = 0, l = name.length; i < l; i++) {\n    if (REFINED_TRANSLATIONS[name[i]] !== 'D') tail += REFINED_TRANSLATIONS[name[i]];\n  }\n\n  // Composing the code from the tail\n  var code = (0, _helpers.squeeze)(tail);\n\n  return firstLetter + code;\n}\nmodule.exports = exports['default'];\nexports['default'].refined = exports.refined;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/phonex.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = phonex;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\nvar INITIALS = [['AEIOUY', 'A'], ['BP', 'B'], ['VF', 'F'], ['KQC', 'C'], ['JG', 'G'], ['ZS', 'S']]; /**\n                                                                                                     * Talisman phonetics/phonex\n                                                                                                     * ==========================\n                                                                                                     *\n                                                                                                     * Implementation of the \"Phonex\" algorithm.\n                                                                                                     *\n                                                                                                     * [Reference]:\n                                                                                                     * http://homepages.cs.ncl.ac.uk/brian.randell/Genealogy/NameMatching.pdf\n                                                                                                     *\n                                                                                                     * [Article]:\n                                                                                                     * Lait, A. J. and B. Randell. \"An Assessment of Name Matching Algorithms\".\n                                                                                                     */\n\n\nINITIALS.forEach(function (rule) {\n  return rule[0] = new Set(rule[0]);\n});\n\nvar B_SET = new Set('BPFV'),\n    C_SET = new Set('CSKGJQXZ'),\n    VOWELS_SET = new Set('AEIOUY');\n\n/**\n * Function taking a single name and computing its Phonex code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The Phonex code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction phonex(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/phonex: the given name is not a string.');\n\n  if (!name) return '';\n\n  // Deburring the string & dropping any non-alphabetical character\n  name = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z]/g, '');\n\n  // Removing trailing S\n  name = name.replace(/S+$/, '');\n\n  // Substitution of some initials\n  var firstTwoLetter = name.slice(0, 2),\n      rest = name.slice(2);\n\n  if (firstTwoLetter === 'KN') name = 'N' + rest;else if (firstTwoLetter === 'PH') name = 'F' + rest;else if (firstTwoLetter === 'WR') name = 'R' + rest;\n\n  // Ignoring first H if present\n  if (name[0] === 'H') name = name.slice(1);\n\n  // Encoding first character\n  for (var i = 0, l = INITIALS.length; i < l; i++) {\n    var _INITIALS$i = INITIALS[i],\n        letters = _INITIALS$i[0],\n        replacement = _INITIALS$i[1];\n\n\n    if (letters.has(name[0])) {\n      name = replacement + name.slice(1);\n      break;\n    }\n  }\n\n  var code = name[0],\n      last = code;\n\n  for (var _i = 1, _l = name.length; _i < _l; _i++) {\n    var letter = name[_i],\n        nextLetter = name[_i + 1];\n\n    var encoding = '0';\n\n    if (B_SET.has(letter)) {\n      encoding = '1';\n    } else if (C_SET.has(letter)) {\n      encoding = '2';\n    } else if (letter === 'D' || letter === 'T') {\n      if (nextLetter !== 'C') encoding = '3';\n    } else if (letter === 'L') {\n      if (VOWELS_SET.has(nextLetter) || _i + 1 === _l) encoding = '4';\n    } else if (letter === 'M' || letter === 'N') {\n      if (nextLetter === 'D' || nextLetter === 'G') name = name.slice(0, _i + 1) + letter + name.slice(_i + 2);\n      encoding = '5';\n    } else if (letter === 'R') {\n      if (VOWELS_SET.has(nextLetter) || _i + 1 === _l) encoding = '6';\n    }\n\n    if (encoding !== last && encoding !== '0') code += encoding;\n\n    last = code.slice(-1);\n  }\n\n  return code;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/roger-root.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = rogerRoot;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _helpers = require('../helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\n/**\n * Talisman phonetics/roger-root\n * ==============================\n *\n * The Roger Root name coding procedure.\n *\n * [Reference]:\n * http://naldc.nal.usda.gov/download/27833/PDF\n */\nvar FIRST_LETTER_ENCODING = {\n  A: '1',\n  B: '09',\n  C: [['CE', '00'], ['CH', '06'], ['CI', '00'], ['CY', '00'], ['C', '07']],\n  D: [['DG', '07'], ['D', '01']],\n  E: '1',\n  F: '08',\n  G: [['GF', '08'], ['GM', '03'], ['GN', '02'], ['G', '07']],\n  H: '2',\n  I: '1',\n  J: '3',\n  K: [['KN', '02'], ['K', '07']],\n  L: '05',\n  M: '03',\n  N: '02',\n  O: '1',\n  P: [['PF', '08'], ['PH', '08'], ['PN', '02'], ['P', '09']],\n  Q: '07',\n  R: '04',\n  S: [['SCH', '06'], ['SH', '06'], ['S', '00']],\n  T: [['TSCH', '06'], ['TSH', '06'], ['TS', '00'], ['T', '01']],\n  U: '1',\n  V: '08',\n  W: [['WR', '04'], ['W', '4']],\n  X: '07',\n  Y: '5',\n  Z: '00'\n};\n\nvar ENCODING = {\n  B: '9',\n  C: [['CE', '0'], ['CH', '6'], ['CI', '0'], ['CY', '0'], ['C', '7']],\n  D: [['DG', '7'], ['D', '1']],\n  F: '8',\n  G: '7',\n  J: '6',\n  K: '7',\n  L: '5',\n  M: '3',\n  N: '2',\n  P: [['PH', '8'], ['P', '9']],\n  Q: '7',\n  R: '4',\n  S: [['SCH', '6'], ['SH', '6'], ['S', '0']],\n  T: [['TSCH', '6'], ['TSH', '6'], ['TS', '0'], ['T', '1']],\n  V: '8',\n  X: '7',\n  Z: '0'\n};\n\n/**\n * Helpers.\n */\nfunction pad(code) {\n  return (code + '00000').slice(0, 5);\n}\n\n/**\n * Function taking a single name and computing its roger root code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The roger root code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction rogerRoot(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/rogerRoot: the given name is not a string.');\n\n  name = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z]/g, '');\n\n  var code = '',\n      encodedFirstLetter = void 0;\n\n  for (var i = 0, l = name.length; i < l; i++) {\n    var firstIteration = !i,\n        encoding = firstIteration ? FIRST_LETTER_ENCODING : ENCODING,\n        rules = encoding[name[i]];\n\n    if (rules) {\n      if (typeof rules === 'string') {\n        code += rules;\n      } else {\n\n        for (var j = 0, m = rules.length; j < m; j++) {\n          var _rules$j = rules[j],\n              match = _rules$j[0],\n              replacement = _rules$j[1];\n\n\n          if (name.substr(i, match.length) === match) {\n            code += replacement;\n            i += match.length - 1;\n            break;\n          }\n        }\n      }\n    } else {\n      code += '-';\n    }\n\n    if (firstIteration) encodedFirstLetter = code;\n  }\n\n  // Squeezing the code\n  code = encodedFirstLetter + (0, _helpers.squeeze)(code.slice(encodedFirstLetter.length));\n\n  return pad(code.replace(/-/g, ''));\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/statcan.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = statcan;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _helpers = require('../helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\n/**\n * Talisman phonetics/statcan\n * ===========================\n *\n * The statistics Canada name coding technique.\n *\n * [Reference]:\n * http://naldc.nal.usda.gov/download/27833/PDF\n */\nvar DROPPED = /[AEIOUY]/g;\n\n/**\n * Function taking a single name and computing its statcan code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The statcan code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction statcan(name) {\n\n  if (typeof name !== 'string') throw Error('talisman/phonetics/statcan: the given name is not a string.');\n\n  var code = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z\\s]/g, '');\n\n  // 1-- Keeping the first letter\n  var first = code[0];\n  code = code.slice(1);\n\n  // 2-- Dropping vowels and Y\n  code = code.replace(DROPPED, '');\n\n  // 3-- Dropping consecutive duplicates\n  code = (0, _helpers.squeeze)(code);\n\n  // 4-- Dropping blanks\n  code = code.replace(/\\s/g, '');\n\n  // 5-- Limiting code size to 4\n  return (first + code).slice(0, 4);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stats/descriptive.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\nexports.sum = sum;\nexports.mean = mean;\nexports.addToMean = addToMean;\nexports.substractFromMean = substractFromMean;\nexports.combineMeans = combineMeans;\nexports.mode = mode;\nexports.quantile = quantile;\nexports.median = median;\nexports.variance = variance;\nexports.stdev = stdev;\nexports.combineVariances = combineVariances;\n/**\n * Talisman stats/descriptive\n * ===========================\n *\n * The library's descriptive stats helpers.\n */\n\n/**\n * Function computing the sum of the given sequence, while correcting floating\n * point errors.\n *\n * @param  {array}  sequence - The sequence to process.\n * @return {number}          - The sum.\n */\nfunction sum(sequence) {\n  var compensation = 0,\n      s = 0;\n\n  for (var i = 0, l = sequence.length; i < l; i++) {\n    var correctedValue = sequence[i] - compensation,\n        next = s + correctedValue;\n\n    compensation = next - s - correctedValue;\n\n    s = next;\n  }\n\n  return s;\n}\n\n/**\n * Function computing the mean of the given sequence.\n *\n * @param  {array}  sequence - The sequence to process.\n * @return {number}          - The mean.\n *\n * @throws {Error} - The function expects a non-empty list.\n */\nfunction mean(sequence) {\n  var length = sequence.length;\n\n  if (!length) throw Error('talisman/stats/descriptive#mean: the given list is empty.');\n\n  return sum(sequence) / length;\n}\n\n/**\n * Function adding a value to the given mean in constant time.\n *\n * @param  {number}  previousMean - The mean to adjust.\n * @param  {number}  nbValues     - The number of values in the given mean.\n * @param  {number}  value        - The value to add.\n * @return {number}               - The mean.\n */\nfunction addToMean(previousMean, nbValues, value) {\n  return previousMean + (value - previousMean) / (nbValues + 1);\n}\n\n/**\n * Function substracting a value from the given mean in constant time.\n *\n * @param  {number}  previousMean - The mean to adjust.\n * @param  {number}  nbValues     - The number of values in the given mean.\n * @param  {number}  value        - The value to substract.\n * @return {number}               - The mean.\n */\nfunction substractFromMean(previousMean, nbValues, value) {\n  return (previousMean * nbValues - value) / (nbValues - 1);\n}\n\n/**\n * Function combining two means into one in constant time.\n *\n * @param  {number} ma - The first mean.\n * @param  {number} na - Number of values for a.\n * @param  {number} mb - The second mean.\n * @param  {number} nb - Number of values for b.\n * @return {number}    - The new mean.\n */\nfunction combineMeans(ma, na, mb, nb) {\n  return (ma * na + mb * nb) / (na + nb);\n}\n\n/**\n * Function finding the mode of the given sequence.\n *\n * Note: If there are more than one mode, will return the first one seen.\n *\n * @param  {array}  sequence - The sequence to process.\n * @return {number}          - The sequence's mode.\n *\n * @throws {Error} - The function expects a non-empty list.\n */\nfunction mode(sequence) {\n  if (!sequence.length) throw Error('talisman/stats/descriptive#modeSorted: the given list is empty.');\n\n  // Shortcut\n  if (sequence.length === 1) return sequence[0];\n\n  var currentMode = null,\n      max = 0;\n\n  var frequencies = {};\n\n  for (var i = 0, l = sequence.length; i < l; i++) {\n    var number = sequence[i];\n\n    frequencies[number] = frequencies[number] || 0;\n    var frequency = ++frequencies[number];\n\n    if (frequency > max) {\n      max = frequency;\n      currentMode = number;\n    }\n  }\n\n  return currentMode;\n}\n\n/**\n * Function computing quantile.\n *\n * @param  {number|object} p        - Desired quantile or options.\n * @param  {array}         sequence - The sequence to process.\n * @return {number}\n */\nvar QUANTILE_DEFAULTS = {\n  interpolation: mean\n};\n\nfunction quantile(options, sequence) {\n  var interpolation = QUANTILE_DEFAULTS.interpolation,\n      p = void 0;\n\n  if ((typeof options === 'undefined' ? 'undefined' : _typeof(options)) === 'object') {\n    p = options.p;\n    interpolation = options.interpolation || interpolation;\n  } else {\n    p = options;\n  }\n\n  // Validation\n  if (typeof interpolation !== 'function') throw Error('talisman/stats/descriptive#quantile: expecting a function for the \"interpolation\" option.');\n\n  if (typeof p !== 'number' || p < 0 || p > 1) throw Error('talisman/stats/descriptive#quantile: p should be a number between 0 and 1.');\n\n  // First we need to sort the sequence\n  var sorted = sequence.slice().sort(function (a, b) {\n    return a - b;\n  }),\n      length = sorted.length;\n\n  // Simple cases\n  if (p === 0) return sorted[0];\n  if (p === 1) return sorted[length - 1];\n\n  // Computing the index\n  var index = length * p - 1;\n\n  // If the index is an integer, we need to interpolate\n  if (index === (index | 0)) {\n    return interpolation([sorted[index], sorted[index + 1]]);\n  }\n\n  index = Math.ceil(index);\n  return sorted[index];\n}\n\n/**\n * Function computing the median of the given sequence.\n *\n * @param  {array}  sequence - The sequence to process.\n * @return {number}\n */\nfunction median(sequence) {\n  return quantile(0.5, sequence);\n}\n\n/**\n * Function computing the variance of the given sequence.\n *\n * @param  {array}  sequence - The sequence to process.\n * @return {number}          - The variance.\n *\n * @throws {Error} - The function expects a non-empty list.\n */\nfunction variance(sequence) {\n  var length = sequence.length;\n\n  if (!length) throw Error('talisman/stats/descriptive#variance: the given list is empty.');\n\n  var m = mean(sequence);\n\n  var s = 0;\n\n  for (var i = 0; i < length; i++) {\n    s += Math.pow(sequence[i] - m, 2);\n  }return s / length;\n}\n\n/**\n * Function computing the standard deviation of the given sequence.\n *\n * @param  {array}  sequence - The sequence to process.\n * @return {number}          - The standard deviation.\n *\n * @throws {Error} - The function expects a non-empty list.\n */\nfunction stdev(sequence) {\n  var v = variance(sequence);\n\n  return Math.sqrt(v);\n}\n\n/**\n * Function combining two variances into one in constant time.\n *\n * @param  {number} ma - The first mean.\n * @param  {number} va - The first variance.\n * @param  {number} na - Number of values for a.\n * @param  {number} mb - The second mean.\n * @param  {number} vb - The second variance.\n * @param  {number} nb - Number of values for b.\n * @return {number}    - The new mean.\n */\nfunction combineVariances(ma, va, na, mb, vb, nb) {\n  var combinedMean = combineMeans(ma, na, mb, nb);\n\n  return (na * (va + Math.pow(ma - combinedMean, 2)) + nb * (vb + Math.pow(mb - combinedMean, 2))) / (na + nb);\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stats/frequencies.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.relative = exports.absolute = undefined;\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; /**\n                                                                                                                                                                                                                                                                               * Talisman stats/frequencies\n                                                                                                                                                                                                                                                                               * ===========================\n                                                                                                                                                                                                                                                                               *\n                                                                                                                                                                                                                                                                               * Functions related to sequences' frequencies.\n                                                                                                                                                                                                                                                                               */\n\n\nexports.updateFrequencies = updateFrequencies;\n\nvar _helpers = require('../helpers');\n\n/**\n * Function taking a sequence and computing its frequencies.\n *\n * @param  {mixed}  sequence - The sequence to process.\n * @return {object}          - A dict of the sequence's frequencies.\n *\n * @example\n *   // frequencies([1, 1, 2, 3, 3, 3]) => {1: 2, 2: 1, 3: 3}\n *   // frequencies('test') => {t: 2, e: 1, s: 1}\n */\nfunction frequencies(sequence) {\n  var index = {};\n\n  // Handling strings\n  sequence = (0, _helpers.seq)(sequence);\n\n  for (var i = 0, l = sequence.length; i < l; i++) {\n    var element = sequence[i];\n\n    if (!index[element]) index[element] = 0;\n    index[element]++;\n  }\n\n  return index;\n}\n\n/**\n * Relative version of the `frequencies` function.\n *\n * @param  {mixed}  sequence - The sequence to process. If an object is passed\n *                             the function will assume it's representing\n *                             absolute frequencies.\n * @return {object}          - A dict of the sequence's relative frequencies.\n *\n * @example\n *   // frequencies([1, 1, 2, 3, 3, 3]) => {1: ~0.33, 2: ~0.16, 3: 0.5}\n *   // frequencies('test') => {t: 0.5, e: 0.25, s: 0.25}\n */\nfunction relativeFrequencies(sequence) {\n  var index = void 0,\n      length = void 0;\n\n  // Handling the object polymorphism\n  if ((typeof sequence === 'undefined' ? 'undefined' : _typeof(sequence)) === 'object' && !Array.isArray(sequence)) {\n    index = sequence;\n    length = 0;\n\n    for (var k in index) {\n      length += index[k];\n    }\n  } else {\n    length = sequence.length;\n    index = frequencies(sequence);\n  }\n\n  var relativeIndex = {};\n\n  for (var _k in index) {\n    relativeIndex[_k] = index[_k] / length;\n  }return relativeIndex;\n}\n\n/**\n * Function taking frequencies and updating them with a new sequence.\n *\n * @param  {object} previousFrequencies  - The frequencies to update.\n * @param  {mixed}  sequence             - The added sequence.\n * @return {object}                      - The updated frequencies.\n */\nfunction updateFrequencies(previousFrequencies, sequence) {\n  sequence = (0, _helpers.seq)(sequence);\n\n  var newFrequencies = frequencies(sequence);\n\n  // Merging frequencies\n  for (var k in previousFrequencies) {\n    newFrequencies[k] = (newFrequencies[k] || 0) + previousFrequencies[k];\n  }return newFrequencies;\n}\n\n/**\n * Exporting\n */\nexports.default = frequencies;\nexports.absolute = frequencies;\nexports.relative = relativeFrequencies;\nmodule.exports = exports['default'];\nexports['default'].updateFrequencies = exports.updateFrequencies;\nexports['default'].absolute = exports.absolute;\nexports['default'].relative = exports.relative;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stats/inferential.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.sampleStdev = exports.sampleVariance = exports.stdev = exports.variance = undefined;\nexports.sampleCovariance = sampleCovariance;\nexports.sampleCorrelation = sampleCorrelation;\n\nvar _descriptive = require('./descriptive');\n\n/**\n * Function computing the sample variance of the given sequence.\n *\n * @param  {number}  ddof     - Delta degrees of freedom.\n * @param  {array}   sequence - The sequence to process.\n * @return {number}           - The variance.\n *\n * @throws {Error} - The function expects a non-empty list.\n */\nfunction genericVariance(ddof, sequence) {\n  var length = sequence.length;\n\n  if (!length) throw Error('talisman/stats/inferential#variance: the given list is empty.');\n\n  // Returning 0 if the denominator would be <= 0\n  var denominator = length - ddof;\n\n  if (denominator <= 0) return 0;\n\n  var m = (0, _descriptive.mean)(sequence);\n\n  var s = 0;\n\n  for (var i = 0; i < length; i++) {\n    s += Math.pow(sequence[i] - m, 2);\n  }return s / denominator;\n}\n\n/**\n * Function computing the sample standard deviation of the given sequence.\n *\n * @param  {number}  ddof     - Delta degrees of freedom.\n * @param  {array}   sequence - The sequence to process.\n * @return {number}           - The variance.\n *\n * @throws {Error} - The function expects a non-empty list.\n */\n/**\n * Talisman stats/inferential\n * ===========================\n *\n * The library's inferential stats helpers.\n */\nfunction genericStdev(ddof, sequence) {\n  var v = genericVariance(ddof, sequence);\n\n  return Math.sqrt(v);\n}\n\n/**\n * Exporting convenient methods.\n */\nvar sampleVariance = genericVariance.bind(null, 1),\n    sampleStdev = genericStdev.bind(null, 1);\n\n/**\n * Function computing the sample covariance.\n *\n * @param  {array}  x - First sequence.\n * @param  {array}  y - Second sequence.\n * @return {number}   - The sample covariance.\n *\n * @throws {Error} - The function expects two equal-length lists.\n * @throws {Error} - The function expects lists containing more than one item.\n */\nfunction sampleCovariance(x, y) {\n  if (x.length !== y.length) throw Error('talisman/stats/inferential#sampleCovariance: this function expects two sequences of same size.');\n\n  if (x.length <= 1) throw Error('talisman/stats/inferential#sampleCovariance: the given lists should contain more than one item.');\n\n  var xMean = (0, _descriptive.mean)(x),\n      yMean = (0, _descriptive.mean)(y),\n      n = x.length;\n\n  var sum = 0;\n\n  for (var i = 0; i < n; i++) {\n    sum += (x[i] - xMean) * (y[i] - yMean);\n  }return sum / (n - 1);\n}\n\n/**\n * Function computing the sample correlation coefficient.\n *\n * @param  {array}  x - First sequence.\n * @param  {array}  y - Second sequence.\n * @return {number}   - The sample correlation coefficient.\n */\nfunction sampleCorrelation(x, y) {\n  var covariance = sampleCovariance(x, y);\n\n  return covariance / (sampleStdev(x) * sampleStdev(y));\n}\n\nexports.variance = genericVariance;\nexports.stdev = genericStdev;\nexports.sampleVariance = sampleVariance;\nexports.sampleStdev = sampleStdev;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/lancaster.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = lancaster;\n/**\n * Talisman stemmers/lancaster\n * ============================\n *\n * The Lancaster stemmer.\n *\n * [Article]:\n * A word stemmer based on the Lancaster stemming algorithm.\n * Paice, Chris D. \"Another Stemmer.\" ACM SIGIR Forum 24.3 (1990): 56-61.\n */\n\n/**\n * Rules of the stemmer.\n */\nvar INTACT = 'INTACT',\n    CONTINUE = 'CONTINUE',\n    STOP = 'STOP',\n    PROTECT = 'PROTECT';\n\nvar RULES = {\n  a: [['ia', '', INTACT], ['a', '', INTACT]],\n  b: [['bb', 'b', STOP]],\n  c: [['ytic', 'ys', STOP], ['ic', '', CONTINUE], ['nc', 'nt', CONTINUE]],\n  d: [['dd', 'd', STOP], ['ied', 'y', CONTINUE], ['ceed', 'cess', STOP], ['eed', 'ee', STOP], ['ed', '', CONTINUE], ['hood', '', CONTINUE]],\n  e: [['e', '', CONTINUE]],\n  f: [['lief', 'liev', STOP], ['if', '', CONTINUE]],\n  g: [['ing', '', CONTINUE], ['iag', 'y', STOP], ['ag', '', CONTINUE], ['gg', 'g', STOP]],\n  h: [['th', '', INTACT], ['guish', 'ct', STOP], ['ish', '', CONTINUE]],\n  i: [['i', '', INTACT], ['i', 'y', CONTINUE]],\n  j: [['ij', 'id', STOP], ['fuj', 'fus', STOP], ['uj', 'ud', STOP], ['oj', 'od', STOP], ['hej', 'her', STOP], ['verj', 'vert', STOP], ['misj', 'mit', STOP], ['nj', 'nd', STOP], ['j', 's', STOP]],\n  l: [['ifiabl', '', STOP], ['iabl', 'y', STOP], ['abl', '', CONTINUE], ['ibl', '', STOP], ['bil', 'bl', CONTINUE], ['cl', 'c', STOP], ['iful', 'y', STOP], ['ful', '', CONTINUE], ['ul', '', STOP], ['ial', '', CONTINUE], ['ual', '', CONTINUE], ['al', '', CONTINUE], ['ll', 'l', STOP]],\n  m: [['ium', '', STOP], ['um', '', INTACT], ['ism', '', CONTINUE], ['mm', 'm', STOP]],\n  n: [['sion', 'j', CONTINUE], ['xion', 'ct', STOP], ['ion', '', CONTINUE], ['ian', '', CONTINUE], ['an', '', CONTINUE], ['een', '', PROTECT], ['en', '', CONTINUE], ['nn', 'n', STOP]],\n  p: [['ship', '', CONTINUE], ['pp', 'p', STOP]],\n  r: [['er', '', CONTINUE], ['ear', '', PROTECT], ['ar', '', STOP], ['ior', '', CONTINUE], ['or', '', CONTINUE], ['ur', '', CONTINUE], ['rr', 'r', STOP], ['tr', 't', CONTINUE], ['ier', 'y', CONTINUE]],\n  s: [['ies', 'y', CONTINUE], ['sis', 's', STOP], ['is', '', CONTINUE], ['ness', '', CONTINUE], ['ss', '', PROTECT], ['ous', '', CONTINUE], ['us', '', INTACT], ['s', '', CONTINUE], ['s', '', STOP]],\n  t: [['plicat', 'ply', STOP], ['at', '', CONTINUE], ['ment', '', CONTINUE], ['ent', '', CONTINUE], ['ant', '', CONTINUE], ['ript', 'rib', STOP], ['orpt', 'orb', STOP], ['duct', 'duc', STOP], ['sumpt', 'sum', STOP], ['cept', 'ceiv', STOP], ['olut', 'olv', STOP], ['sist', '', PROTECT], ['ist', '', CONTINUE], ['tt', 't', STOP]],\n  u: [['iqu', '', STOP], ['ogu', 'og', STOP]],\n  v: [['siv', 'j', CONTINUE], ['eiv', '', PROTECT], ['iv', '', CONTINUE]],\n  y: [['bly', 'bl', CONTINUE], ['ily', 'y', CONTINUE], ['ply', '', PROTECT], ['ly', '', CONTINUE], ['ogy', 'og', STOP], ['phy', 'ph', STOP], ['omy', 'om', STOP], ['opy', 'op', STOP], ['ity', '', CONTINUE], ['ety', '', CONTINUE], ['lty', 'l', STOP], ['istry', '', STOP], ['ary', '', CONTINUE], ['ory', '', CONTINUE], ['ify', '', STOP], ['ncy', 'nt', CONTINUE], ['acy', '', CONTINUE]],\n  z: [['iz', '', CONTINUE], ['yz', 'ys', STOP]]\n};\n\n/**\n * Patterns.\n */\nvar VOWEL = /[aeiouy]/;\n\n/**\n * Helpers.\n */\nfunction isStemAcceptable(stem) {\n  if (VOWEL.test(stem.charAt(0))) return stem.length > 1;\n  return stem.length > 2 && VOWEL.test(stem);\n}\n\n/**\n * Function stemming the given world using the Lancaster algorithm.\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\nfunction lancaster(word) {\n  var stem = word.toLowerCase(),\n      intact = true;\n\n  var rules = RULES[stem.charAt(stem.length - 1)];\n\n  if (!rules) return stem;\n\n  var i = -1,\n      l = rules.length;\n\n  while (++i < l) {\n    var _rules$i = rules[i],\n        match = _rules$i[0],\n        replacement = _rules$i[1],\n        kind = _rules$i[2];\n\n\n    if (!intact && kind === INTACT) continue;\n\n    var breakpoint = stem.length - match.length;\n\n    if (breakpoint < 0 || stem.substr(breakpoint) !== match) continue;\n\n    if (kind === PROTECT) return stem;\n\n    var next = stem.substr(0, breakpoint) + replacement;\n\n    if (!isStemAcceptable(next)) continue;\n\n    stem = next;\n\n    if (kind === CONTINUE) {\n      intact = false;\n      rules = RULES[stem.charAt(stem.length - 1)];\n\n      if (!rules) return stem;\n\n      i = -1;\n      l = rules.length;\n    }\n  }\n\n  return stem;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/lovins.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = lovins;\n/* eslint no-multi-spaces: 0 */\n/* eslint no-confusing-arrow: 0 */\n/**\n * Talisman stemmers/lovins\n * =========================\n *\n * Julie Beth Lovins' stemmer.\n *\n * [Reference]:\n * http://snowball.tartarus.org/algorithms/lovins/stemmer.html\n *\n * [Article]:\n * Lovins JB (1968) Development of a stemming algorithm. Mechanical Translation\n * and Computational Linguistics, 11: 22-31.\n */\n\n/**\n * Endings.\n */\nvar ENDINGS_LIST = [/alistically$/, 'B', /arizability$/, 'A', /izationally$/, 'B', /antialness$/, 'A', /arisations$/, 'A', /arizations$/, 'A', /entialness$/, 'A', /allically$/, 'C', /antaneous$/, 'A', /antiality$/, 'A', /arisation$/, 'A', /arization$/, 'A', /ationally$/, 'B', /ativeness$/, 'A', /eableness$/, 'E', /entations$/, 'A', /entiality$/, 'A', /entialize$/, 'A', /entiation$/, 'A', /ionalness$/, 'A', /istically$/, 'A', /itousness$/, 'A', /izability$/, 'A', /izational$/, 'A', /ableness$/, 'A', /arizable$/, 'A', /entation$/, 'A', /entially$/, 'A', /eousness$/, 'A', /ibleness$/, 'A', /icalness$/, 'A', /ionalism$/, 'A', /ionality$/, 'A', /ionalize$/, 'A', /iousness$/, 'A', /izations$/, 'A', /lessness$/, 'A', /ability$/, 'A', /aically$/, 'A', /alistic$/, 'B', /alities$/, 'A', /ariness$/, 'E', /aristic$/, 'A', /arizing$/, 'A', /ateness$/, 'A', /atingly$/, 'A', /ational$/, 'B', /atively$/, 'A', /ativism$/, 'A', /elihood$/, 'E', /encible$/, 'A', /entally$/, 'A', /entials$/, 'A', /entiate$/, 'A', /entness$/, 'A', /fulness$/, 'A', /ibility$/, 'A', /icalism$/, 'A', /icalist$/, 'A', /icality$/, 'A', /icalize$/, 'A', /ication$/, 'G', /icianry$/, 'A', /ination$/, 'A', /ingness$/, 'A', /ionally$/, 'A', /isation$/, 'A', /ishness$/, 'A', /istical$/, 'A', /iteness$/, 'A', /iveness$/, 'A', /ivistic$/, 'A', /ivities$/, 'A', /ization$/, 'F', /izement$/, 'A', /oidally$/, 'A', /ousness$/, 'A', /aceous$/, 'A', /acious$/, 'B', /action$/, 'G', /alness$/, 'A', /ancial$/, 'A', /ancies$/, 'A', /ancing$/, 'B', /ariser$/, 'A', /arized$/, 'A', /arizer$/, 'A', /atable$/, 'A', /ations$/, 'B', /atives$/, 'A', /eature$/, 'Z', /efully$/, 'A', /encies$/, 'A', /encing$/, 'A', /ential$/, 'A', /enting$/, 'C', /entist$/, 'A', /eously$/, 'A', /ialist$/, 'A', /iality$/, 'A', /ialize$/, 'A', /ically$/, 'A', /icance$/, 'A', /icians$/, 'A', /icists$/, 'A', /ifully$/, 'A', /ionals$/, 'A', /ionate$/, 'D', /ioning$/, 'A', /ionist$/, 'A', /iously$/, 'A', /istics$/, 'A', /izable$/, 'E', /lessly$/, 'A', /nesses$/, 'A', /oidism$/, 'A', /acies$/, 'A', /acity$/, 'A', /aging$/, 'B', /aical$/, 'A', /alist$/, 'A', /alism$/, 'B', /ality$/, 'A', /alize$/, 'A', /allic$/, 'BB', /anced$/, 'B', /ances$/, 'B', /antic$/, 'C', /arial$/, 'A', /aries$/, 'A', /arily$/, 'A', /arity$/, 'B', /arize$/, 'A', /aroid$/, 'A', /ately$/, 'A', /ating$/, 'I', /ation$/, 'B', /ative$/, 'A', /ators$/, 'A', /atory$/, 'A', /ature$/, 'E', /early$/, 'Y', /ehood$/, 'A', /eless$/, 'A', /elity$/, 'A', /ement$/, 'A', /enced$/, 'A', /ences$/, 'A', /eness$/, 'E', /ening$/, 'E', /ental$/, 'A', /ented$/, 'C', /ently$/, 'A', /fully$/, 'A', /ially$/, 'A', /icant$/, 'A', /ician$/, 'A', /icide$/, 'A', /icism$/, 'A', /icist$/, 'A', /icity$/, 'A', /idine$/, 'I', /iedly$/, 'A', /ihood$/, 'A', /inate$/, 'A', /iness$/, 'A', /ingly$/, 'B', /inism$/, 'J', /inity$/, 'CC', /ional$/, 'A', /ioned$/, 'A', /ished$/, 'A', /istic$/, 'A', /ities$/, 'A', /itous$/, 'A', /ively$/, 'A', /ivity$/, 'A', /izers$/, 'F', /izing$/, 'F', /oidal$/, 'A', /oides$/, 'A', /otide$/, 'A', /ously$/, 'A', /able$/, 'A', /ably$/, 'A', /ages$/, 'B', /ally$/, 'B', /ance$/, 'B', /ancy$/, 'B', /ants$/, 'B', /aric$/, 'A', /arly$/, 'K', /ated$/, 'I', /ates$/, 'A', /atic$/, 'B', /ator$/, 'A', /ealy$/, 'Y', /edly$/, 'E', /eful$/, 'A', /eity$/, 'A', /ence$/, 'A', /ency$/, 'A', /ened$/, 'E', /enly$/, 'E', /eous$/, 'A', /hood$/, 'A', /ials$/, 'A', /ians$/, 'A', /ible$/, 'A', /ibly$/, 'A', /ical$/, 'A', /ides$/, 'L', /iers$/, 'A', /iful$/, 'A', /ines$/, 'M', /ings$/, 'N', /ions$/, 'B', /ious$/, 'A', /isms$/, 'B', /ists$/, 'A', /itic$/, 'H', /ized$/, 'F', /izer$/, 'F', /less$/, 'A', /lily$/, 'A', /ness$/, 'A', /ogen$/, 'A', /ward$/, 'A', /wise$/, 'A', /ying$/, 'B', /yish$/, 'A', /acy$/, 'A', /age$/, 'B', /aic$/, 'A', /als$/, 'BB', /ant$/, 'B', /ars$/, 'O', /ary$/, 'F', /ata$/, 'A', /ate$/, 'A', /eal$/, 'Y', /ear$/, 'Y', /ely$/, 'E', /ene$/, 'E', /ent$/, 'C', /ery$/, 'E', /ese$/, 'A', /ful$/, 'A', /ial$/, 'A', /ian$/, 'A', /ics$/, 'A', /ide$/, 'L', /ied$/, 'A', /ier$/, 'A', /ies$/, 'P', /ily$/, 'A', /ine$/, 'M', /ing$/, 'N', /ion$/, 'Q', /ish$/, 'C', /ism$/, 'B', /ist$/, 'A', /ite$/, 'AA', /ity$/, 'A', /ium$/, 'A', /ive$/, 'A', /ize$/, 'F', /oid$/, 'A', /one$/, 'R', /ous$/, 'A', /ae$/, 'A', /al$/, 'BB', /ar$/, 'X', /as$/, 'B', /ed$/, 'E', /en$/, 'F', /es$/, 'E', /ia$/, 'A', /ic$/, 'A', /is$/, 'A', /ly$/, 'B', /on$/, 'S', /or$/, 'T', /um$/, 'U', /us$/, 'V', /yl$/, 'R', /s'/, 'A', /'s$/, 'A', /a$/, 'A', /e$/, 'A', /i$/, 'A', /o$/, 'A', /s$/, 'W', /y$/, 'B'];\n\nvar ENDINGS = [];\n\nfor (var i = 0, l = ENDINGS_LIST.length; i < l; i += 2) {\n  ENDINGS.push([ENDINGS_LIST[i], ENDINGS_LIST[i + 1]]);\n} /**\n   * Conditions.\n   */\nvar CONDITIONS = {\n  A: function A() {\n    return true;\n  },\n  B: function B(stem) {\n    return stem.length > 2;\n  },\n  C: function C(stem) {\n    return stem.length > 3;\n  },\n  D: function D(stem) {\n    return stem.length > 4;\n  },\n  E: function E(stem) {\n    return !/e$/.test(stem);\n  },\n  F: function F(stem) {\n    return CONDITIONS.B(stem) && CONDITIONS.E(stem);\n  },\n  G: function G(stem) {\n    return CONDITIONS.B(stem) && /f$/.test(stem);\n  },\n  H: function H(stem) {\n    return (/(t|ll)$/.test(stem)\n    );\n  },\n  I: function I(stem) {\n    return !/[oe]$/.test(stem);\n  },\n  J: function J(stem) {\n    return !/[ae]$/.test(stem);\n  },\n  K: function K(stem) {\n    return CONDITIONS.B(stem) && /(l|i|(u\\we))$/.test(stem);\n  },\n  L: function L(stem) {\n    return !/(u|x|([^o]s))$/.test(stem);\n  },\n  M: function M(stem) {\n    return !/[acem]$/.test(stem);\n  },\n  N: function N(stem) {\n    return (/s\\w{2}$/.test(stem) ? CONDITIONS.C(stem) : CONDITIONS.B(stem)\n    );\n  },\n  O: function O(stem) {\n    return (/[li]$/.test(stem)\n    );\n  },\n  P: function P(stem) {\n    return !/c$/.test(stem);\n  },\n  Q: function Q(stem) {\n    return CONDITIONS.B(stem) && !/[ln]$/.test(stem);\n  },\n  R: function R(stem) {\n    return (/[nr]$/.test(stem)\n    );\n  },\n  S: function S(stem) {\n    return (/(dr|[^t]t)$/.test(stem)\n    );\n  },\n  T: function T(stem) {\n    return (/(s|[^o]t)$/.test(stem)\n    );\n  },\n  U: function U(stem) {\n    return (/[lmnr]$/.test(stem)\n    );\n  },\n  V: function V(stem) {\n    return (/c$/.test(stem)\n    );\n  },\n  W: function W(stem) {\n    return !/[su]$/.test(stem);\n  },\n  X: function X(stem) {\n    return (/(l|i|u\\we)$/.test(stem)\n    );\n  },\n  Y: function Y(stem) {\n    return (/in$/.test(stem)\n    );\n  },\n  Z: function Z(stem) {\n    return !/f$/.test(stem);\n  },\n  AA: function AA(stem) {\n    return (/([dflt]|ph|th|er|or|es)$/.test(stem)\n    );\n  },\n  BB: function BB(stem) {\n    return CONDITIONS.B(stem) && !/(met|ryst)/.test(stem);\n  },\n  CC: function CC(stem) {\n    return (/l$/.test(stem)\n    );\n  }\n};\n\n/**\n * Endings.\n */\nvar TRANSFORMATIONS = [[/iev$/, 'ief'], [/uct$/, 'uc'], [/umpt$/, 'um'], [/rpt$/, 'rb'], [/urs$/, 'ur'], [/istr$/, 'ister'], [/metr$/, 'meter'], [/olv$/, 'olut'], [/([^aoi])ul$/, '$1l'], [/bex$/, 'bic'], [/dex$/, 'dic'], [/pex$/, 'pic'], [/tex$/, 'tic'], [/ax$/, 'ac'], [/ex$/, 'ec'], [/ix$/, 'ic'], [/lux$/, 'luc'], [/uad$/, 'uas'], [/vad$/, 'vas'], [/cid$/, 'cis'], [/lid$/, 'lis'], [/erid$/, 'eris'], [/pand$/, 'pans'], [/([^s])end$/, '$1ens'], [/ond$/, 'ons'], [/lud$/, 'lus'], [/rud$/, 'rus'], [/([^pt])her$/, '$1hes'], [/mit$/, 'mis'], [/([^m])ent$/, '$1ens'], [/ert$/, 'ers'], [/([^n])et$/, '$1es'], [/(yt|yz)$/, 'ys']];\n\n/**\n * Function stemming the given world using the Lovins algorithm.\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\nfunction lovins(word) {\n\n  // Preparing the word\n  word = word.toLowerCase().replace(/^a-z'/g, '');\n\n  // Dropping the longest suffix we can find in the word\n  var stem = word;\n  for (var _i = 0, _l = ENDINGS.length; _i < _l; _i++) {\n    var _ENDINGS$_i = ENDINGS[_i],\n        match = _ENDINGS$_i[0],\n        condition = _ENDINGS$_i[1];\n\n\n    stem = word.replace(match, '');\n\n    if (stem.length > 1 && stem.length < word.length && CONDITIONS[condition](stem)) break;\n  }\n\n  // Dropping double occurrences of some consonants ending the stem\n  if (/[bdglmnprst]{2,}$/.test(stem) && stem[stem.length - 1] === stem[stem.length - 2]) {\n    stem = stem.slice(0, -1);\n  }\n\n  // Applying transformations\n  for (var _i2 = 0, _l2 = TRANSFORMATIONS.length; _i2 < _l2; _i2++) {\n    var _TRANSFORMATIONS$_i = TRANSFORMATIONS[_i2],\n        match = _TRANSFORMATIONS$_i[0],\n        replacement = _TRANSFORMATIONS$_i[1];\n\n    stem = stem.replace(match, replacement);\n  }\n\n  return stem;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/porter.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = porter;\n/* eslint no-cond-assign: 0 */\n/**\n * Talisman stemmers/porter\n * =========================\n *\n * The classical Porter stemmer.\n *\n * [Reference]:\n * http://tartarus.org/martin/PorterStemmer/\n *\n * [Article]:\n * C.J. van Rijsbergen, S.E. Robertson and M.F. Porter, 1980. New models in\n * probabilistic information retrieval. London: British Library.\n * (British Library Research and Development Report, no. 5587).\n */\n\n/**\n * Suffixes.\n */\nvar STEP2_SUFFIXES = ['ational', 'tional', 'enci', 'anci', 'izer', 'bli', 'alli', 'entli', 'eli', 'ousli', 'ization', 'ation', 'ator', 'alism', 'iveness', 'fulness', 'ousness', 'aliti', 'iviti', 'biliti', 'logi'];\n\nvar STEP3_SUFFIXES = ['icate', 'ative', 'alize', 'iciti', 'ical', 'ful', 'ness'];\n\nvar STEP4_SUFFIXES = ['al', 'ance', 'ence', 'er', 'ic', 'able', 'ible', 'ant', 'ement', 'ment', 'ent', 'ou', 'ism', 'ate', 'iti', 'ous', 'ive', 'ize'];\n\nvar STEP2_SUFFIXES_REGEX = new RegExp('^(.+?)(' + STEP2_SUFFIXES.join('|') + ')$'),\n    STEP3_SUFFIXES_REGEX = new RegExp('^(.+?)(' + STEP3_SUFFIXES.join('|') + ')$'),\n    STEP4_SUFFIXES_REGEX = new RegExp('^(.+?)(' + STEP4_SUFFIXES.join('|') + ')$');\n\n/**\n * Steps maps.\n */\nvar STEP2_MAP = {\n  ational: 'ate',\n  tional: 'tion',\n  enci: 'ence',\n  anci: 'ance',\n  izer: 'ize',\n  bli: 'ble',\n  alli: 'al',\n  entli: 'ent',\n  eli: 'e',\n  ousli: 'ous',\n  ization: 'ize',\n  ation: 'ate',\n  ator: 'ate',\n  alism: 'al',\n  iveness: 'ive',\n  fulness: 'ful',\n  ousness: 'ous',\n  aliti: 'al',\n  iviti: 'ive',\n  biliti: 'ble',\n  logi: 'log'\n};\n\nvar STEP3_MAP = {\n  icate: 'ic',\n  ative: '',\n  alize: 'al',\n  iciti: 'ic',\n  ical: 'ic',\n  ful: '',\n  ness: ''\n};\n\n/**\n * Patterns.\n */\nvar C = '[^aeiou]',\n    V = '[aeiouy]',\n    CC = '' + C + C + '*',\n    VV = '' + V + V + '*';\n\nvar MGR0 = new RegExp('^(' + CC + ')?' + VV + CC),\n    MEQ1 = new RegExp('^(' + CC + ')?' + VV + CC + '(' + VV + ')?$'),\n    MGR1 = new RegExp('^(' + CC + ')?' + VV + CC + VV + CC),\n    VOWEL_IN_STEM = new RegExp('^(' + CC + ')?' + V);\n\nvar STEP1a1 = /^(.+?)(ss|i)es$/,\n    STEP1a2 = /^(.+?)([^s])s$/;\n\nvar STEP1b1 = /^(.+?)eed$/,\n    STEP1b2 = /^(.+?)(ed|ing)$/,\n    STEP1b3 = /(at|bl|iz)$/,\n    STEP1b4 = /([^aeiouylsz])\\1$/,\n    STEP1b5 = new RegExp('^' + CC + V + '[^aeiouwxy]$');\n\nvar STEP1c = new RegExp('^(.*' + V + '.*)y$');\n\nvar STEP4 = /^(.+?)(s|t)(ion)$/;\n\nvar STEP51 = /^(.+?)e$/,\n    STEP52 = new RegExp('^' + CC + V + '[^aeiouwxy]$');\n\n/**\n * Helpers.\n */\nfunction chop(string) {\n  return string.slice(0, -1);\n}\n\nfunction match(regex, string) {\n  var m = regex.exec(string);\n  regex.lastIndex = 0;\n  return m;\n}\n\n/**\n * Function stemming the given world using the Porter algorithm.\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\nfunction porter(word) {\n  word = word.toLowerCase();\n\n  // If the word is too short, we return it unscathed\n  if (word.length < 3) return word;\n\n  var m = null;\n\n  // If the first letter is a Y, we uppercase it so it's not treated as vowel\n  if (word[0] === 'y') word = 'Y' + word.slice(1);\n\n  //-- Step 1a\n  word = word.replace(STEP1a1, '$1$2');\n  word = word.replace(STEP1a2, '$1$2');\n\n  //-- Step 1b\n  if (m = match(STEP1b1, word)) {\n    var _m = m,\n        stem = _m[1];\n\n\n    if (MGR0.test(stem)) word = chop(word);\n  } else if (m = match(STEP1b2, word)) {\n    var _m2 = m,\n        _stem = _m2[1];\n\n\n    if (VOWEL_IN_STEM.test(_stem)) {\n      word = _stem;\n\n      if (STEP1b3.test(word)) word = word + 'e';else if (STEP1b4.test(word)) word = chop(word);else if (STEP1b5.test(word)) word = word + 'e';\n    }\n  }\n\n  //-- Step 1c\n  if (m = match(STEP1c, word)) {\n    var _m3 = m,\n        _stem2 = _m3[1];\n\n\n    word = _stem2 + 'i';\n  }\n\n  //-- Step 2\n  if (m = match(STEP2_SUFFIXES_REGEX, word)) {\n    var _m4 = m,\n        _stem3 = _m4[1],\n        suffix = _m4[2];\n\n\n    if (MGR0.test(_stem3)) word = _stem3 + STEP2_MAP[suffix];\n  }\n\n  //-- Step 3\n  if (m = match(STEP3_SUFFIXES_REGEX, word)) {\n    var _m5 = m,\n        _stem4 = _m5[1],\n        _suffix = _m5[2];\n\n\n    if (MGR0.test(_stem4)) word = _stem4 + STEP3_MAP[_suffix];\n  }\n\n  //-- Step 4\n  if (m = match(STEP4_SUFFIXES_REGEX, word)) {\n    var _m6 = m,\n        _stem5 = _m6[1];\n\n\n    if (MGR1.test(_stem5)) word = _stem5;\n  } else if (m = match(STEP4, word)) {\n    var _m7 = m,\n        first = _m7[1],\n        second = _m7[2],\n        _stem6 = first + second;\n\n    if (MGR1.test(_stem6)) word = _stem6;\n  }\n\n  //-- Step 5\n  if (m = match(STEP51, word)) {\n    var _m8 = m,\n        _stem7 = _m8[1];\n\n\n    if (MGR1.test(_stem7) || MEQ1.test(_stem7) && !STEP52.test(_stem7)) word = _stem7;\n  }\n\n  if (/ll$/.test(word) && MGR1.test(word)) word = chop(word);\n\n  return word.toLowerCase();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/s-stemmer.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = sStemmer;\n/**\n * Talisman stemmers/s-stemmer\n * ============================\n *\n * Implementation of the English \"S-Stemmer\".\n *\n * [Reference]:\n * http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.9828&rep=rep1&type=pdf\n *\n * [Article]:\n * Donna Harman (1991) How effective is suffixing?\n * Journal of the American Society for Information Science (vol. 42 issue 1).\n *\n * [Note]:\n * I cannot find the original author of the algorithm, only its explanation in\n * the linked article.\n */\n\n/**\n * Function stemming the given world using the \"S-Stemmer\".\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\nfunction sStemmer(word) {\n  var length = word.length;\n\n  if (length < 3 || word[length - 1] !== 's') return word;\n\n  var penultimate = word[length - 2];\n\n  if (penultimate === 'u' || penultimate === 's') return word;\n\n  if (penultimate === 'e') {\n    if (length > 3 && word[length - 3] === 'i' && word[length - 4] !== 'a' && word[length - 4] !== 'e') {\n      return word.slice(0, -3) + 'y';\n    }\n\n    if (word[length - 3] === 'i' || word[length - 3] === 'a' || word[length - 3] === 'o' || word[length - 3] === 'e') {\n      return word;\n    }\n  }\n\n  return word.slice(0, -1);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/uea-lite.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.withRule = withRule;\nexports.default = ueaLite;\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\n/**\n * Talisman stemmers/uea-lite\n * ===========================\n *\n * The University of East Anglia (UEA) Lite stemmer.\n *\n * [Reference]:\n * http://www2.cmp.uea.ac.uk/~djs/projects/UEAlite/stemmer.html\n * http://github.com/ealdent/uea-stemmer\n *\n * [Authors]:\n * Marie-CLaire Jenkins\n * Dan Smith\n * Jason M. Adams (Ruby version additions)\n */\n\n/**\n * Rules.\n */\nvar PROBLEMS = new Set(['is', 'as', 'this', 'has', 'was', 'during', 'menses']);\n\nvar CONTRACTIONS = [[/n't/, ' not'], [/'ve/, ' have'], [/'re/, ' are'], [/'m/, ' am']];\n\nvar complexSuffixing = function complexSuffixing(word) {\n\n  // Dropping final \"s\"\n  if (word[word.length - 1] === 's') word = word.slice(0, -1);\n\n  // Dropping \"ing\"\n  if (word.slice(-3) === 'ing') word = word.slice(0, -3);\n\n  // Dropping \"ed\"\n  else if (word.slice(-2) === 'ed') word = word.slice(0, -2);\n\n  // Dropping potential consecutive duplicate letters\n  if (word[word.length - 1] === word[word.length - 2]) word = word.slice(0, -1);\n\n  return word;\n};\n\nvar RULES = [[/^\\d+$/, null, '90.3'], [/^\\w+-\\w+$/, null, '90.2'], [/-/, null, '90.1'], [/_/, null, '90'], [/^[A-Z]+s$/, 1, '91.1'], [/^[A-Z]+$/, null, '91'], [/^(?:.*[A-Z].*[A-Z]|[A-Z]{1}).*$/, null, '92'], [/aceous$/, 6, '1'], [/ces$/, 1, '2'], [/cs$/, null, '3'], [/sis$/, null, '4'], [/tis$/, null, '5'], [/ss$/, null, '6'], [/eed$/, null, '7'], [/eeds$/, 1, '7'], [/ued$/, 1, '8'], [/ues$/, 1, '9'], [/ees$/, 1, '10'], [/iases$/, 2, '11.4'], [/uses$/, 1, '11.3'], [/sses$/, 2, 11.2], [/eses$/, 'esis', '11.1'], [/ses$/, 1, '11'], [/tled$/, 1, '12.5'], [/pled$/, 1, '12.4'], [/bled$/, 1, '12.3'], [/eled$/, 2, '12.2'], [/lled$/, 2, '12.1'], [/led$/, 2, '12'], [/ened$/, 2, '13.7'], [/ained$/, 2, '13.6'], [/erned$/, 2, '13.5'], [/rned$/, 2, '13.4'], [/nned$/, 3, '13.3'], [/oned$/, 2, '13.2'], [/gned$/, 2, '13.1'], [/ned$/, 1, '13'], [/ifted$/, 2, '14'], [/ected$/, 2, '15'], [/vided$/, 1, '16'], [/ved$/, 1, '17'], [/ced$/, 1, '18'],\n\n//--< Jason M. Adams\n[/arred$/, 3, '19.1'],\n//--> Jason M. Adams\n\n[/erred$/, 3, '19'], [/urred$/, 3, '20.5'], [/lored$/, 2, '20.4'], [/eared$/, 2, '20.3'], [/tored$/, 1, '20.2'], [/ered$/, 2, '20.1'], [/red$/, 1, '20'], [/reds$/, 2, '20'], [/tted$/, 3, '21'],\n\n//--< Jason M. Adams\n[/noted$/, 1, '22.6'], [/leted$/, 1, '22.5'], [/[^vm]ited$/, 2, '22.4'], [/(?:ch|[vm])i[td]ed$/, 1, '22.3'], [/uted$/, 1, '22.2'], [/ated$/, 1, '22.1'], [/ted$/, 2, '22'],\n//--> Jason M. Adams\n\n[/anges$/, 1, '23'], [/aining$/, 3, '24'], [/acting$/, 3, '25'], [/ttings?$/, 't', '26'], [/viding$/, 'vide', '27'], [/ssed$/, 2, '28'], [/sed$/, 1, '29'], [/titudes$/, 1, '30'],\n\n//--< Jason M. Adams\n[/oed$/, 1, '31.3'], [/d?oes$/, 2, '31.2'], [/[oaiu]ked$/, 1, '31.1'], [/[aiu]med/, 1, '31'],\n//--> Jason M. Adams\n\n[/ulted$/, 2, '32'], [/uming$/, 'ume', '33'], [/fulness$/, 4, '34'], [/ousness$/, 4, '35'], [/r[aeiou]bed$/, 1, '36.1'], [/beds?$/, 'b', '36'], [/ssings?$/, 'ss', '37'], [/ulting$/, 3, '38'], [/vings?$/, 'v', '39'], [/vings$/], [/eadings?$/, 'ead', '40.7'], [/oadings?$/, 'oad', '40.6'], [/edings?$/, 'ed', '40.5'], [/ddings?$/, 'd', '40.4'], [/ldings?$/, 'ld', '40.3'], [/rdings?$/, 'rd', '40.2'], [/ndings?$/, 'nd', '40.1'], [/dings?/, 'de', '40'], [/llings?$/, 'l', '41'], [/ealings?$/, 'eal', '42.4'], [/olings?$/, 'ol', '42.3'], [/ailings?$/, 'ail', '42.2'], [/elings?$/, 'el', '42.1'], [/lings?$/, 'le', '42'], [/nged$/, 1, '43.2'], [/gged$/, 3, '43.1'], [/ged$/, 1, '43'], [/mmings?$/, 'm', '44.3'], [/rming$/, 3, '44.2'], [/lming$/, 3, '44.1'], [/mings?$/, 'me', '44'], [/ngings?$/, 'ng', '45.2'], [/ggings?$/, 'g', '45.1'], [/gings?$/, 'ge', '45'], [/aning$/, 3, '46.6'], [/ening$/, 3, '46.5'], [/gning$/, 3, '46.4'], [/nning$/, 4, '46.3'], [/oning$/, 3, '46.2'], [/rning$/, 3, '46.1'], [/ning$/, 'ne', '46'], [/stings?$/, 'st', '47'], [/etings?$/, 'et', '48.4'], [/pting$/, 3, '48.3'], [/ntings?$/, 'nt', '48.2'], [/cting$/, 3, '48.1'], [/tings?$/, 'ct', '48.1'], [/ssed$/, 2, '49'], [/les$/, 1, '50'], [/tes$/, 1, '51'], [/zed$/, 1, '52'], [/lled$/, 2, '53'], [/irings?$/, 'ire', '54.4'], [/urings?$/, 'ure', '54.3'], [/ncings?$/, 'nce', '54.2'], [/zing$/, 3, '54.1'], [/sings?$/, 'se', '54'], [/lling$/, 3, '55'], [/ied$/, 'e', '56'], [/ating$/, 'ate', '57'],\n\n//--< Jason M. Adams\n[/dying$/, 'die', '58.2'], [/^lying$/, 'lie', '58.2'], [/tying$/, 'tie', '58.2'],\n//--> Jason M. Adams\n\n[/thing$/, null, '58.1'], [/things$/, 1, '58.1'], [/\\w{2}ings?$/, complexSuffixing, '58'], [/ies$/, 'y', '59'], [/lves$/, 'lf', '60.1'], [/ves$/, 1, '60'], [/aped$/, 1, '61.3'], [/uded$/, 1, '61.2'], [/oded$/, 1, '61.1'],\n\n// NOTE: same rule as 22.1, but present uselessly in all reference\n// implementations\n// [/ated$/, 1, '61'],\n[/\\w{2}eds?$/, complexSuffixing, '62'],\n\n//--< Jason M. Adams\n[/des$/, 1, '63.10'], [/res$/, 1, '63.9'],\n//--> Jason M. Adams\n\n[/pes$/, 1, '63.8'], [/mes$/, 1, '63.7'], [/ones$/, 1, '63.6'], [/izes$/, 1, '63.5'], [/ures$/, 1, '63.4'], [/ines$/, 1, '63.3'], [/ides$/, 1, '63.2'],\n\n//--< Jason M. Adams\n[/[kg]es$/, 1, '63.1'],\n//--> Jason M. Adam\n\n[/es$/, 2, '63'], [/is$/, 'e', '64'], [/ous$/, null, '65'], [/ums$/, null, '66'], [/us$/, null, '67'], [/s$/, 1, '68']];\n\n/**\n * Function stemming the given world using the UEALite stemmer.\n *\n * @param  {string} word - The word to stem.\n * @return {object}      - An object containing the stemmed word and the applied\n *                         rule.\n */\nfunction withRule(word) {\n  var stem = word;\n\n  // Is the given word problematic?\n  if (PROBLEMS.has(word)) return { rule: '90', stem: stem };\n\n  // If the word contains apostrophe(s)\n  if (/'/.test(word)) {\n\n    // Possessive (both singular & plural)\n    if (/'s?$/i.test(word)) stem = stem.replace(/'s?$/i, '');\n\n    // Expand various contractions\n    for (var i = 0, l = CONTRACTIONS.length; i < l; i++) {\n      var _stem;\n\n      stem = (_stem = stem).replace.apply(_stem, _toConsumableArray(CONTRACTIONS[i]));\n    }return { rule: '94', stem: stem };\n  }\n\n  // Applying rules\n  for (var _i = 0, _l = RULES.length; _i < _l; _i++) {\n    var _RULES$_i = RULES[_i],\n        pattern = _RULES$_i[0],\n        replacement = _RULES$_i[1],\n        rule = _RULES$_i[2];\n\n    // Replacing through string\n\n    if (typeof replacement === 'string') {\n      var newStem = stem.replace(pattern, replacement);\n\n      if (newStem !== stem) return { rule: rule, stem: newStem };\n    }\n\n    // Attempting to match the pattern\n    if (pattern.test(stem)) {\n\n      if (typeof replacement === 'function') stem = replacement(stem);else if (replacement) stem = stem.slice(0, -replacement);\n\n      return { rule: rule, stem: stem };\n    }\n  }\n\n  return { rule: '0', stem: word };\n}\n\nfunction ueaLite(word) {\n  return withRule(word).stem;\n}\nmodule.exports = exports['default'];\nexports['default'].withRule = exports.withRule;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tag/averaged-perceptron.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.analyzeSentences = analyzeSentences;\nexports.normalize = normalize;\nexports.extractFeatures = extractFeatures;\nexports.predict = predict;\n\nvar _shuffle = require('pandemonium/shuffle');\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } } /**\n                                                                                                                                                           * Talisman tag/averaged-perceptron\n                                                                                                                                                           * =================================\n                                                                                                                                                           *\n                                                                                                                                                           * The Averaged Perceptron POS tagging method.\n                                                                                                                                                           *\n                                                                                                                                                           * [Author]: Matthew Honnibal\n                                                                                                                                                           *\n                                                                                                                                                           * [Reference]: http://spacy.io/blog/part-of-speech-POS-tagger-in-python/\n                                                                                                                                                           */\n\n\n/**\n * Constants.\n */\nvar HASH_DELIMITER = '‡';\nvar hasher = function hasher(a, b) {\n  return a + HASH_DELIMITER + b;\n};\n\nvar LOWEST_STRING = String.fromCharCode(0);\n\nvar START = ['-START-', '-START2-'],\n    END = ['-END-', '-END2-'];\n\nvar HYPHEN_REGEX = /-/,\n    YEAR_REGEX = /\\d{4}/,\n    DIGIT_REGEX = /\\d/;\n\n/**\n * Defaults.\n */\nvar DEFAULTS = {\n  iterations: 5,\n  ambiguityThreshold: 0.97,\n  frequencyThreshold: 20\n};\n\n/**\n * Helpers.\n */\n\n/**\n * Function taking training sentences and returning\n *\n * @param  {array}  sentences - Array of sentences being arrays of (word, tag).\n * @return {object}           - Found classes & tags.\n */\nfunction analyzeSentences(sentences) {\n  var classes = new Set(),\n      counts = {},\n      tags = {};\n\n  // Iterating over sentences\n  for (var i = 0, l = sentences.length; i < l; i++) {\n    var sentence = sentences[i];\n\n    // Iterating over words\n    for (var j = 0, m = sentence.length; j < m; j++) {\n      var _sentence$j = sentence[j],\n          word = _sentence$j[0],\n          tag = _sentence$j[1];\n\n      classes.add(tag);\n\n      if (!(word in counts)) counts[word] = {};\n      if (!(tag in counts[word])) counts[word][tag] = 0;\n      counts[word][tag]++;\n    }\n  }\n\n  // Adding words to the tag dictionary\n  for (var word in counts) {\n    var tagFrequencies = counts[word];\n\n    // Finding max frequency\n    var max = -Infinity,\n        maxTag = null,\n        sum = 0;\n\n    for (var tag in tagFrequencies) {\n      var count = tagFrequencies[tag];\n\n      if (count > max) {\n        maxTag = tag;\n        max = count;\n      }\n\n      sum += count;\n    }\n\n    // We don't add rare words to the dictionary, just unambiguous ones\n    if (sum >= DEFAULTS.frequencyThreshold && max / sum >= DEFAULTS.ambiguityThreshold) tags[word] = maxTag;\n  }\n\n  return { classes: classes, tags: tags };\n}\n\n/**\n * Function normalizing the given word before its pass through the perceptron.\n *\n * @param  {string} word - Target word.\n * @return {string}      - Normalized word.\n */\nfunction normalize(word) {\n  if (HYPHEN_REGEX.test(word) && word[0] !== '-') return '!HYPHEN';\n\n  if (YEAR_REGEX.test(word)) return '!YEAR';\n\n  if (DIGIT_REGEX.test(word[0])) return '!DIGITS';\n\n  return word.toLowerCase();\n}\n\n/**\n * Function used to build a context from the given tokenized sentence.\n *\n * @param  {array} sentence - Target sentence.\n * @return {array}          - Context.\n */\nfunction createContext(sentence) {\n  var context = new Array(sentence.length + 4);\n  context[0] = START[0];\n  context[1] = START[1];\n\n  for (var j = 0, m = sentence.length; j < m; j++) {\n    context[j + 2] = normalize(sentence[j][0]);\n  }context[context.length - 2] = END[0];\n  context[context.length - 1] = END[1];\n\n  return context;\n}\n\n/**\n * Function extracting feature from the given word & its context.\n *\n * @param  {string} word    - Target word.\n * @param  {number} index   - Index of the word in the sentence.\n * @param  {array}  context - Word's context.\n * @param  {array}  prev    - Previous.\n * @param  {array}  prev2   - Previous 2.\n * @return {array}          - Features.\n */\nfunction extractFeatures(index, word, context, previous, previous2) {\n  var features = { bias: 1 };\n  index += 2;\n\n  features['i suffix ' + word.slice(-3)] = 1;\n  features['i pref1 ' + word[0]] = 1;\n  features['i-1 tag ' + previous] = 1;\n  features['i-2 tag ' + previous2] = 1;\n  features['i tag+i-2 tag ' + previous + ' ' + previous2] = 1;\n  features['i word ' + context[index]] = 1;\n  features['i-1 tag+i word ' + previous + ' ' + context[index]] = 1;\n  features['i-1 word ' + context[index - 1]] = 1;\n  features['i-1 suffix ' + context[index - 1].slice(-3)] = 1;\n  features['i-2 word ' + context[index - 2]] = 1;\n  features['i+1 word ' + context[index + 1]] = 1;\n  features['i+1 suffix ' + context[index + 1].slice(-3)] = 1;\n  features['i+2 word ' + context[index + 2]] = 1;\n\n  return features;\n}\n\n/**\n * Given features, weights & classes, this function will return the best\n * label by computing the dot product of the features & weights.\n *\n * @param  {object} features - Target features.\n * @param  {object} weights  - Current weights.\n * @param  {array}  classes  - Array of possible classes.\n * @return {array}           - The best label.\n */\nfunction predict(features, weights, classes) {\n  var scores = {};\n\n  // Iterating over features\n  for (var feature in features) {\n    var value = features[feature];\n\n    if (!value || !(feature in weights)) continue;\n\n    var relevantWeights = weights[feature];\n\n    for (var label in relevantWeights) {\n      var weight = relevantWeights[label];\n      scores[label] = scores[label] || 0;\n      scores[label] += value * weight;\n    }\n  }\n\n  // Retrieving the best label\n  var bestLabel = LOWEST_STRING,\n      bestScore = -Infinity;\n\n  // NOTE: this part is not strictly equal to its Python counterpart\n  for (var i = 0, l = classes.length; i < l; i++) {\n    var _label = classes[i],\n        score = scores[_label] || 0;\n\n    if (score > bestScore) {\n      bestScore = score;\n      bestLabel = _label;\n    } else if (score === bestScore) {\n\n      if (_label > bestLabel) bestLabel = _label;\n    }\n  }\n\n  return bestLabel;\n}\n\n/**\n * The AveragedPerceptronTagger class.\n *\n * @constructor\n * @param {object}   [options]           - Customization options.\n * @param {number}   [options.iteration] - Number of training operations.\n * @param {function} [options.rng]       - RNG function.\n */\n\nvar AveragedPerceptronTagger = function () {\n  function AveragedPerceptronTagger(options) {\n    _classCallCheck(this, AveragedPerceptronTagger);\n\n    options = options || {};\n\n    this.options = {\n      iterations: options.iterations || DEFAULTS.iterations\n    };\n\n    // Creating shuffler\n    this.shuffle = (0, _shuffle.createShuffle)(options.rng || Math.random);\n\n    // Properties\n    this.trained = false;\n    this.tags = {};\n    this.classes = null;\n    this.weights = {};\n    this.seenInstances = 0;\n    this.totals = {};\n    this.timestamps = {};\n  }\n\n  /**\n   * Method used to update the model's weights.\n   *\n   * @param  {string} truth    - The correct label.\n   * @param  {string} guess    - The predicted label.\n   * @param  {object} features - The features.\n   * @return {AveragedPerceptronTagger} - Returns itself for chaining.\n   */\n\n\n  AveragedPerceptronTagger.prototype.update = function update(truth, guess, features) {\n    this.seenInstances++;\n\n    // If the guess is correct, we don't have much to do\n    if (truth === guess) return this;\n\n    for (var feature in features) {\n      if (!(feature in this.weights)) this.weights[feature] = {};\n\n      var weights = this.weights[feature];\n\n      // For truth\n      var truthKey = hasher(feature, truth),\n          truthWeight = weights[truth] || 0;\n\n      this.totals[truthKey] = this.totals[truthKey] || 0;\n      this.totals[truthKey] += (this.seenInstances - (this.timestamps[truthKey] || 0)) * truthWeight;\n      this.timestamps[truthKey] = this.seenInstances;\n      weights[truth] = truthWeight + 1;\n\n      // For guess\n      var guessKey = hasher(feature, guess),\n          guessWeight = weights[guess] || 0;\n\n      this.totals[guessKey] = this.totals[guessKey] || 0;\n      this.totals[guessKey] += (this.seenInstances - (this.timestamps[guessKey] || 0)) * guessWeight;\n      this.timestamps[guessKey] = this.seenInstances;\n      weights[guess] = guessWeight - 1;\n    }\n\n    return this;\n  };\n\n  /**\n   * Method used to finalize training by computing average weights from\n   * all iterations.\n   *\n   * @return {AveragedPerceptronTagger} - Returns itself for chaining.\n   */\n\n\n  AveragedPerceptronTagger.prototype.averageWeights = function averageWeights() {\n    for (var feature in this.weights) {\n      var updatedWeights = {};\n\n      for (var label in this.weights[feature]) {\n        var weight = this.weights[feature][label],\n            key = hasher(feature, label);\n\n        var total = this.totals[key];\n        total += (this.seenInstances - this.timestamps[key]) * weight;\n\n        var averaged = Math.round(total / this.seenInstances, 3);\n\n        if (averaged) updatedWeights[label] = averaged;\n      }\n\n      this.weights[feature] = updatedWeights;\n    }\n\n    return this;\n  };\n\n  /**\n   * Method used to train the tagger with the input sentences.\n   *\n   * @param  {array} sentences - Array of sentences being arrays of (word, tag).\n   * @return {AveragedPerceptronTagger} - Returns itself for chaining.\n   */\n\n\n  AveragedPerceptronTagger.prototype.train = function train(sentences) {\n\n    if (this.trained) throw Error('talisman/tag/averaged-perceptron.train: this tagger has already been trained.');\n\n    var _analyzeSentences = analyzeSentences(sentences),\n        classes = _analyzeSentences.classes,\n        tags = _analyzeSentences.tags;\n\n    // Setting properties\n\n\n    this.classes = Array.from(classes);\n    this.tags = tags;\n\n    // Performing iterations\n    for (var i = 0, l = this.options.iterations; i < l; i++) {\n      this.iterate(sentences);\n\n      // Shuffling the sentences for next iteration\n      if (i !== l - 1) sentences = this.shuffle(sentences);\n    }\n\n    // Get average weights\n    this.averageWeights();\n\n    // Cleanup\n    delete this.seenInstances;\n    delete this.totals;\n    delete this.timestamps;\n\n    // The tagger is now trained\n    this.trained = true;\n\n    return this;\n  };\n\n  /**\n   * Method used to perform a single training operation.\n   *\n   * @return {AveragedPerceptronTagger} - Returns itself for chaining.\n   */\n\n\n  AveragedPerceptronTagger.prototype.iterate = function iterate(sentences) {\n\n    // Iterating over sentences\n    for (var i = 0, l = sentences.length; i < l; i++) {\n      var sentence = sentences[i];\n\n      var previous = START[0],\n          previous2 = START[1];\n\n      // Building context\n      var context = createContext(sentence);\n\n      for (var j = 0, m = sentence.length; j < m; j++) {\n        var _sentence$j2 = sentence[j],\n            word = _sentence$j2[0],\n            tag = _sentence$j2[1];\n\n        var guess = this.tags[word];\n\n        if (!guess) {\n          var features = extractFeatures(j, word, context, previous, previous2);\n\n          guess = predict(features, this.weights, this.classes);\n\n          this.update(tag, guess, features);\n        }\n\n        previous2 = previous;\n        previous = guess;\n      }\n    }\n\n    return this;\n  };\n\n  /**\n   * Method used to tag the provided tokenized sentence.\n   *\n   * @param  {array} sentence - Array of word tokens.\n   * @return {array}          - The tagged tokens.\n   */\n\n\n  AveragedPerceptronTagger.prototype.tag = function tag(sentence) {\n    if (!this.trained) throw Error('talisman/tag/averaged-perceptron.tag: this tagger hasn\\'t been trained yet.');\n\n    var output = new Array(sentence.length),\n        context = createContext(sentence);\n\n    var previous = START,\n        previous2 = START;\n\n    for (var i = 0, l = sentence.length; i < l; i++) {\n      var word = sentence[i];\n\n      var tag = this.tags[word];\n\n      if (!tag) {\n        var features = extractFeatures(i, word, context, previous, previous2);\n        tag = predict(features, this.weights, this.classes);\n      }\n\n      output[i] = [word, tag];\n      previous2 = previous;\n      previous = tag;\n    }\n\n    return output;\n  };\n\n  return AveragedPerceptronTagger;\n}();\n\nexports.default = AveragedPerceptronTagger;\nmodule.exports = exports['default'];\nexports['default'].analyzeSentences = exports.analyzeSentences;\nexports['default'].normalize = exports.normalize;\nexports['default'].extractFeatures = exports.extractFeatures;\nexports['default'].predict = exports.predict;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/classification/naive-bayes/discrete.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * Talisman classification/naive-bayes/discrete\n * =============================================\n *\n * Abstract discrete Naive-Bayes classifier.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n */\n\n/**\n * Abstract discrete Naive-Bayes classifier.\n *\n * @constructor\n */\nvar AbstractDiscreteNaiveBayes = function () {\n  function AbstractDiscreteNaiveBayes(options) {\n    _classCallCheck(this, AbstractDiscreteNaiveBayes);\n\n    var _ref = options || {},\n        _ref$alpha = _ref.alpha,\n        alpha = _ref$alpha === undefined ? 1.0 : _ref$alpha;\n\n    this.alpha = alpha;\n  }\n\n  /**\n   * Method used to reset the internal state of the classifier.\n   *\n   * @return {NaiveBayes} - Returns itself for chaining.\n   */\n\n\n  AbstractDiscreteNaiveBayes.prototype.reset = function reset() {\n    this.classes = null;\n    this.counts = null;\n\n    return this;\n  };\n\n  /**\n   * Method used to train the classifier and taking the dataset's vectors &\n   * labels.\n   *\n   * @param  {array}      features - Training vectors.\n   * @param  {array}      labels   - Target values.\n   * @return {NaiveBayes}          - Returns itself for chaining.\n   *\n   * @throws {Error} - Will throw if features and labels are not of same length.\n   */\n\n\n  AbstractDiscreteNaiveBayes.prototype.fit = function fit(features, labels) {\n    var nbVectors = features.length;\n\n    if (nbVectors !== labels.length) throw Error('talisman/classification/naive-bayes/discrete.fit: given arrays have different lengths.');\n\n    // Resetting internal state\n    this.reset();\n\n    // Finding classes\n    var classes = {};\n\n    for (var i = 0, l = labels.length; i < l; i++) {\n      var label = labels[i];\n\n      classes[label] = classes[label] || 0;\n      classes[label]++;\n    }\n\n    // Counting features per classes\n    var counts = {};\n\n    for (var k in classes) {\n      counts[k] = {};\n    }for (var _i = 0; _i < nbVectors; _i++) {\n      var cls = counts[labels[_i]],\n          vector = features[_i];\n\n      for (var j = 0, _l = vector.length; j < _l; j++) {\n        var value = vector[j];\n\n        cls[value] = cls[value] || 0;\n        cls[value]++;\n      }\n    }\n\n    this.classes = classes;\n    this.counts = counts;\n\n    return this;\n  };\n\n  return AbstractDiscreteNaiveBayes;\n}();\n\nexports.default = AbstractDiscreteNaiveBayes;\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/classification/naive-bayes/gaussian.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _vectors = require('../../helpers/vectors');\n\nvar _matrices = require('../../helpers/matrices');\n\nvar _descriptive = require('../../stats/descriptive');\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } } /**\n                                                                                                                                                           * Talisman classification/naive-bayes/gaussian\n                                                                                                                                                           * =============================================\n                                                                                                                                                           *\n                                                                                                                                                           * Implementation of the Gaussian Naive-Bayes classifier.\n                                                                                                                                                           *\n                                                                                                                                                           * [Reference]: https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n                                                                                                                                                           */\n\n\n/**\n * The Gaussian Naive Bayes classifier.\n *\n * @constructor\n */\nvar GaussianNaiveBayes = function () {\n  function GaussianNaiveBayes() {\n    _classCallCheck(this, GaussianNaiveBayes);\n  }\n\n  /**\n   * Method used to reset the internal state of the classifier.\n   *\n   * @return {NaiveBayes} - Returns itself for chaining.\n   */\n  GaussianNaiveBayes.prototype.reset = function reset() {\n    this.classes = null;\n    this.priors = null;\n    this.dimensions = 0;\n    this.theta = null;\n    this.sigma = null;\n\n    return this;\n  };\n\n  /**\n   * Method used to train the classifier and taking the dataset's vectors &\n   * labels.\n   *\n   * @param  {array}      features    - Training vectors.\n   * @param  {array}      labels      - Target values.\n   * @return {NaiveBayes}             - Returns itself for chaining.\n   *\n   * @throws {Error} - Will throw if features and labels are not of same length.\n   */\n\n\n  GaussianNaiveBayes.prototype.fit = function fit(features, labels) {\n    var nbVectors = features.length;\n\n    if (nbVectors !== labels.length) throw Error('talisman/classification/naive-bayes/gaussian.fit: given arrays have different lengths.');\n\n    // Resetting internal state\n    this.reset();\n\n    // Classes\n    var classes = {},\n        priors = {};\n\n    // Finding unique classes\n    for (var i = 0, l = labels.length; i < l; i++) {\n      var label = labels[i];\n\n      classes[label] = classes[label] || 0;\n      classes[label]++;\n    }\n\n    for (var k in classes) {\n      priors[k] = classes[k] / nbVectors;\n    } // Lengths\n    var dimensions = features[0].length;\n\n    // Building matrices\n    var matrices = {},\n        offsets = {},\n        featureSets = (0, _matrices.mat)(dimensions, nbVectors);\n\n    for (var _k in classes) {\n      matrices[_k] = (0, _matrices.mat)(dimensions, classes[_k]);\n      offsets[_k] = (0, _vectors.vec)(dimensions, 0);\n    }\n\n    for (var _i = 0; _i < nbVectors; _i++) {\n      var _label = labels[_i],\n          matrix = matrices[_label];\n\n      for (var j = 0; j < dimensions; j++) {\n        matrix[j][offsets[_label][j]++] = features[_i][j];\n        featureSets[j][_i] = features[_i][j];\n      }\n    }\n\n    // Epsilon\n    var maxVariance = Math.max.apply(Math, _toConsumableArray(featureSets.map(_descriptive.variance))),\n        espilon = 1e-9 * maxVariance;\n\n    // Computing means & variances\n    var theta = {},\n        sigma = {};\n\n    for (var _k2 in matrices) {\n      theta[_k2] = [];\n      sigma[_k2] = [];\n\n      for (var _i2 = 0; _i2 < dimensions; _i2++) {\n        theta[_k2][_i2] = (0, _descriptive.mean)(matrices[_k2][_i2]);\n        sigma[_k2][_i2] = (0, _descriptive.variance)(matrices[_k2][_i2]) + espilon;\n      }\n    }\n\n    this.classes = classes;\n    this.priors = priors;\n    this.dimensions = dimensions;\n    this.theta = theta;\n    this.sigma = sigma;\n\n    return this;\n  };\n\n  /**\n   * Method used to get the joint log likelihood for a new vector.\n   *\n   * @param  {array} vector - The vector to classify.\n   * @return {object}       - The probabilities.\n   *\n   * @throw {Error} - The classifier cannot predict if not yet fitted.\n   * @throw {Error} - The classifier expects a vector of correct dimension.\n   */\n\n\n  GaussianNaiveBayes.prototype.jointLogLikelihood = function jointLogLikelihood(vector) {\n    if (!this.theta) throw Error('talisman/classification/naive-bayes/gaussian.probabilities: the classifier is not yet fitted');\n\n    if (vector.length !== this.dimensions) throw Error('talisman/classification/naive-bayes/gaussian.probabilities: the given vector is not of correct dimension (' + vector.length + ' instead of ' + this.dimensions + ').');\n\n    var probabilities = {};\n\n    for (var k in this.classes) {\n      var theta = this.theta[k],\n          sigma = this.sigma[k],\n          jointi = Math.log(this.priors[k]);\n\n      var s1 = 0,\n          s2 = 0;\n\n      for (var i = 0; i < this.dimensions; i++) {\n        var t = theta[i],\n            s = sigma[i],\n            x = vector[i];\n\n        s1 += Math.log(2 * Math.PI * s);\n        s2 += Math.pow(x - t, 2) / s;\n      }\n\n      var nij = -0.5 * s1 - 0.5 * s2;\n      probabilities[k] = jointi + nij;\n    }\n\n    return probabilities;\n  };\n\n  /**\n   * Method used to classify a new vector.\n   *\n   * @param  {array} vector - The vector to classify.\n   * @return {mixed}        - The predicted label.\n   */\n\n\n  GaussianNaiveBayes.prototype.predict = function predict(vector) {\n    var probabilities = this.jointLogLikelihood(vector);\n\n    // Finding the best class\n    var bestClass = null,\n        bestScore = -Infinity;\n\n    for (var k in probabilities) {\n      if (bestScore < probabilities[k]) {\n        bestClass = k;\n        bestScore = probabilities[k];\n      }\n    }\n\n    return bestClass;\n  };\n\n  /**\n   * Method used to export the classifier's model to a JSON representation.\n   *\n   * @return {object} - The JSON model.\n   */\n\n\n  GaussianNaiveBayes.prototype.export = function _export() {\n    return {\n      classes: this.classes,\n      priors: this.priors,\n      dimensions: this.dimensions,\n      theta: this.theta,\n      sigma: this.sigma\n    };\n  };\n\n  /**\n   * Method used to import a JSON model into the classifier.\n   *\n   * @param  {object}     model - The JSON model.\n   * @return {NaiveBayes}       - Returns itself for chaining.\n   */\n\n\n  GaussianNaiveBayes.prototype.import = function _import(model) {\n    this.reset();\n\n    this.classes = model.classes;\n    this.priors = model.priors;\n    this.dimensions = model.dimensions;\n    this.theta = model.theta;\n    this.sigma = model.sigma;\n  };\n\n  /**\n   * Method used to force JSON.stringify to format the classifier using the\n   * #.export method.\n   */\n\n\n  GaussianNaiveBayes.prototype.toJSON = function toJSON() {\n    return this.export();\n  };\n\n  return GaussianNaiveBayes;\n}();\n\nexports.default = GaussianNaiveBayes;\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/classification/naive-bayes/multinomial.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _discrete = require('./discrete');\n\nvar _discrete2 = _interopRequireDefault(_discrete);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /**\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Talisman classification/naive-bayes/multinomial\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * ================================================\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Implementation of the Multinomial Naive-Bayes classifier.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * [Reference]: https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                */\n\n\n/**\n * The Multinomial Naive Bayes classifier.\n *\n * @constructor\n */\nvar MultinomialNaiveBayes = function (_AbstractDiscreteNaiv) {\n  _inherits(MultinomialNaiveBayes, _AbstractDiscreteNaiv);\n\n  function MultinomialNaiveBayes() {\n    _classCallCheck(this, MultinomialNaiveBayes);\n\n    return _possibleConstructorReturn(this, _AbstractDiscreteNaiv.apply(this, arguments));\n  }\n\n  return MultinomialNaiveBayes;\n}(_discrete2.default);\n\nexports.default = MultinomialNaiveBayes;\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/abstract.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * Talisman clustering/record-linkage/abstract\n * ============================================\n *\n * Abstract class used by every record-linkage clusterer to expose a same\n * interface.\n */\n\n/**\n * Defaults.\n */\nvar DEFAULTS = {\n  minClusterSize: 2\n};\n\n/**\n * Record Linkage Clusterer class.\n *\n * @constructor\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\nvar RecordLinkageClusterer = function RecordLinkageClusterer(params, items) {\n  _classCallCheck(this, RecordLinkageClusterer);\n\n  if (!params || (typeof params === 'undefined' ? 'undefined' : _typeof(params)) !== 'object') throw new Error('talisman/clustering/record-linkage: the given params should be an object.');\n\n  if (!Array.isArray(items)) throw new Error('talisman/clustering/record-linkage: the given items should be an array.');\n\n  // Properties\n  this.items = items;\n  this.params = {\n    minClusterSize: params.minClusterSize || DEFAULTS.minClusterSize\n  };\n};\n\nexports.default = RecordLinkageClusterer;\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/blocking.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.BlockingClusterer = undefined;\nexports.default = blocking;\n\nvar _abstract = require('./abstract');\n\nvar _abstract2 = _interopRequireDefault(_abstract);\n\nvar _helpers = require('./helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /**\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Talisman clustering/record-linkage/blocking\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * ============================================\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Clusterer dispatching documents to blocks which we will then cluster. A\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * document may be attached to more than one block since the algorithm uses\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * an inverted index. Time complexity is nb(b-1)/2 where n is the number\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * of blocks and b the average size of a block.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                */\n\n\n/**\n * Blocking Clusterer class.\n *\n * @constructor\n */\nvar BlockingClusterer = exports.BlockingClusterer = function (_RecordLinkageCluster) {\n  _inherits(BlockingClusterer, _RecordLinkageCluster);\n\n  function BlockingClusterer(params, items) {\n    _classCallCheck(this, BlockingClusterer);\n\n    var _this = _possibleConstructorReturn(this, _RecordLinkageCluster.call(this, params, items));\n\n    (0, _helpers.handleSimilarityPolymorphisms)(_this, params);\n\n    var blocker = params.blocks || params.block;\n\n    if (typeof blocker !== 'function') throw new Error('talisman/clustering/record-linkage/blocking: the given blocker is not a function.');\n\n    _this.blocker = blocker;\n    return _this;\n  }\n\n  BlockingClusterer.prototype.run = function run() {\n    var graph = {},\n        blocks = Object.create(null);\n\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      var tokens = [].concat(this.blocker(this.items[i], i));\n\n      for (var j = 0, m = tokens.length; j < m; j++) {\n        var token = tokens[j];\n\n        // We skip falsey tokens\n        if (!token) continue;\n\n        if (!blocks[token]) blocks[token] = [];\n\n        blocks[token].push(i);\n      }\n    }\n\n    for (var k in blocks) {\n      var block = blocks[k];\n\n      for (var _i = 0, _l = block.length; _i < _l; _i++) {\n        var a = this.items[block[_i]];\n\n        for (var _j = _i + 1; _j < _l; _j++) {\n          var b = this.items[block[_j]];\n\n          if (this.similarity(a, b)) {\n            graph[block[_i]] = graph[block[_i]] || new Set();\n            graph[block[_i]].add(block[_j]);\n\n            graph[block[_j]] = graph[block[_j]] || new Set();\n            graph[block[_j]].add(block[_i]);\n          }\n        }\n      }\n    }\n\n    return (0, _helpers.clustersFromSetGraph)(this.items, graph, this.params.minClusterSize);\n  };\n\n  return BlockingClusterer;\n}(_abstract2.default);\n\n/**\n * Shortcut function for the blocking clusterer.\n *\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\n\nfunction blocking(params, items) {\n  var clusterer = new BlockingClusterer(params, items);\n\n  return clusterer.run();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/helpers.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.handleSimilarityPolymorphisms = handleSimilarityPolymorphisms;\nexports.clustersFromArrayGraph = clustersFromArrayGraph;\nexports.clustersFromSetGraph = clustersFromSetGraph;\n/**\n * Talisman clustering/record-linkage/helpers\n * ===========================================\n *\n * Common function used throughout the clustering/record-linkage namespace.\n */\n\n/**\n * Function handling distance/similarity & radius parameter polymorphisms.\n *\n * @param {RecordLinkageClusterer} target - Target instance.\n * @param {object}                 params - Parameters.\n */\nfunction handleSimilarityPolymorphisms(target, params) {\n  if ('radius' in params && typeof params.radius !== 'number') throw new Error('talisman/clustering/record-linkage: the given radius should be a number.');\n\n  if (typeof params.distance !== 'function' && typeof params.similarity !== 'function') throw new Error('talisman/clustering/record-linkage: the clusterer should be given a distance or a similarity function.');\n\n  if ('radius' in params) {\n    target.radius = params.radius;\n\n    if (params.distance) target.similarity = function (a, b) {\n      return params.distance(a, b) <= target.radius;\n    };else target.similarity = function (a, b) {\n      return params.similarity(a, b) >= target.radius;\n    };\n  } else {\n\n    if (params.distance) target.similarity = function (a, b) {\n      return !params.distance(a, b);\n    };else target.similarity = params.similarity;\n  }\n}\n\n// NOTE: it is possible to sort the clusters by size beforehand to make\n// the largest clusters possible, or even to order in reverse\n\n// NOTE: since we'd want to sort by lenghts here, it's possible to use\n// a linear time algorithm such as radix sort\n\n// NOTE: should iterate on graph rather than on items & delete keys from the\n// graph rather than having a set register\n\n/**\n * Function returning a list of clusters from the given items & similarity\n * graph represented as an index of items to the array of neighbors.\n *\n * @param  {array}  items          - List of items.\n * @param  {object} graph          - Similarity graph.\n * @param  {number} minClusterSize - Minimum number of items in a cluster.\n */\nfunction clustersFromArrayGraph(items, graph, minClusterSize) {\n  var clusters = [],\n      visited = new Set();\n\n  var cluster = void 0;\n\n  for (var i = 0, l = items.length; i < l; i++) {\n    var item = items[i];\n\n    if (visited.has(i)) continue;\n\n    if (!graph[i]) continue;\n\n    if (graph[i].length + 1 < minClusterSize) continue;\n\n    cluster = new Array(graph[i].length + 1);\n    cluster[0] = item;\n    visited.add(i);\n\n    // Adding neighbors to the cluster\n    for (var j = 0, m = graph[i].length; j < m; j++) {\n      var neighborIndex = graph[i][j],\n          neighbor = items[neighborIndex];\n\n      cluster[j + 1] = neighbor;\n      visited.add(neighborIndex);\n    }\n\n    clusters.push(cluster);\n  }\n\n  return clusters;\n}\n\n/**\n * Function returning a list of clusters from the given items & similarity\n * graph represented as an index of items to the set of neighbors.\n *\n * @param  {array}  items          - List of items.\n * @param  {object} graph          - Similarity graph.\n * @param  {number} minClusterSize - Minimum number of items in a cluster.\n */\nfunction clustersFromSetGraph(items, graph, minClusterSize) {\n  var clusters = [],\n      visited = new Set();\n\n  var cluster = void 0;\n\n  for (var i = 0, l = items.length; i < l; i++) {\n    var item = items[i];\n\n    if (visited.has(i)) continue;\n\n    if (!graph[i]) continue;\n\n    if (graph[i].size + 1 < minClusterSize) continue;\n\n    cluster = new Array(graph[i].size + 1);\n    cluster[0] = item;\n    visited.add(i);\n\n    // Adding neighbors to the cluster\n    var iterator = graph[i].values();\n\n    var step = void 0,\n        j = 1;\n\n    while ((step = iterator.next()) && !step.done) {\n      var neighborIndex = step.value,\n          neighbor = items[neighborIndex];\n\n      cluster[j] = neighbor;\n      visited.add(neighborIndex);\n      j++;\n    }\n\n    clusters.push(cluster);\n  }\n\n  return clusters;\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/canopy.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.CanopyClusterer = undefined;\nexports.default = canopy;\n\nvar _abstract = require('./abstract');\n\nvar _abstract2 = _interopRequireDefault(_abstract);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /**\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Talisman clustering/record-linkage/canopy\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * ==========================================\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Canopy clustering implementation.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                */\n\n\n/**\n * Canopy Clusterer class.\n *\n * @constructor\n */\nvar CanopyClusterer = exports.CanopyClusterer = function (_RecordLinkageCluster) {\n  _inherits(CanopyClusterer, _RecordLinkageCluster);\n\n  function CanopyClusterer(params, items) {\n    _classCallCheck(this, CanopyClusterer);\n\n    // Validating the distance function\n    var _this = _possibleConstructorReturn(this, _RecordLinkageCluster.call(this, params, items));\n\n    if (typeof params.distance !== 'function') throw new Error('talisman/clustering/record-linkage/canopy: the given distance is not a function.');\n\n    // Validating the thresholds\n    if (typeof params.loose !== 'number') throw new Error('talisman/clustering/record-linkage/canopy: the given loose distance is not a number.');\n    if (typeof params.tight !== 'number') throw new Error('talisman/clustering/record-linkage/canopy: the given tight distance is not a number.');\n\n    if (params.loose < params.tight) throw new Error('talisman/clustering/record-linkage/canopy: loose distance should be greater than tight distance.');\n\n    _this.distance = params.distance;\n    _this.params.loose = params.loose;\n    _this.params.tight = params.tight;\n    return _this;\n  }\n\n  CanopyClusterer.prototype.run = function run() {\n    var itemsIndex = {},\n        clusters = [];\n\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      itemsIndex[i] = true;\n    }for (var k in itemsIndex) {\n      var a = this.items[k];\n\n      // Starting a new canopy\n      delete itemsIndex[k];\n      var cluster = [a];\n\n      // Comparing to other elements in the set\n      for (var k2 in itemsIndex) {\n        var b = this.items[k2],\n            d = this.distance(a, b);\n\n        if (d <= this.params.loose) cluster.push(b);\n\n        if (d <= this.params.tight) delete itemsIndex[k2];\n      }\n\n      clusters.push(cluster);\n    }\n\n    return clusters;\n  };\n\n  return CanopyClusterer;\n}(_abstract2.default);\n\n/**\n * Shortcut function for the canopy clusterer.\n *\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\n\nfunction canopy(params, items) {\n  var clusterer = new CanopyClusterer(params, items);\n\n  return clusterer.run();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/key-collision.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.KeyCollisionClusterer = undefined;\nexports.default = keyCollision;\n\nvar _abstract = require('./abstract');\n\nvar _abstract2 = _interopRequireDefault(_abstract);\n\nvar _helpers = require('./helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /**\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Talisman clustering/record-linkage/key-collision\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * =================================================\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Simple clustering algorithm running in linear time just applying a\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * keying function to each data point and grouping them when the resulting\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * keys collide.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                */\n\n\n/**\n * Key Collision Clusterer class.\n *\n * @constructor\n */\nvar KeyCollisionClusterer = exports.KeyCollisionClusterer = function (_RecordLinkageCluster) {\n  _inherits(KeyCollisionClusterer, _RecordLinkageCluster);\n\n  function KeyCollisionClusterer(params, items) {\n    _classCallCheck(this, KeyCollisionClusterer);\n\n    // Validating keyer\n    var _this = _possibleConstructorReturn(this, _RecordLinkageCluster.call(this, params, items));\n\n    _this.keyer = params.keys || params.key;\n    _this.merge = params.merge || false;\n\n    if (typeof _this.keyer !== 'function') throw new Error('talisman/clustering/record-linkage/key-collision: the given keyer is not a function.');\n    return _this;\n  }\n\n  KeyCollisionClusterer.prototype.runWithMerge = function runWithMerge() {\n    var map = Object.create(null);\n\n    // Computing buckets map\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      var item = this.items[i],\n          keys = [].concat(this.keyer(item, i));\n\n      for (var j = 0, m = keys.length; j < m; j++) {\n        var key = keys[j];\n\n        // If the key is falsy, we continue\n        if (!key) continue;\n\n        if (!map[key]) map[key] = new Set();\n        map[key].add(i);\n      }\n    }\n\n    // Computing graph\n    // TODO: I sense that we can do better & faster\n    var graph = Object.create(null);\n\n    for (var _key in map) {\n      var bucket = Array.from(map[_key]);\n\n      for (var _i = 0, _l = bucket.length; _i < _l; _i++) {\n        for (var _j = _i + 1; _j < _l; _j++) {\n          graph[bucket[_i]] = graph[bucket[_i]] || new Set();\n          graph[bucket[_i]].add(bucket[_j]);\n\n          graph[bucket[_j]] = graph[bucket[_j]] || new Set();\n          graph[bucket[_j]].add(bucket[_i]);\n        }\n      }\n    }\n\n    return (0, _helpers.clustersFromSetGraph)(this.items, graph, this.params.minClusterSize);\n  };\n\n  KeyCollisionClusterer.prototype.runWithoutMerge = function runWithoutMerge() {\n    var map = Object.create(null);\n\n    // Computing buckets map\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      var item = this.items[i],\n          keys = [].concat(this.keyer(item, i));\n\n      for (var j = 0, m = keys.length; j < m; j++) {\n        var key = keys[j];\n\n        // If the key is falsy, we continue\n        if (!key) continue;\n\n        if (!map[key]) map[key] = new Set();\n        map[key].add(item);\n      }\n    }\n\n    // Retrieving clusters\n    var clusters = [];\n\n    for (var _key2 in map) {\n      if (map[_key2].size >= this.params.minClusterSize) clusters.push(Array.from(map[_key2]));\n    }\n\n    return clusters;\n  };\n\n  KeyCollisionClusterer.prototype.run = function run() {\n    if (this.merge) return this.runWithMerge();else return this.runWithoutMerge();\n  };\n\n  return KeyCollisionClusterer;\n}(_abstract2.default);\n\n/**\n * Shortcut function for the key collision clusterer.\n *\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\n\nfunction keyCollision(params, items) {\n  var clusterer = new KeyCollisionClusterer(params, items);\n\n  return clusterer.run();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/leader.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.LeaderClusterer = undefined;\nexports.default = leader;\n\nvar _abstract = require('./abstract');\n\nvar _abstract2 = _interopRequireDefault(_abstract);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /**\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Talisman clustering/record-linkage/leader\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * ==========================================\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * The Leader clustering algorithm is a quite simple algorithm used to partition\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * arbitrary data and running in O(ln) time complexity, l being the number of\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * clusters.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * It's also important to note that the resulting partition might change with\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * the order of given items.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                */\n\n\n/**\n * Leader Clusterer class.\n *\n * @constructor\n */\nvar LeaderClusterer = exports.LeaderClusterer = function (_RecordLinkageCluster) {\n  _inherits(LeaderClusterer, _RecordLinkageCluster);\n\n  function LeaderClusterer(params, items) {\n    _classCallCheck(this, LeaderClusterer);\n\n    // Validating the distance function\n    var _this = _possibleConstructorReturn(this, _RecordLinkageCluster.call(this, params, items));\n\n    if (typeof params.distance !== 'function') throw new Error('talisman/clustering/record-linkage/leader: the given distance is not a function.');\n\n    // Validating the thresholds\n    if (typeof params.threshold !== 'number') throw new Error('talisman/clustering/record-linkage/leader: the given threshold is not a number.');\n\n    _this.distance = params.distance;\n    _this.params.threshold = params.threshold;\n    return _this;\n  }\n\n  LeaderClusterer.prototype.run = function run() {\n    var clusters = [];\n\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      var item = this.items[i];\n\n      var closestClusterIndex = null,\n          closest = Infinity;\n\n      for (var j = 0, m = clusters.length; j < m; j++) {\n        var clusterLeader = clusters[j][0],\n            distance = this.distance(clusterLeader, item);\n\n        if (distance < closest) {\n          closest = distance;\n          closestClusterIndex = j;\n        }\n      }\n\n      if (closest <= this.params.threshold) {\n        clusters[closestClusterIndex].push(item);\n      } else {\n        clusters.push([item]);\n      }\n    }\n\n    return clusters;\n  };\n\n  return LeaderClusterer;\n}(_abstract2.default);\n\n/**\n * Shortcut function for the leader clusterer.\n *\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\n\nfunction leader(params, items) {\n  var clusterer = new LeaderClusterer(params, items);\n\n  return clusterer.run();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/naive.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.NaiveClusterer = undefined;\nexports.default = naive;\n\nvar _abstract = require('./abstract');\n\nvar _abstract2 = _interopRequireDefault(_abstract);\n\nvar _helpers = require('./helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /**\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Talisman clustering/record-linkage/naive\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * =========================================\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Naive clustering working by performing the n(n-1)/2 distance calculations\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * between all relevant pairs. Time complexity of such a clustering is therefore\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * O(n^2), which is quite bad.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Note that the produced clusters are fuzzy.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                */\n\n\n/**\n * Naive Clusterer class.\n *\n * @constructor\n */\nvar NaiveClusterer = exports.NaiveClusterer = function (_RecordLinkageCluster) {\n  _inherits(NaiveClusterer, _RecordLinkageCluster);\n\n  function NaiveClusterer(params, items) {\n    _classCallCheck(this, NaiveClusterer);\n\n    var _this = _possibleConstructorReturn(this, _RecordLinkageCluster.call(this, params, items));\n\n    (0, _helpers.handleSimilarityPolymorphisms)(_this, params);\n    return _this;\n  }\n\n  NaiveClusterer.prototype.run = function run() {\n    var graph = {};\n\n    // Iterating over the needed pairs\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      var a = this.items[i];\n\n      for (var j = i + 1; j < l; j++) {\n        var b = this.items[j];\n\n        if (this.similarity(a, b)) {\n          graph[i] = graph[i] || [];\n          graph[i].push(j);\n\n          // NOTE: undirected link seems to be mandatory for it to work\n          graph[j] = graph[j] || [];\n          graph[j].push(i);\n        }\n      }\n    }\n\n    // Computing clusters\n    return (0, _helpers.clustersFromArrayGraph)(this.items, graph, this.params.minClusterSize);\n  };\n\n  return NaiveClusterer;\n}(_abstract2.default);\n\n/**\n * Shortcut function for the naive clusterer.\n *\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\n\nfunction naive(params, items) {\n  var clusterer = new NaiveClusterer(params, items);\n\n  return clusterer.run();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/nn-descent.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.NNDescentClusterer = undefined;\nexports.default = nnDescent;\n\nvar _abstract = require('./abstract');\n\nvar _abstract2 = _interopRequireDefault(_abstract);\n\nvar _choice = require('pandemonium/choice');\n\nvar _dangerousButPerformantSample = require('pandemonium/dangerous-but-performant-sample');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /* eslint no-constant-condition: 0 */\n/**\n * Talisman clustering/record-linkage/nn-descent\n * ==============================================\n *\n * JavaScript implementation of the NN-Descent algorithm designed to generate\n * k-NN graphs approximations in a performant fashion.\n *\n * [Reference]:\n * http://www.cs.princeton.edu/cass/papers/www11.pdf\n *\n * [Article]:\n * \"Efficient K-Nearest Neighbor Graph Construction for Generic Similarity\n * Measures\" Wei Dong, Moses Charikar, Kai Li.\n */\n\n\n// TODO: JSDoc\n\n/**\n * Defaults.\n */\nvar DEFAULTS = {\n\n  // Sampling coefficient\n  rho: 0.5,\n\n  // Early termination coefficient\n  delta: 0.001,\n\n  // Maximum number of iterations to perform\n  maxIterations: Infinity,\n\n  // RNG to use\n  rng: Math.random\n};\n\n/**\n * NN-Descent Clusterer class.\n *\n * @constructor\n */\n\nvar NNDescentClusterer = exports.NNDescentClusterer = function (_RecordLinkageCluster) {\n  _inherits(NNDescentClusterer, _RecordLinkageCluster);\n\n  function NNDescentClusterer(params, items) {\n    _classCallCheck(this, NNDescentClusterer);\n\n    // Checking rho\n    var _this = _possibleConstructorReturn(this, _RecordLinkageCluster.call(this, params, items));\n\n    _this.rho = params.rho || DEFAULTS.rho;\n\n    if (typeof _this.rho !== 'number' || _this.rho > 1 || _this.rho <= 0) throw new Error('talisman/clustering/record-linkage/nn-descent: rho should be a number greater than 0 and less or equal than 1.');\n\n    // Checking delta\n    _this.delta = params.delta || DEFAULTS.delta;\n\n    if (typeof _this.delta !== 'number' || _this.delta >= 1 || _this.delta <= 0) throw new Error('talisman/clustering/record-linkage/nn-descent: delta should be a number greater than 0 and less than 1.');\n\n    // Checking maxIterations\n    _this.maxIterations = params.maxIterations || DEFAULTS.maxIterations;\n\n    if (_this.maxIterations <= 0) throw new Error('talisman/clustering/record-linkage/nn-descent: maxIterations should be > 0');\n\n    // Checking similarity\n    _this.similarity = params.similarity;\n\n    if (typeof _this.similarity !== 'function') throw new Error('talisman/clustering/record-linkage/nn-descent: similarity should be a function.');\n\n    // Checking RNG\n    _this.rng = params.rng || DEFAULTS.rng;\n\n    if (typeof _this.rng !== 'function') throw new Error('talisman/clustering/record-linkage/nn-descent: rng should be a function.');\n\n    _this.sampleFunction = (0, _dangerousButPerformantSample.createDangerousButPerformantSample)(_this.rng);\n    _this.choiceFunction = (0, _choice.createChoice)(_this.rng);\n\n    // Checking k\n    _this.k = params.k;\n\n    if (typeof _this.k !== 'number' || _this.k <= 0) throw new Error('talisman/clustering/record-linkage/nn-descent: k should be > 0');\n\n    // Properties\n    _this.iterations = 0;\n    _this.computations = 0;\n    _this.c = 0;\n    return _this;\n  }\n\n  NNDescentClusterer.prototype.sampleItems = function sampleItems(forItem) {\n    var _this2 = this;\n\n    var items = new Set(this.sampleFunction(this.k, this.items));\n\n    // The original item should obviously not be in the sample\n    if (items.has(forItem)) {\n      items.delete(forItem);\n\n      while (items.size < this.k) {\n        items.add(this.choiceFunction(this.items));\n      }\n    }\n\n    return Array.from(items).map(function (item) {\n      return {\n        item: item,\n        similarity: _this2.similarity(item, forItem),\n        processed: false\n      };\n    });\n  };\n\n  NNDescentClusterer.prototype.sample = function sample(items, n) {\n\n    // NOTE: Probably possible to mutate here, but not sure.\n    if (items.length <= n) return items.slice();\n\n    return this.sampleFunction(n, items);\n  };\n\n  NNDescentClusterer.prototype.pickFalses = function pickFalses(elements) {\n    var list = [];\n\n    for (var i = 0, l = elements.length; i < l; i++) {\n      var element = elements[i];\n\n      if (element.processed) list.push(element.item);\n    }\n\n    return list;\n  };\n\n  NNDescentClusterer.prototype.pickTruesAndMarkFalses = function pickTruesAndMarkFalses(elements) {\n    var list = [];\n\n    for (var i = 0, l = elements.length; i < l; i++) {\n      var element = elements[i];\n\n      if (!element.processed && this.rng() < this.rho) {\n        element.processed = true;\n        list.push(element.item);\n      }\n    }\n\n    return list;\n  };\n\n  NNDescentClusterer.prototype.reverse = function reverse(lists) {\n    var R = new Map();\n\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      R.set(this.items[i], []);\n    }for (var _i = 0, _l = this.items.length; _i < _l; _i++) {\n      var item = this.items[_i],\n          list = lists.get(item);\n\n      for (var j = 0, m = list.length; j < m; j++) {\n        R.get(list[j]).push(item);\n      }\n    }\n\n    return R;\n  };\n\n  NNDescentClusterer.prototype.union = function union(a, b) {\n    var set = new Set(a);\n\n    for (var i = 0, l = b.length; i < l; i++) {\n      set.add(b[i]);\n    }return Array.from(set);\n  };\n\n  NNDescentClusterer.prototype.updateNN = function updateNN(K, item, similarity) {\n\n    // NOTE: this is a naive approach that could be bested by a priority queue\n    // or by caching the min similarity + holding elements in a Set\n    var minSimilarity = Infinity,\n        minSimilarityIndex = -1;\n\n    for (var i = 0, l = K.length; i < l; i++) {\n      var element = K[i];\n\n      if (item === element.item) return;\n\n      if (element.similarity < minSimilarity) {\n        minSimilarity = element.similarity;\n        minSimilarityIndex = i;\n      }\n    }\n\n    if (minSimilarity < similarity) {\n\n      // Replacing the item\n      K[minSimilarityIndex] = {\n        item: item,\n        similarity: similarity,\n        processed: false\n      };\n\n      // NOTE: we could avoid to store c in instance state by making this\n      // function return something meaningful.\n      this.c++;\n    }\n  };\n\n  NNDescentClusterer.prototype.run = function run() {\n    var B = new Map(),\n        rhok = Math.ceil(this.rho * this.k);\n\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      var item = this.items[i];\n\n      B.set(item, this.sampleItems(item));\n    }\n\n    var before = new Map(),\n        current = new Map();\n\n    // Performing the iterations\n    while (true) {\n      this.iterations++;\n      this.c = 0;\n\n      for (var _i2 = 0, _l2 = this.items.length; _i2 < _l2; _i2++) {\n        var _item = this.items[_i2];\n\n        before.set(_item, this.pickFalses(B.get(_item)));\n        current.set(_item, this.pickTruesAndMarkFalses(B.get(_item)));\n      }\n\n      var before2 = this.reverse(before),\n          current2 = this.reverse(current);\n\n      for (var _i3 = 0, _l3 = this.items.length; _i3 < _l3; _i3++) {\n        var _item2 = this.items[_i3];\n\n        before.set(_item2, this.union(before.get(_item2), this.sample(before2.get(_item2), rhok)));\n\n        current.set(_item2, this.union(current.get(_item2), this.sample(current2.get(_item2), rhok)));\n\n        var currentTargets = current.get(_item2),\n            beforeTargets = before.get(_item2);\n\n        for (var j = 0, m = currentTargets.length; j < m; j++) {\n          var u1 = currentTargets[j];\n\n          for (var k = j + 1; k < m; k++) {\n            var u2 = currentTargets[k],\n                similarity = this.similarity(u1, u2);\n\n            this.computations++;\n\n            this.updateNN(B.get(u1), u2, similarity);\n            this.updateNN(B.get(u2), u1, similarity);\n          }\n\n          for (var _k = 0, n = beforeTargets.length; _k < n; _k++) {\n            var _u = beforeTargets[_k];\n\n            if (u1 === _u) continue;\n\n            var _similarity = this.similarity(u1, _u);\n\n            this.computations++;\n\n            this.updateNN(B.get(u1), _u, _similarity);\n            this.updateNN(B.get(_u), u1, _similarity);\n          }\n        }\n      }\n\n      // Termination?\n      // console.log('iteration', this.c, this.delta * this.items.length * this.k, this.computations);\n      if (this.iterations >= this.maxIterations || this.c <= this.delta * this.items.length * this.k) break;\n    }\n\n    return B;\n  };\n\n  return NNDescentClusterer;\n}(_abstract2.default);\n\n/**\n * Shortcut function for the NN-Descent clusterer.\n *\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\n\nfunction nnDescent(params, items) {\n  var clusterer = new NNDescentClusterer(params, items);\n\n  return clusterer.run();\n}\nmodule.exports = exports['default'];\nexports['default'].NNDescentClusterer = exports.NNDescentClusterer;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/sorted-neighborhood.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.SortedNeighborhoodClusterer = undefined;\nexports.default = sortedNeighborhood;\n\nvar _abstract = require('./abstract');\n\nvar _abstract2 = _interopRequireDefault(_abstract);\n\nvar _helpers = require('./helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /**\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Talisman clustering/record-linkage/sorted-neighborhood\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * =======================================================\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Clustering method first sorting the dataset before applying pairwise\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * comparisons only within the given window. Time complexity is quite\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * better than the naive approach: O(n(w+log n)).\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                */\n\n\n/**\n * Sorted Neighborhood Clusterer class.\n *\n * @constructor\n */\nvar SortedNeighborhoodClusterer = exports.SortedNeighborhoodClusterer = function (_RecordLinkageCluster) {\n  _inherits(SortedNeighborhoodClusterer, _RecordLinkageCluster);\n\n  function SortedNeighborhoodClusterer(params, items) {\n    _classCallCheck(this, SortedNeighborhoodClusterer);\n\n    var _this = _possibleConstructorReturn(this, _RecordLinkageCluster.call(this, params, items));\n\n    (0, _helpers.handleSimilarityPolymorphisms)(_this, params);\n\n    if (typeof params.window !== 'number' || params.window < 1) throw new Error('talisman/clustering/record-linkage/sorted-neighborhood: the given window should be a number > 0.');\n\n    _this.window = params.window;\n\n    var comparators = [].concat(params.comparator || params.comparators);\n\n    if (comparators.some(function (comparator) {\n      return typeof comparator !== 'function';\n    })) throw new Error('talisman/clustering/record-linkage/sorted-neighborhood: the given comparators should all be functions.');\n\n    _this.comparators = comparators;\n\n    // Cloning items because we are going to mutate the array\n    _this.sorted = new Array(_this.items.length);\n\n    for (var i = 0, l = _this.items.length; i < l; i++) {\n      _this.sorted[i] = i;\n    }\n    return _this;\n  }\n\n  SortedNeighborhoodClusterer.prototype.run = function run() {\n    var _this2 = this;\n\n    var graph = {},\n        w = this.window;\n\n    // Applying comparators\n\n    var _loop = function _loop(c, d) {\n      var comparator = _this2.comparators[c];\n\n      // Sorting items\n      _this2.sorted.sort(function (a, b) {\n        return comparator(_this2.items[a], _this2.items[b]);\n      });\n\n      // Performing pairwise comparisons within allowed window\n      for (var i = 0, l = _this2.sorted.length; i < l; i++) {\n        var aIndex = _this2.sorted[i],\n            a = _this2.items[aIndex];\n\n        for (var j = i + 1, m = Math.min(l, 1 + i + w); j < m; j++) {\n          var bIndex = _this2.sorted[j],\n              b = _this2.items[bIndex];\n\n          if (_this2.similarity(a, b)) {\n            graph[aIndex] = graph[aIndex] || new Set();\n            graph[aIndex].add(bIndex);\n\n            // NOTE: undirected link seems to be mandatory for it to work\n            graph[bIndex] = graph[bIndex] || new Set();\n            graph[bIndex].add(aIndex);\n          }\n        }\n      }\n    };\n\n    for (var c = 0, d = this.comparators.length; c < d; c++) {\n      _loop(c, d);\n    }\n\n    return (0, _helpers.clustersFromSetGraph)(this.items, graph, this.params.minClusterSize);\n  };\n\n  return SortedNeighborhoodClusterer;\n}(_abstract2.default);\n\n/**\n * Shortcut function for the sorted neighborhood clusterer.\n *\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\n\nfunction sortedNeighborhood(params, items) {\n  var clusterer = new SortedNeighborhoodClusterer(params, items);\n\n  return clusterer.run();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/clustering/record-linkage/vp-tree.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.VPTreeClusterer = undefined;\nexports.default = vpTree;\n\nvar _vpTree = require('mnemonist/vp-tree');\n\nvar _vpTree2 = _interopRequireDefault(_vpTree);\n\nvar _abstract = require('./abstract');\n\nvar _abstract2 = _interopRequireDefault(_abstract);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } /**\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Talisman clustering/record-linkage/vp-tree\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * ===========================================\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                *\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * Clustering method using a Vantage Point Tree (VPTree) to find the clusters\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                * more efficiently.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                */\n\n\n/**\n * Vantage Point Tree Clusterer class.\n *\n * @constructor\n */\nvar VPTreeClusterer = exports.VPTreeClusterer = function (_RecordLinkageCluster) {\n  _inherits(VPTreeClusterer, _RecordLinkageCluster);\n\n  function VPTreeClusterer(params, items) {\n    _classCallCheck(this, VPTreeClusterer);\n\n    // Validating radius\n    var _this = _possibleConstructorReturn(this, _RecordLinkageCluster.call(this, params, items));\n\n    if (typeof params.radius !== 'number') throw new Error('talisman/clustering/record-linkage/vp-tree: the given radius is not a number.');\n\n    // Validating the distance function\n    if (typeof params.distance !== 'function') throw new Error('talisman/clustering/record-linkage/vp-tree: the given distance is not a function.');\n\n    // Properties\n    _this.radius = params.radius;\n    _this.distance = params.distance;\n    return _this;\n  }\n\n  VPTreeClusterer.prototype.run = function run() {\n\n    // Building the tree\n    var tree = new _vpTree2.default(this.distance, this.items);\n\n    // Retrieving the clusters\n    var clusters = [],\n        visited = new Set();\n\n    for (var i = 0, l = this.items.length; i < l; i++) {\n      var item = this.items[i];\n\n      if (visited.has(item)) continue;\n\n      var neighbors = tree.neighbors(this.radius, item);\n\n      var cluster = new Array(neighbors.length);\n\n      for (var j = 0, m = neighbors.length; j < m; j++) {\n        visited.add(neighbors[j].item);\n        cluster[j] = neighbors[j].item;\n      }\n\n      if (cluster.length >= this.params.minClusterSize) clusters.push(cluster);\n    }\n\n    return clusters;\n  };\n\n  return VPTreeClusterer;\n}(_abstract2.default);\n\n/**\n * Shortcut function for the vantage point tree clusterer.\n *\n * @param {object} params - Clusterer parameters.\n * @param {array}  items  - Items to cluster.\n */\n\n\nfunction vpTree(params, items) {\n  var clusterer = new VPTreeClusterer(params, items);\n\n  return clusterer.run();\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/features/extraction/vectorizers.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.collectionVectorizer = collectionVectorizer;\nexports.bagOfWordsVectorizer = bagOfWordsVectorizer;\nexports.countVectorizer = countVectorizer;\nexports.tfidfVectorizer = tfidfVectorizer;\n/* eslint no-loop-func: 0 */\n/**\n * Talisman features/extraction/vectorizers\n * =========================================\n *\n * Compilation of vectorizers aiming at transforming data into\n * feature matrices used by machine learning methods.\n */\n\n/**\n * Vectorizer taking a collection as input and outputting a feature matrix.\n *\n * @param  {object}   options             - Options to customize the output.\n * @param  {function} [options.type]      - Array class to use.\n * @param  {string}   [options.separator] - Separator to use in qualitative\n *                                          headers name.\n * @param  {array}    collection          - The target collection (array of\n *                                          objects).\n * @return {object}                       - An object containing the result\n *                                          (meta, headers & features).\n */\nvar DEFAULT_COLLECTION_OPTIONS = {\n  type: Array,\n  separator: '='\n};\n\nfunction collectionVectorizer(options, collection) {\n  options = options || {};\n\n  var ArrayClass = options.type || DEFAULT_COLLECTION_OPTIONS.type,\n      separator = options.separator || DEFAULT_COLLECTION_OPTIONS.separator;\n\n  // Doing a first pass to assess the content of the collection\n  var fields = {};\n\n  for (var i = 0, l = collection.length; i < l; i++) {\n    var item = collection[i];\n\n    // Checking every field\n    for (var k in item) {\n      var value = item[k],\n          quantitative = typeof value === 'number';\n\n      if (!(k in fields)) {\n        fields[k] = {\n          values: new Set(),\n          quantitative: quantitative\n        };\n      }\n\n      fields[k].values.add('' + value);\n      fields[k].quantitative = fields[k].quantitative && quantitative;\n    }\n  }\n\n  // Building the meta\n  var meta = {},\n      quantitativeFields = new Set();\n\n  var length = 0;\n\n  var _loop = function _loop(_k) {\n    var _fields$_k = fields[_k],\n        quantitative = _fields$_k.quantitative,\n        values = _fields$_k.values;\n\n\n    if (quantitative) {\n      meta[_k] = {\n        index: length++,\n        quantitative: quantitative\n      };\n\n      quantitativeFields.add(_k);\n    } else {\n      values.forEach(function (value) {\n        meta['' + _k + separator + value] = {\n          index: length++,\n          quantitative: quantitative\n        };\n      });\n    }\n  };\n\n  for (var _k in fields) {\n    _loop(_k);\n  }\n\n  // Building the features matrix\n  var features = new Array(collection.length);\n\n  for (var _i = 0, _l = collection.length; _i < _l; _i++) {\n    var _item = collection[_i];\n\n    features[_i] = new ArrayClass(length);\n\n    for (var _k2 in _item) {\n      var _value = _item[_k2],\n          _quantitative = quantitativeFields.has(_k2),\n          h = _quantitative ? _k2 : '' + _k2 + separator + _value,\n          index = meta[h].index;\n\n      features[_i][index] = _quantitative ? _value : 1;\n    }\n  }\n\n  // Building the headers\n  var headers = Object.keys(meta).map(function (k) {\n    return k;\n  });\n\n  return {\n    headers: headers,\n    meta: meta,\n    features: features\n  };\n}\n\n/**\n * Vectorizer taking a list of tokenized documents as input and outputting a\n * \"bag of words\" features matrix.\n *\n * @param  {object}   options             - Options to customize the output.\n * @param  {function} [options.type]      - Array class to use.\n * @param  {array}    documents           - The documents to process.\n * @return {object}                       - An object containing the result\n *                                          (meta, headers & features).\n */\nvar DEFAULT_TEXT_OPTIONS = {\n  type: Array\n};\n\nfunction bagOfWordsVectorizer(options, documents) {\n  options = options || {};\n\n  var ArrayClass = options.type || DEFAULT_TEXT_OPTIONS.type;\n\n  // Iterating through documents to gather every word\n  var words = {};\n  var index = 0;\n\n  for (var i = 0, l = documents.length; i < l; i++) {\n    var doc = documents[i];\n\n    for (var j = 0, m = doc.length; j < m; j++) {\n      if (!(doc[j] in words)) words[doc[j]] = index++;\n    }\n  }\n\n  // Building headers & features matrix\n  var headers = Object.keys(words),\n      features = new Array(documents.length);\n\n  for (var _i2 = 0, _l2 = documents.length; _i2 < _l2; _i2++) {\n    var _doc = documents[_i2];\n\n    features[_i2] = new ArrayClass(headers.length);\n\n    for (var _j = 0, _m = _doc.length; _j < _m; _j++) {\n      features[_i2][words[_doc[_j]]] = 1;\n    }\n  }\n\n  return {\n    headers: headers,\n    features: features\n  };\n}\n\n/**\n * Vectorizer taking a list of tokenized documents as input and outputting a\n * features matrix containing the count of each word in the document.\n *\n * @param  {object}   options             - Options to customize the output.\n * @param  {function} [options.type]      - Array class to use.\n * @param  {array}    documents           - The documents to process.\n * @return {object}                       - An object containing the result\n *                                          (meta, headers & features).\n */\nfunction countVectorizer(options, documents) {\n  options = options || {};\n\n  var ArrayClass = options.type || DEFAULT_TEXT_OPTIONS.type;\n\n  // Iterating through documents to gather every word\n  var words = {};\n  var index = 0;\n\n  for (var i = 0, l = documents.length; i < l; i++) {\n    var doc = documents[i];\n\n    for (var j = 0, m = doc.length; j < m; j++) {\n      if (!(doc[j] in words)) words[doc[j]] = index++;\n    }\n  }\n\n  // Building headers & features matrix\n  var headers = Object.keys(words),\n      features = new Array(documents.length);\n\n  for (var _i3 = 0, _l3 = documents.length; _i3 < _l3; _i3++) {\n    var _doc2 = documents[_i3];\n\n    features[_i3] = new ArrayClass(headers.length);\n\n    for (var _j2 = 0, _m2 = _doc2.length; _j2 < _m2; _j2++) {\n      var k = words[_doc2[_j2]];\n      features[_i3][k] = features[_i3][k] || 0;\n      features[_i3][k]++;\n    }\n  }\n\n  return {\n    headers: headers,\n    features: features\n  };\n}\n\n/**\n * Vectorizer taking a list of tokenized documents as input and outputting a\n * features matrix containing the tfidf metric for each word in the document.\n *\n * @param  {object}   options             - Options to customize the output.\n * @param  {function} [options.type]      - Array class to use.\n * @param  {array}    documents           - The documents to process.\n * @return {object}                       - An object containing the result\n *                                          (meta, headers & features).\n */\nfunction tfidfVectorizer(options, documents) {\n  options = options || {};\n\n  var ArrayClass = options.type || DEFAULT_TEXT_OPTIONS.type;\n\n  // Iterating through documents to gather every word\n  var words = {},\n      termFrequencies = [];\n\n  var index = 0;\n\n  for (var i = 0, l = documents.length; i < l; i++) {\n    var doc = documents[i];\n\n    termFrequencies.push({});\n\n    for (var j = 0, m = doc.length; j < m; j++) {\n      var word = doc[j];\n\n      if (!(word in words)) words[word] = {\n        index: index++,\n        idf: 0\n      };\n\n      words[word].idf++;\n\n      termFrequencies[i][word] = termFrequencies[i][word] || 0;\n      termFrequencies[i][word]++;\n    }\n  }\n\n  // Computing inverse document frequencies\n  for (var _word in words) {\n    words[_word].idf = Math.log(documents.length / words[_word].idf);\n  } // Building headers & features matrix\n  var headers = Object.keys(words),\n      features = new Array(documents.length);\n\n  for (var _i4 = 0, _l4 = documents.length; _i4 < _l4; _i4++) {\n    var _doc3 = documents[_i4],\n        tfs = termFrequencies[_i4];\n\n    features[_i4] = new ArrayClass(headers.length);\n\n    for (var _j3 = 0, _m3 = _doc3.length; _j3 < _m3; _j3++) {\n      var _words$_doc3$_j = words[_doc3[_j3]],\n          k = _words$_doc3$_j.index,\n          idf = _words$_doc3$_j.idf;\n\n      features[_i4][k] = tfs[_doc3[_j3]] * idf;\n    }\n  }\n\n  return {\n    headers: headers,\n    features: features\n  };\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/inflectors/spanish/noun.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.singularize = singularize;\n\nvar _helpers = require('../../helpers');\n\n/**\n * Constants.\n */\nvar ACCENT_MAP = (0, _helpers.translation)('AEIOUaeiou', 'ÁÉÍÓÚáéíóú'); /**\n                                                                         * Talisman inflectors/spanish/noun\n                                                                         * =================================\n                                                                         *\n                                                                         * A noun inflector for the Spanish language.\n                                                                         *\n                                                                         * [Reference]:\n                                                                         * https://github.com/bermi/Python-Inflector\n                                                                         *\n                                                                         * [Auhors]:\n                                                                         * Bermi Ferrer Martinez\n                                                                         * Carles Sadurní Anguita\n                                                                         */\n\n\nvar SINGULAR_RULES = [[/^([bcdfghjklmnñpqrstvwxyz]*)([aeiou])([ns])es$/i, '$1$2$3'], [/([aeiou])([ns])es$/i, '$1$2', true], [/shes$/i, 'sh'], [/oides$/i, 'oide'], [/(sis|tis|xis)$/i, '$1'], [/(é)s$/i, '$1'], [/(ces)$/i, 'z'], [/([^e])s$/i, '$1'], [/([bcdfghjklmnñprstvwxyz]{2,}e)s$/i, '$1'], [/([ghñptv]e)s$/i, '$1'], [/jes$/i, 'je'], [/ques$/i, 'que'], [/es$/i, '']];\n\nvar IMMUTABLE_WORDS = new Set(['lunes', 'martes', 'miércoles', 'jueves', 'viernes', 'paraguas', 'tijeras', 'gafas', 'vacaciones', 'víveres', 'cumpleaños', 'virus', 'atlas', 'sms', 'hummus']);\n\nvar IRREGULAR_SINGULAR_TO_PLURAL = {\n  base: 'bases',\n  carácter: 'caracteres',\n  champú: 'champús',\n  curriculum: 'currículos',\n  espécimen: 'especímenes',\n  jersey: 'jerséis',\n  memorándum: 'memorandos',\n  menú: 'menús',\n  no: 'noes',\n  país: 'países',\n  referéndum: 'referendos',\n  régimen: 'regímenes',\n  sándwich: 'sándwiches',\n  si: 'sis',\n  taxi: 'taxis',\n  ultimátum: 'ultimatos'\n};\n\nvar IRREGULAR_PLURAL_TO_SINGULAR = {};\n\nfor (var singular in IRREGULAR_SINGULAR_TO_PLURAL) {\n  IRREGULAR_PLURAL_TO_SINGULAR[IRREGULAR_SINGULAR_TO_PLURAL[singular]] = singular;\n} /**\n   * Function used to apply source word's case to target word.\n   *\n   * @param  {string} source - Source word.\n   * @param  {string} target - Target word.\n   * @return {string}\n   */\nfunction transferCase(source, target) {\n  var cased = '';\n\n  for (var i = 0, l = target.length; i < l; i++) {\n    var c = source[i].toLowerCase() === source[i].toLowerCase() ? 'toLowerCase' : 'toUpperCase';\n\n    cased += target[i][c]();\n  }\n\n  return cased;\n}\n\n/**\n * Function used to inflect nouns to their singular form.\n *\n * @param  {string} noun - Noun to inflect.\n * @return {string}      - The singular version.\n */\nfunction singularize(noun) {\n  var lowerCaseNoun = noun.toLowerCase();\n\n  // Checking immutable words\n  if (IMMUTABLE_WORDS.has(lowerCaseNoun)) return noun;\n\n  // Checking irregulars\n  var irregular = IRREGULAR_PLURAL_TO_SINGULAR[noun];\n\n  if (irregular) return transferCase(noun, irregular);\n\n  // Applying rules\n  for (var i = 0, l = SINGULAR_RULES.length; i < l; i++) {\n    var _SINGULAR_RULES$i = SINGULAR_RULES[i],\n        pattern = _SINGULAR_RULES$i[0],\n        replacement = _SINGULAR_RULES$i[1],\n        accent = _SINGULAR_RULES$i[2];\n\n\n    var match = pattern.test(noun);\n\n    if (match) {\n\n      var _singular = void 0;\n\n      // Watching out for accents\n      if (accent) _singular = noun.replace(pattern, function (_, m1, m2) {\n        return ACCENT_MAP[m1] + m2;\n      });else _singular = noun.replace(pattern, replacement);\n\n      return _singular;\n    }\n  }\n\n  return noun;\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/bag.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = bag;\n/**\n * Talisman metrics/distance/bag\n * ==============================\n *\n * Function computing the bag distance which works likewise which is the max\n * of the difference of multiset a & multiset b and the difference of\n * multiset b & multiset a.\n *\n * [Reference]:\n * http://www-db.disi.unibo.it/research/papers/SPIRE02.pdf\n *\n * [Article]:\n * String Matching with Metric Trees Using an Approximate Distance.\n * Ilaria Bartolini, Paolo Ciaccia, and Marco Patella.\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Function returning the bag distance.\n *\n * @param  {mixed}  a - The first sequence.\n * @param  {mixed}  b - The second sequence.\n * @return {number}   - The bag distance.\n */\nfunction bag(a, b) {\n  if (a === b) return 0;\n\n  var ma = Object.create(null),\n      mb = Object.create(null);\n\n  var da = a.length,\n      db = b.length;\n\n  if (!da) return db;\n  if (!db) return da;\n\n  var longest = Math.max(da, db);\n\n  for (var i = 0; i < longest; i++) {\n    if (i < da) {\n      var value = a[i];\n\n      if (!ma[value]) ma[value] = 0;\n      ma[value]++;\n    }\n\n    if (i < db) {\n      var _value = b[i];\n\n      if (!mb[_value]) mb[_value] = 0;\n      mb[_value]++;\n    }\n  }\n\n  for (var k in ma) {\n    if (mb[k]) da -= Math.min(ma[k], mb[k]);\n  }\n\n  for (var _k in mb) {\n    if (ma[_k]) db -= Math.min(mb[_k], ma[_k]);\n  }\n\n  return Math.max(da, db);\n}\nmodule.exports = exports[\"default\"];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/canberra.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = canberra;\n/**\n * Talisman metrics/distance/canberra\n * ===================================\n *\n * Function computing the Canberra distance.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Canberra_distance\n *\n * [Tags]: metric, vector space.\n */\n\n/**\n * Function returning the Canberra distance between two vectors.\n *\n * @param  {mixed}  a     - The first vector.\n * @param  {mixed}  b     - The second vector.\n * @return {number}       - The Canberra distance between a & b.\n *\n * @throws {Error} The function expects vectors of same dimension.\n */\nfunction canberra(a, b) {\n  if (a.length !== b.length) throw Error('talisman/metrics/distance/canberra: the given vectors are not of the same dimension.');\n\n  var distance = 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    distance += Math.abs(a[i] - b[i]) / (Math.abs(a[i]) + Math.abs(b[i]));\n  }return distance;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/chebyshev.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = chebyshev;\n/**\n * Talisman metrics/distance/chebyshev\n * ====================================\n *\n * Function computing the Chebyshev distance.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Chebyshev_distance\n *\n * [Tags]: metric, vector space.\n */\n\n/**\n * Function returning the Chebyshev distance between two vectors.\n *\n * @param  {mixed}  a     - The first vector.\n * @param  {mixed}  b     - The second vector.\n * @return {number}       - The Chebyshev distance between a & b.\n *\n * @throws {Error} The function expects vectors of same dimension.\n */\nfunction chebyshev(a, b) {\n  if (a.length !== b.length) throw Error('talisman/metrics/distance/chebyshev: the given vectors are not of the same dimension.');\n\n  var distance = 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    distance = Math.max(distance, Math.abs(a[i] - b[i]));\n  }return distance;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/cosine.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.default = cosine;\nexports.distance = distance;\n/**\n * Talisman metrics/distance/cosine\n * =================================\n *\n * Function computing the cosine similarity.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Cosine_similarity\n *\n * [Tags]: semimetric.\n */\n\n/**\n * Function returning the cosine similarity between two vectors.\n *\n * @param  {mixed}  a - The first vector.\n * @param  {mixed}  b - The second vector.\n * @return {number}   - The cosine similarity between a & b.\n *\n * @throws {Error} The function expects vectors of same dimension.\n */\nfunction cosine(a, b) {\n  if (a.length !== b.length) throw Error('talisman/metrics/distance/cosine: the given vectors are not of the same dimension.');\n\n  var xx = 0,\n      xy = 0,\n      yy = 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    var x = a[i],\n        y = b[i];\n\n    xx += x * x;\n    yy += y * y;\n    xy += x * y;\n  }\n\n  return xy / Math.sqrt(xx * yy);\n}\n\n/**\n * Cosine distance is 1 - the cosine similarity.\n */\nfunction distance(a, b) {\n  return 1 - cosine(a, b);\n}\n\nexports.similarity = cosine;\nmodule.exports = exports['default'];\nexports['default'].distance = exports.distance;\nexports['default'].similarity = exports.similarity;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/damerau-levenshtein.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.default = damerauLevenshtein;\nexports.limited = limited;\n/**\n * Talisman metrics/distance/damerau-levenshtein\n * ==============================================\n *\n * Functions computing the Damerau-Levenshtein distance.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance\n *\n * [Original Code]:\n * http://blog.softwx.net/2015/01/optimizing-damerau-levenshtein_15.html\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Function returning the Damerau-Levenshtein distance between two sequences.\n *\n * @param  {mixed}  a  - The first sequence to process.\n * @param  {mixed}  b  - The second sequence to process.\n * @return {number}    - The Damerau-Levenshtein distance between a & b.\n */\nfunction damerauLevenshtein(a, b) {\n  if (a === b) return 0;\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la) return lb;\n  if (!lb) return la;\n\n  // Swapping the strings so that the shorter string is the first one.\n  if (la > lb) {\n    var _ref = [b, a];\n    a = _ref[0];\n    b = _ref[1];\n    var _ref2 = [lb, la];\n    la = _ref2[0];\n    lb = _ref2[1];\n  }\n\n  // Ignoring common suffix\n  while (la > 0 && a[la - 1] === b[lb - 1]) {\n    la--;\n    lb--;\n  }\n\n  var start = 0;\n\n  // If a common prefix exists of if a is a full b suffix\n  if (a[0] === b[0] || !la) {\n\n    // Common prefix can also be ignored\n    while (start < la && a[start] === b[start]) {\n      start++;\n    }la -= start;\n    lb -= start;\n\n    if (!la) return lb;\n\n    b = b.slice(start, start + lb);\n  }\n\n  var v0 = new Array(lb),\n      v2 = new Array(lb);\n\n  for (var i = 0; i < lb; i++) {\n    v0[i] = i + 1;\n  }var charA = a[0],\n      current = 0;\n\n  // Starting the nested loops\n  for (var _i = 0; _i < la; _i++) {\n    var previousCharA = charA;\n\n    var nextTranspositionCost = 0,\n        charB = b[0],\n        left = _i;\n\n    current = _i + 1;\n    charA = a[start + _i];\n\n    for (var j = 0; j < lb; j++) {\n      var above = current,\n          previousCharB = charB;\n\n      var thisTranspositionCost = nextTranspositionCost;\n\n      charB = b[j];\n      nextTranspositionCost = v2[j];\n      v2[j] = current = left;\n      left = v0[j];\n\n      if (charA !== charB) {\n\n        // Insertion\n        if (left < current) current = left;\n\n        // Deletion\n        if (above < current) current = above;\n\n        current++;\n\n        // Transposition\n        if (_i !== 0 && j !== 0 && charA === previousCharB && charB === previousCharA) {\n          thisTranspositionCost++;\n\n          if (thisTranspositionCost < current) current = thisTranspositionCost;\n        }\n      }\n\n      v0[j] = current;\n    }\n  }\n\n  return current;\n}\n\n/**\n * Function returning the Damerau-Levenshtein distance between two sequences\n * but with a twist: this version will stop its computation if distance\n * exceed a given maximum and return Infinity.\n *\n * @param  {number} max - Maximum distance.\n * @param  {mixed}  a   - The first sequence to process.\n * @param  {mixed}  b   - The second sequence to process.\n * @return {number}     - The Damerau-Levenshtein distance between a & b or Infinity.\n */\nfunction limited(max, a, b) {\n  if (a === b) return 0;\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la) return lb > max ? Infinity : lb;\n  if (!lb) return la > max ? Infinity : la;\n\n  // Swapping the strings so that the shorter string is the first one.\n  if (la > lb) {\n    var _ref3 = [b, a];\n    a = _ref3[0];\n    b = _ref3[1];\n    var _ref4 = [lb, la];\n    la = _ref4[0];\n    lb = _ref4[1];\n  }\n\n  // Ignoring common suffix\n  while (la > 0 && a[la - 1] === b[lb - 1]) {\n    la--;\n    lb--;\n  }\n\n  var start = 0;\n\n  // If a common prefix exists of if a is a full b suffix\n  if (a[0] === b[0] || !la) {\n\n    // Common prefix can also be ignored\n    while (start < la && a[start] === b[start]) {\n      start++;\n    }la -= start;\n    lb -= start;\n\n    if (!la) return lb > max ? Infinity : lb;\n\n    b = b.slice(start, start + lb);\n  }\n\n  var diff = lb - la;\n\n  if (max > lb) max = lb;else if (diff > max) return Infinity;\n\n  var v0 = new Array(lb),\n      v2 = new Array(lb);\n\n  var i = void 0;\n  for (i = 0; i < max; i++) {\n    v0[i] = i + 1;\n  }for (; i < lb; i++) {\n    v0[i] = max + 1;\n  }var offset = max - diff,\n      haveMax = max < lb;\n\n  var jStart = 0,\n      jEnd = max;\n\n  var charA = a[0],\n      current = 0;\n\n  // Starting the nested loops\n  for (i = 0; i < la; i++) {\n    var previousCharA = charA;\n\n    var nextTranspositionCost = 0,\n        charB = b[0],\n        left = i;\n\n    current = i + 1;\n    charA = a[start + i];\n    jStart += i > offset ? 1 : 0;\n    jEnd += jEnd < lb ? 1 : 0;\n\n    for (var j = jStart; j < jEnd; j++) {\n      var above = current,\n          previousCharB = charB;\n\n      var thisTranspositionCost = nextTranspositionCost;\n\n      charB = b[j];\n      nextTranspositionCost = v2[j];\n      v2[j] = current = left;\n      left = v0[j];\n\n      if (charA !== charB) {\n\n        // Insertion\n        if (left < current) current = left;\n\n        // Deletion\n        if (above < current) current = above;\n\n        current++;\n\n        // Transposition\n        if (i !== 0 && j !== 0 && charA === previousCharB && charB === previousCharA) {\n          thisTranspositionCost++;\n\n          if (thisTranspositionCost < current) current = thisTranspositionCost;\n        }\n      }\n\n      v0[j] = current;\n    }\n\n    if (haveMax && v0[i + diff] > max) return Infinity;\n  }\n\n  return current <= max ? current : Infinity;\n}\nmodule.exports = exports[\"default\"];\nexports[\"default\"].limited = exports.limited;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/dice.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.distance = exports.similarity = exports.coefficient = exports.index = undefined;\n\nvar _tversky = require('./tversky');\n\nvar _tversky2 = _interopRequireDefault(_tversky);\n\nvar _ngrams = require('../../tokenizers/ngrams');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Dice coefficient is just Tversky index with alpha = beta = 1 over the\n * sequences' bigrams.\n */\n/**\n * Talisman metrics/distance/dice\n * ===============================\n *\n * Functions computing the Dice coefficient.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n *\n * [Article]:\n * Dice, Lee R. (1945). \"Measures of the Amount of Ecologic Association\n * Between Species\". Ecology 26 (3): 297–302.\n *\n * [Tags]: semimetric, string metric.\n */\nvar dice = function dice(x, y) {\n\n  // Shortcuts\n  if (x === y) return 1;\n\n  if (x.length === 1 && y.length === 1 && x !== y) return 0;\n\n  // Computing the sequences' bigrams\n  x = (0, _ngrams.bigrams)(x);\n  y = (0, _ngrams.bigrams)(y);\n\n  return (0, _tversky2.default)({ alpha: 0.5, beta: 0.5 }, x, y);\n};\n\n/**\n * Dice distance is 1 - the Dice index.\n */\nvar distance = function distance(x, y) {\n  return 1 - dice(x, y);\n};\n\n/**\n * Exporting.\n */\nexports.default = dice;\nexports.index = dice;\nexports.coefficient = dice;\nexports.similarity = dice;\nexports.distance = distance;\nmodule.exports = exports['default'];\nexports['default'].index = exports.index;\nexports['default'].coefficient = exports.coefficient;\nexports['default'].similarity = exports.similarity;\nexports['default'].distance = exports.distance;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/tversky.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = tversky;\n/**\n * Talisman metrics/distance/tversky\n * ==================================\n *\n * Functions computing the Tversky index.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Tversky_index\n *\n * [Article]:\n * Tversky, Amos (1977). \"Features of Similarity\".\n * Psychological Reviews 84 (4): 327–352.\n *\n * [Tags]: metric, asymmetric, string metric.\n */\n\n/**\n * Helpers\n */\nfunction I(X, Y) {\n  var intersection = new Set();\n\n  X.forEach(function (item) {\n    if (Y.has(item)) intersection.add(item);\n  });\n\n  return intersection.size;\n}\n\nfunction R(X, Y) {\n  var difference = new Set();\n\n  X.forEach(function (item) {\n    if (!Y.has(item)) difference.add(item);\n  });\n\n  return difference.size;\n}\n\n/**\n * Function returning the asymmetric Tversky index between both sequences.\n *\n * @param  {mixed}  x     - The first sequence to process.\n * @param  {mixed}  y     - The second sequence to process.\n * @param  {number} alpha - The alpha parameter.\n * @param  {number} beta  - The beta parameter.\n * @return {number}       - The asymmetric Tversky index.\n */\nfunction asymmetricTversky(x, y, alpha, beta) {\n  var XIY = I(x, y);\n\n  return XIY / (XIY + alpha * R(x, y) + beta * R(y, x));\n}\n\n/**\n * Function returning the symmetric Tversky index between both sequences.\n *\n * @param  {mixed}  x     - The first sequence to process.\n * @param  {mixed}  y     - The second sequence to process.\n * @param  {number} alpha - The alpha parameter.\n * @param  {number} beta  - The beta parameter.\n * @return {number}       - The symmetric Tversky index.\n */\nfunction symmetricTversky(x, y, alpha, beta) {\n  var XIY = I(x, y),\n      XminusY = R(x, y),\n      YminusX = R(y, x),\n      a = Math.min(XminusY, YminusX),\n      b = Math.max(XminusY, YminusX);\n\n  return XIY / (XIY + beta * (alpha * a + Math.pow(alpha - 1, b)));\n}\n\n/**\n * Function returning the Tversky index according to given parameters between\n * both sequences.\n *\n * @param  {object} params - The index's parameters.\n * @param  {mixed}  x      - The first sequence to process.\n * @param  {mixed}  y      - The second sequence to process.\n * @return {number}        - The resulting Tversky index.\n *\n * @throws {Error} The function expects both alpha & beta to be >= 0.\n */\nfunction tversky(params, x, y) {\n  params = params || {};\n\n  var _params = params,\n      _params$alpha = _params.alpha,\n      alpha = _params$alpha === undefined ? 1 : _params$alpha,\n      _params$beta = _params.beta,\n      beta = _params$beta === undefined ? 1 : _params$beta,\n      _params$symmetric = _params.symmetric,\n      symmetric = _params$symmetric === undefined ? false : _params$symmetric;\n\n\n  if (alpha < 0 || beta < 0) throw Error('talisman/metrics/distance/tversky: alpha & beta parameters should be >= 0.');\n\n  // Casting to sets\n  x = new Set(x);\n  y = new Set(y);\n\n  return symmetric ? symmetricTversky(x, y, alpha, beta) : asymmetricTversky(x, y, alpha, beta);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/guth.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = guth;\n/**\n * Talisman metrics/distance/guth\n * ===============================\n *\n * Implementation of the Guth distance.\n *\n * [Article]:\n * Gloria J. A. Guth (1976) Surname Spellings and Computerized Record Linkage,\n * Historical Methods Newsletter, 10:1, 10-19\n * DOI: 10.1080/00182494.1976.10112645\n *\n * [Tags]: metric, vector space.\n */\n\n/**\n * Function returning the Guth distance between two sequences.\n *\n * @param  {mixed}  a - The first sequence to process.\n * @param  {mixed}  b - The second sequence to process.\n * @return {number}   - The Guth distance between a & b.\n */\nfunction guth(a, b) {\n  if (a === b) return 0;\n\n  var tmp = void 0;\n\n  // Swapping so that a is the shortest\n  if (a.length > b.length) {\n    tmp = a;\n    a = b;\n    b = tmp;\n  }\n\n  var d = 0;\n\n  // Iterating\n  for (var i = 0, la = a.length, lb = b.length; i < lb; i++) {\n\n    // Early termination when b is really longer than a\n    if (i > la + 1) {\n      d += lb - i;\n      break;\n    }\n\n    var match = a[i] === b[i] || i + 1 < lb && a[i] === b[i + 1] || i + 2 < lb && a[i] === b[i + 2] || i && a[i] === b[i - 1] || i && a[i - 1] === b[i] || i + 1 < la && a[i + 1] === b[i] || i + 2 < la && a[i + 2] === b[i] || i + 1 < la && i + 1 < lb && a[i + 1] === b[i + 1] || i + 2 < la && i + 2 < lb && a[i + 2] === b[i + 2];\n\n    if (!match) d++;\n  }\n\n  return d;\n}\nmodule.exports = exports[\"default\"];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/hamming.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.default = hamming;\nexports.normalizedDistance = normalizedDistance;\nexports.normalizedSimilarity = normalizedSimilarity;\nexports.bitwise = bitwise;\n/**\n * Talisman metrics/distance/hamming\n * ==================================\n *\n * Function computing the Hamming distance.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Hamming_distance\n *\n * [Article]:\n * Hamming, Richard W. (1950), \"Error detecting and error correcting codes\",\n * Bell System Technical Journal 29 (2): 147–160\n *\n * [Tags]: metric, vector space, string metric.\n */\n\n/**\n * Function returning the Hamming distance between two sequences.\n *\n * @param  {mixed}  a - The first sequence to process.\n * @param  {mixed}  b - The second sequence to process.\n * @return {number}   - The Hamming distance between a & b.\n *\n * @throws {Error} The function expects sequences of equal length.\n */\nfunction hamming(a, b) {\n\n  if (a === b) return 0;\n\n  if (a.length !== b.length) throw Error('talisman/metrics/distance/hamming: given sequences are not of equal length.');\n\n  var distance = 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    if (a[i] !== b[i]) distance++;\n  }\n\n  return distance;\n}\n\n/**\n * Function returning the normalized Hamming distance between two sequences.\n *\n * @param  {mixed}  a - The first sequence to process.\n * @param  {mixed}  b - The second sequence to process.\n * @return {number}   - The normalized Hamming distance between a & b.\n */\nfunction normalizedDistance(a, b) {\n\n  if (a === b) return 0;\n\n  if (a.length > b.length) {\n    ;\n\n    var _ref = [b, a];\n    a = _ref[0];\n    b = _ref[1];\n  }var distance = b.length - a.length;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    if (a[i] !== b[i]) distance++;\n  }\n\n  return distance / b.length;\n}\n\n/**\n * Function returning the normalized Hamming similarity between two sequences.\n *\n * @param  {mixed}  a - The first sequence to process.\n * @param  {mixed}  b - The second sequence to process.\n * @return {number}   - The normalized Hamming similarity between a & b.\n */\nfunction normalizedSimilarity(a, b) {\n  return 1 - normalizedDistance(a, b);\n}\n\n/**\n * Function returning the Hamming distance between two numbers using only\n * bitwise operators.\n *\n * Note that this implementation uses a loop in O(k) time, k being the number\n * of bits set. There are other implementations possible using arithmetics but\n * litterature seems to agree that this does not speedup the computation and\n * since JavaScript does not have a direct access to processor low-level ops\n * such as popcount, this should be the most performant we can do now.\n *\n * @param  {mixed}  a - The first number to process.\n * @param  {mixed}  b - The second number to process.\n * @return {number}   - The Hamming distance between a & b.\n */\nfunction bitwise(a, b) {\n  var d = 0,\n      xor = a ^ b;\n\n  while (xor) {\n    d++;\n    xor &= xor - 1;\n  }\n\n  return d;\n}\nmodule.exports = exports['default'];\nexports['default'].normalizedDistance = exports.normalizedDistance;\nexports['default'].normalizedSimilarity = exports.normalizedSimilarity;\nexports['default'].bitwise = exports.bitwise;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/identity.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.distance = distance;\nexports.similarity = similarity;\n/**\n * Talisman metrics/distance/identity\n * ===================================\n *\n * Identity distance/similarity.\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Identity distance.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n * @param  {number}         - Distance between 0 & 1.\n */\nfunction distance(a, b) {\n  if (typeof a === 'string') return a === b ? 0 : 1;\n\n  if (a === b) return 0;\n\n  if (a.length !== b.length) return 1;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    if (a[i] !== b[i]) return 1;\n  }\n\n  return 0;\n}\n\n/**\n * Identity similarity.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n * @param  {number}         - Similarity between 0 & 1.\n */\nfunction similarity(a, b) {\n  if (typeof a === 'string') return a === b ? 1 : 0;\n\n  if (a === b) return 1;\n\n  if (a.length !== b.length) return 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    if (a[i] !== b[i]) return 0;\n  }\n\n  return 1;\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/jaccard.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\n/**\n * Talisman metrics/distance/jaccard\n * ==================================\n *\n * Functions computing the Jaccard distance/similarity.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Jaccard_index\n *\n * [Article]:\n * Jaccard, Paul (1912), \"The distribution of the flora in the alpine zone\",\n * New Phytologist 11: 37–50\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Function returning the Jaccard similarity score between two sequences.\n *\n * @param  {mixed}  a - The first sequence.\n * @param  {mixed}  b - The second sequence.\n * @return {number}   - The Jaccard similarity score between a & b.\n */\nfunction jaccard(a, b) {\n  if (a === b) return 1;\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la || !lb) return 0;\n\n  var setA = {},\n      setB = {};\n\n  var I = 0,\n      sizeA = 0,\n      sizeB = 0;\n\n  for (var i = 0; i < la; i++) {\n    if (!setA.hasOwnProperty(a[i])) {\n      setA[a[i]] = true;\n      sizeA++;\n    }\n  }\n\n  for (var _i = 0; _i < lb; _i++) {\n    if (!setB.hasOwnProperty(b[_i])) {\n      setB[b[_i]] = true;\n      sizeB++;\n\n      if (setA.hasOwnProperty(b[_i])) I++;\n    }\n  }\n\n  // Size of the union is sum of size of both sets minus intersection\n  var U = sizeA + sizeB - I;\n\n  return I / U;\n}\n\n/**\n * Jaccard distance is 1 - the Jaccard index.\n */\nvar distance = function distance(x, y) {\n  return 1 - jaccard(x, y);\n};\n\n/**\n * Exporting.\n */\nexports.default = jaccard;\nexports.index = jaccard;\nexports.similarity = jaccard;\nexports.distance = distance;\nmodule.exports = exports[\"default\"];\nexports[\"default\"].index = exports.index;\nexports[\"default\"].similarity = exports.similarity;\nexports[\"default\"].distance = exports.distance;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/jaro.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.distance = exports.similarity = undefined;\nexports.default = jaro;\n\nvar _vectors = require('../../helpers/vectors');\n\n/**\n * Function returning the Jaro score between two sequences.\n *\n * @param  {mixed}  a     - The first sequence.\n * @param  {mixed}  b     - The second sequence.\n * @return {number}       - The Jaro score between a & b.\n */\nfunction jaro(a, b) {\n\n  // Fast break\n  if (a === b) return 1;\n\n  var max = void 0,\n      min = void 0;\n\n  if (a.length > b.length) {\n    max = a;\n    min = b;\n  } else {\n    max = b;\n    min = a;\n  }\n\n  // Finding matches\n  var range = Math.max((max.length / 2 | 0) - 1, 0),\n      indexes = (0, _vectors.vec)(min.length, -1),\n      flags = (0, _vectors.vec)(max.length, false);\n\n  var matches = 0;\n\n  for (var i = 0, l = min.length; i < l; i++) {\n    var character = min[i],\n        xi = Math.max(i - range, 0),\n        xn = Math.min(i + range + 1, max.length);\n\n    for (var j = xi, _m = xn; j < _m; j++) {\n      if (!flags[j] && character === max[j]) {\n        indexes[i] = j;\n        flags[j] = true;\n        matches++;\n        break;\n      }\n    }\n  }\n\n  var ms1 = new Array(matches),\n      ms2 = new Array(matches);\n\n  var si = void 0;\n\n  si = 0;\n  for (var _i = 0, _l = min.length; _i < _l; _i++) {\n    if (indexes[_i] !== -1) {\n      ms1[si] = min[_i];\n      si++;\n    }\n  }\n\n  si = 0;\n  for (var _i2 = 0, _l2 = max.length; _i2 < _l2; _i2++) {\n    if (flags[_i2]) {\n      ms2[si] = max[_i2];\n      si++;\n    }\n  }\n\n  var transpositions = 0;\n  for (var _i3 = 0, _l3 = ms1.length; _i3 < _l3; _i3++) {\n    if (ms1[_i3] !== ms2[_i3]) transpositions++;\n  }\n\n  // Computing the distance\n  if (!matches) return 0;\n\n  var t = transpositions / 2 | 0,\n      m = matches;\n\n  return (m / a.length + m / b.length + (m - t) / m) / 3;\n}\n\n/**\n * Jaro distance is 1 - the Jaro score.\n */\n/**\n * Talisman metrics/distance/jaro\n * ===============================\n *\n * Function computing the Jaro score.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\n *\n * [Articles]:\n * Jaro, M. A. (1989). \"Advances in record linkage methodology as applied to\n * the 1985 census of Tampa Florida\".\n * Journal of the American Statistical Association 84 (406): 414–20\n *\n * Jaro, M. A. (1995). \"Probabilistic linkage of large public health data file\".\n * Statistics in Medicine 14 (5–7): 491–8.\n *\n * [Tags]: semimetric, string metric.\n */\nvar distance = function distance(a, b) {\n  return 1 - jaro(a, b);\n};\n\n/**\n * Exporting.\n */\nexports.similarity = jaro;\nexports.distance = distance;\nmodule.exports = exports['default'];\nexports['default'].similarity = exports.similarity;\nexports['default'].distance = exports.distance;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/jaro-winkler.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.distance = exports.similarity = exports.custom = undefined;\n\nvar _jaro = require('./jaro');\n\nvar _jaro2 = _interopRequireDefault(_jaro);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Function returning the Jaro-Winkler score between two sequences.\n *\n * @param  {object} options - Custom options.\n * @param  {mixed}  a       - The first sequence.\n * @param  {mixed}  b       - The second sequence.\n * @return {number}         - The Jaro-Winkler score between a & b.\n */\nfunction customJaroWinkler(options, a, b) {\n  options = options || {};\n\n  var _options = options,\n      _options$boostThresho = _options.boostThreshold,\n      boostThreshold = _options$boostThresho === undefined ? 0.7 : _options$boostThresho,\n      _options$scalingFacto = _options.scalingFactor,\n      scalingFactor = _options$scalingFacto === undefined ? 0.1 : _options$scalingFacto;\n\n\n  if (scalingFactor > 0.25) throw Error('talisman/metrics/distance/jaro-winkler: the scaling factor should not exceed 0.25.');\n\n  if (boostThreshold < 0 || boostThreshold > 1) throw Error('talisman/metrics/distance/jaro-winkler: the boost threshold should be comprised between 0 and 1.');\n\n  // Fast break\n  if (a === b) return 1;\n\n  // Computing Jaro-Winkler score\n  var dj = (0, _jaro2.default)(a, b);\n\n  if (dj < boostThreshold) return dj;\n\n  var p = scalingFactor;\n  var l = 0;\n\n  var prefixLimit = Math.min(a.length, b.length, 4);\n\n  // Common prefix (up to 4 characters)\n  for (var i = 0; i < prefixLimit; i++) {\n    if (a[i] === b[i]) l++;else break;\n  }\n\n  return dj + l * p * (1 - dj);\n}\n\n/**\n * Jaro-Winkler standard function.\n */\n/**\n * Talisman metrics/distance/jaro-winkler\n * =======================================\n *\n * Function computing the Jaro-Winkler score.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\n *\n * [Article]:\n * Winkler, W. E. (1990). \"String Comparator Metrics and Enhanced Decision Rules\n * in the Fellegi-Sunter Model of Record Linkage\".\n * Proceedings of the Section on Survey Research Methods\n * (American Statistical Association): 354–359.\n *\n * [Tags]: semimetric, string metric.\n */\nvar jaroWinkler = customJaroWinkler.bind(null, null);\n\n/**\n * Jaro-Winkler distance is 1 - the Jaro-Winkler score.\n */\nvar distance = function distance(a, b) {\n  return 1 - jaroWinkler(a, b);\n};\n\n/**\n * Exporting.\n */\nexports.default = jaroWinkler;\nexports.custom = customJaroWinkler;\nexports.similarity = jaroWinkler;\nexports.distance = distance;\nmodule.exports = exports['default'];\nexports['default'].custom = exports.custom;\nexports['default'].similarity = exports.similarity;\nexports['default'].distance = exports.distance;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/lcs.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.similarity = similarity;\nexports.distance = distance;\n\nvar _suffixArray = require('mnemonist/suffix-array');\n\n/**\n * LCS similarity.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n * @param  {number}         - Similarity between 0 & 1.\n */\nfunction similarity(a, b) {\n  if (a === b) return 1;\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la || !lb) return 0;\n\n  var gst = new _suffixArray.GeneralizedSuffixArray([a, b]),\n      lcs = gst.longestCommonSubsequence().length;\n\n  return lcs / Math.max(la, lb);\n}\n\n/**\n * LCS distance.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n * @param  {number}         - Distance between 0 & 1.\n */\n/**\n * Talisman metrics/distance/lcs\n * ==============================\n *\n * Function computing the Longest Common Subsequence distance/similarity.\n *\n * [Tags]: metric, string metric.\n */\nfunction distance(a, b) {\n  return 1 - similarity(a, b);\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/length.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.similarity = similarity;\nexports.distance = distance;\n/**\n * Talisman metrics/distance/length\n * =================================\n *\n * Length distance/similarity. Basically just the ratio of the shorter length\n * over the longer length.\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Length similarity.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n */\nfunction similarity(a, b) {\n  if (a === b) return 1;\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la || !lb) return 0;\n\n  if (la < lb) return la / lb;\n\n  return lb / la;\n}\n\n/**\n * Length distance.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n */\nfunction distance(a, b) {\n  return 1 - similarity(a, b);\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/levenshtein.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.default = levenshtein;\nexports.limited = limited;\n/**\n * Talisman metrics/distance/levenshtein\n * ======================================\n *\n * Functions computing the Levenshtein distance.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Levenshtein_distance\n *\n * [Article]:\n * Levenshtein, Vladimir I. (February 1966). \"Binary codes capable of\n * correcting deletions, insertions, and reversals\".\n * Soviet Physics Doklady 10 (8): 707–710.\n *\n * [Tags]: metric, string metric.\n */\nvar VECTOR = [],\n    CODES = [];\n\n/**\n * Function returning the Levenshtein distance between two sequences. This\n * version only works on strings and leverage the `.charCodeAt` method to\n * perform fast comparisons between 16 bits integers.\n *\n * @param  {string}  a - The first string to process.\n * @param  {string}  b - The second string to process.\n * @return {number}    - The Levenshtein distance between a & b.\n */\nfunction levenshteinForStrings(a, b) {\n  if (a === b) return 0;\n\n  var tmp = a;\n\n  // Swapping the strings so that the shorter string is the first one.\n  if (a.length > b.length) {\n    a = b;\n    b = tmp;\n  }\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la) return lb;\n  if (!lb) return la;\n\n  // Ignoring common suffix\n  // NOTE: ~- is a fast - 1 operation, it does not work on big number though\n  while (la > 0 && a.charCodeAt(~-la) === b.charCodeAt(~-lb)) {\n    la--;\n    lb--;\n  }\n\n  if (!la) return lb;\n\n  var start = 0;\n\n  // Ignoring common prefix\n  while (start < la && a.charCodeAt(start) === b.charCodeAt(start)) {\n    start++;\n  }la -= start;\n  lb -= start;\n\n  if (!la) return lb;\n\n  var v0 = VECTOR;\n\n  var i = 0;\n\n  while (i < lb) {\n    CODES[start + i] = b.charCodeAt(start + i);\n    v0[i] = ++i;\n  }\n\n  var current = 0,\n      left = void 0,\n      above = void 0,\n      charA = void 0,\n      j = void 0;\n\n  // Starting the nested loops\n  for (i = 0; i < la; i++) {\n    left = i;\n    current = i + 1;\n\n    charA = a.charCodeAt(start + i);\n\n    for (j = 0; j < lb; j++) {\n      above = current;\n\n      current = left;\n      left = v0[j];\n\n      if (charA !== CODES[start + j]) {\n\n        // Insertion\n        if (left < current) current = left;\n\n        // Deletion\n        if (above < current) current = above;\n\n        current++;\n      }\n\n      v0[j] = current;\n    }\n  }\n\n  return current;\n}\n\n/**\n * Function returning the Levenshtein distance between two arbitrary sequences.\n *\n * @param  {mixed}  a - The first sequence to process.\n * @param  {mixed}  b - The second sequence to process.\n * @return {number}   - The Levenshtein distance between a & b.\n */\nfunction levenshtein(a, b) {\n\n  // If the sequences are string, we use the optimized version\n  if (typeof a === 'string') return levenshteinForStrings(a, b);\n\n  if (a === b) return 0;\n\n  var tmp = a;\n\n  // Swapping the strings so that the shorter string is the first one.\n  if (a.length > b.length) {\n    a = b;\n    b = tmp;\n  }\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la) return lb;\n  if (!lb) return la;\n\n  // Ignoring common suffix\n  // NOTE: ~- is a fast - 1 operation, it does not work on big number though\n  while (la > 0 && a[~-la] === b[~-lb]) {\n    la--;\n    lb--;\n  }\n\n  if (!la) return lb;\n\n  var start = 0;\n\n  // Ignoring common prefix\n  while (start < la && a[start] === b[start]) {\n    start++;\n  }la -= start;\n  lb -= start;\n\n  if (!la) return lb;\n\n  var v0 = VECTOR;\n\n  var i = 0;\n\n  while (i < lb) {\n    v0[i] = ++i;\n  }var current = 0,\n      left = void 0,\n      above = void 0,\n      charA = void 0,\n      j = void 0;\n\n  // Starting the nested loops\n  for (i = 0; i < la; i++) {\n    left = i;\n    current = i + 1;\n\n    charA = a[start + i];\n\n    for (j = 0; j < lb; j++) {\n      above = current;\n\n      current = left;\n      left = v0[j];\n\n      if (charA !== b[start + j]) {\n\n        // Insertion\n        if (left < current) current = left;\n\n        // Deletion\n        if (above < current) current = above;\n\n        current++;\n      }\n\n      v0[j] = current;\n    }\n  }\n\n  return current;\n}\n\n/**\n * Function returning the Levenshtein distance between two sequences\n * but with a twist: this version will stop its computation if distance\n * exceed a given maximum and return Infinity. This version only works on\n * strings and leverage the `.charCodeAt` method to perform fast comparisons\n * between 16 bits integers.\n *\n * @param  {number} max - Maximum distance.\n * @param  {string} a   - The first string to process.\n * @param  {string} b   - The second string to process.\n * @return {number}     - The Levenshtein distance between a & b or Infinity.\n */\nfunction limitedLevenshteinForStrings(max, a, b) {\n  if (a === b) return 0;\n\n  var tmp = a;\n\n  // Swapping the strings so that the shorter string is the first one.\n  if (a.length > b.length) {\n    a = b;\n    b = tmp;\n  }\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la) return lb > max ? Infinity : lb;\n  if (!lb) return la > max ? Infinity : la;\n\n  // Ignoring common suffix\n  // NOTE: ~- is a fast - 1 operation, it does not work on big number though\n  while (la > 0 && a.charCodeAt(~-la) === b.charCodeAt(~-lb)) {\n    la--;\n    lb--;\n  }\n\n  if (!la) return lb > max ? Infinity : lb;\n\n  var start = 0;\n\n  // Ignoring common prefix\n  while (start < la && a.charCodeAt(start) === b.charCodeAt(start)) {\n    start++;\n  }la -= start;\n  lb -= start;\n\n  if (!la) return lb > max ? Infinity : lb;\n\n  var diff = lb - la;\n\n  if (max > lb) max = lb;else if (diff > max) return Infinity;\n\n  var v0 = VECTOR;\n\n  var i = 0;\n\n  while (i < max) {\n    CODES[start + i] = b.charCodeAt(start + i);\n    v0[i] = ++i;\n  }\n  while (i < lb) {\n    CODES[start + i] = b.charCodeAt(start + i++);\n    v0[i] = max + 1;\n  }\n\n  var offset = max - diff,\n      haveMax = max < lb;\n\n  var jStart = 0,\n      jEnd = max;\n\n  var current = 0,\n      left = void 0,\n      above = void 0,\n      charA = void 0,\n      j = void 0;\n\n  // Starting the nested loops\n  for (i = 0; i < la; i++) {\n    left = i;\n    current = i + 1;\n\n    charA = a.charCodeAt(start + i);\n    jStart += i > offset ? 1 : 0;\n    jEnd += jEnd < lb ? 1 : 0;\n\n    for (j = jStart; j < jEnd; j++) {\n      above = current;\n\n      current = left;\n      left = v0[j];\n\n      if (charA !== CODES[start + j]) {\n\n        // Insertion\n        if (left < current) current = left;\n\n        // Deletion\n        if (above < current) current = above;\n\n        current++;\n      }\n\n      v0[j] = current;\n    }\n\n    if (haveMax && v0[i + diff] > max) return Infinity;\n  }\n\n  return current <= max ? current : Infinity;\n}\n\n/**\n * Function returning the Levenshtein distance between two sequences\n * but with a twist: this version will stop its computation if distance\n * exceed a given maximum and return Infinity.\n *\n * @param  {number} max - Maximum distance.\n * @param  {mixed}  a   - The first sequence to process.\n * @param  {mixed}  b   - The second sequence to process.\n * @return {number}     - The Levenshtein distance between a & b or Infinity.\n */\nfunction limited(max, a, b) {\n\n  // If the sequences are string, we use the optimized version\n  if (typeof a === 'string') return limitedLevenshteinForStrings(max, a, b);\n\n  if (a === b) return 0;\n\n  var tmp = a;\n\n  // Swapping the strings so that the shorter string is the first one.\n  if (a.length > b.length) {\n    a = b;\n    b = tmp;\n  }\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la) return lb > max ? Infinity : lb;\n  if (!lb) return la > max ? Infinity : la;\n\n  // Ignoring common suffix\n  // NOTE: ~- is a fast - 1 operation, it does not work on big number though\n  while (la > 0 && a[~-la] === b[~-lb]) {\n    la--;\n    lb--;\n  }\n\n  if (!la) return lb > max ? Infinity : lb;\n\n  var start = 0;\n\n  // Ignoring common prefix\n  while (start < la && a[start] === b[start]) {\n    start++;\n  }la -= start;\n  lb -= start;\n\n  if (!la) return lb > max ? Infinity : lb;\n\n  var diff = lb - la;\n\n  if (max > lb) max = lb;else if (diff > max) return Infinity;\n\n  var v0 = VECTOR;\n\n  var i = 0;\n\n  while (i < max) {\n    v0[i] = ++i;\n  }\n  while (i < lb) {\n    v0[i++] = max + 1;\n  }\n\n  var offset = max - diff,\n      haveMax = max < lb;\n\n  var jStart = 0,\n      jEnd = max;\n\n  var current = 0,\n      left = void 0,\n      above = void 0,\n      charA = void 0,\n      j = void 0;\n\n  // Starting the nested loops\n  for (i = 0; i < la; i++) {\n    left = i;\n    current = i + 1;\n\n    charA = a[start + i];\n    jStart += i > offset ? 1 : 0;\n    jEnd += jEnd < lb ? 1 : 0;\n\n    for (j = jStart; j < jEnd; j++) {\n      above = current;\n\n      current = left;\n      left = v0[j];\n\n      if (charA !== b[start + j]) {\n\n        // Insertion\n        if (left < current) current = left;\n\n        // Deletion\n        if (above < current) current = above;\n\n        current++;\n      }\n\n      v0[j] = current;\n    }\n\n    if (haveMax && v0[i + diff] > max) return Infinity;\n  }\n\n  return current <= max ? current : Infinity;\n}\nmodule.exports = exports['default'];\nexports['default'].limited = exports.limited;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/manhattan.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = manhattan;\n/**\n * Talisman metrics/distance/manhattan\n * ====================================\n *\n * Function computing the Manhattan distance.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Taxicab_geometry\n *\n * [Tags]: metric, vector space.\n */\n\n/**\n * Function returning the Manhattan distance between two vectors.\n *\n * @param  {mixed}  a     - The first vector.\n * @param  {mixed}  b     - The second vector.\n * @return {number}       - The Manhattan distance between a & b.\n *\n * @throws {Error} The function expects vector of same dimensions.\n */\nfunction manhattan(a, b) {\n  if (a.length !== b.length) throw Error('talisman/metrics/distance/manhattan: the given vectors are not of the same dimension.');\n\n  var distance = 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    distance += Math.abs(a[i] - b[i]);\n  }return distance;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/minkowski.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = minkowski;\n/**\n * Talisman metrics/distance/minkowski\n * ====================================\n *\n * Function computing the Minkowski distance.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Minkowski_distance\n *\n * [Tags]: metric, vector space.\n */\n\n/**\n * Function returning the Minkowski distance between two vectors.\n *\n * @param  {number} p     - The value for p.\n * @param  {mixed}  a     - The first vector.\n * @param  {mixed}  b     - The second vector.\n * @return {number}       - The Minkowski distance between a & b.\n *\n * @throw  {Error} The function expects a p value >= 1.\n * @throws {Error} The function expects vectors of same dimension.\n */\nfunction minkowski(p, a, b) {\n  if (p < 1) throw Error('talisman/metrics/distance/minkowski: the given p-value should be >= 1.');\n\n  if (a.length !== b.length) throw Error('talisman/metrics/distance/minkowski: the given vectors are not of the same dimension.');\n\n  var sum = 0;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    sum += Math.pow(Math.abs(a[i] - b[i]), p);\n  }return Math.pow(sum, 1 / p);\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/mlipns.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.lipns = lipns;\nexports.custom = custom;\n/**\n * Talisman metrics/distance/mlipns\n * =================================\n *\n * Function computing the Modified Language-Independent Product Name Search\n * similarity (MLIPNS).\n *\n * [Reference]:\n * http://www.sial.iias.spb.su/files/386-386-1-PB.pdf\n *\n * [Article]:\n * Shannaq, Boumedyen A. N. and Victor V. Alexandrov. 2010. \"Using Product\n * Similarity for Adding Business.\" Global Journal of Computer Science and\n * Technology. 10(12). 2-8.\n *\n * [Tags]: metric.\n */\n\n/**\n * Function returning the LIPNS distance between two sequences, which is\n * basically the Hamming distance tolerating strings of different lengths.\n *\n * @param  {mixed}  a - The first sequence to process.\n * @param  {mixed}  b - The second sequence to process.\n * @return {number}   - The LIPNS similarity between a & b.\n */\nfunction lipns(a, b) {\n\n  if (a === b) return 0;\n\n  if (a.length > b.length) {\n    ;\n\n    var _ref = [b, a];\n    a = _ref[0];\n    b = _ref[1];\n  }var distance = b.length - a.length;\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    if (a[i] !== b[i]) distance++;\n  }\n\n  return distance;\n}\n\n/**\n * Function returning the MLIPNS similarity between two sequences.\n *\n * @param  {object} settings        - Settings:\n * @param  {number}   threshold     - maximum similarity score below which\n *                                    strings  are considered similar.\n * @param  {number}   maxMismatches - Maximum allowed mismatches.\n * @param  {mixed}  a               - The first sequence to process.\n * @param  {mixed}  b               - The second sequence to process.\n * @return {number}                 - The MLIPNS similarity between a & b.\n */\nfunction custom(settings, a, b) {\n  var threshold = settings.threshold,\n      maxMismatches = settings.maxMismatches;\n\n  if (a === b) return 1;\n\n  if (!a.length || !b.length) return 0;\n\n  var mismatches = 0,\n      distance = lipns(a, b),\n      maximumLength = Math.max(a.length, b.length);\n\n  while (mismatches <= maxMismatches) {\n    if (maximumLength < 1 || 1 - (maximumLength - distance) / maximumLength <= threshold) return 1;\n\n    mismatches++;\n    distance--;\n    maximumLength--;\n  }\n\n  if (maximumLength < 1) return 1;\n\n  return 0;\n}\n\nvar mlipns = custom.bind(null, {\n  threshold: 0.25,\n  maxMismatches: 2\n});\n\nexports.default = mlipns;\nmodule.exports = exports[\"default\"];\nexports[\"default\"].lipns = exports.lipns;\nexports[\"default\"].custom = exports.custom;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/monge-elkan.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.default = mongeElkan;\nexports.symmetric = symmetric;\n/**\n * Talisman metrics/distance/monge-elkan\n * ======================================\n *\n * Implementation of the Monge-Elkan distance.\n *\n * [Reference]: http://www.aaai.org/Papers/KDD/1996/KDD96-044.pdf\n *\n * [Article]:\n * Monge, Alvaro E. and Charles P. Elkan. 1996. \"The field matching problem:\n * Algorithms and applications.\" KDD-9 Proceedings.\n *\n * [Tags]: metric, asymmetric, string metric.\n */\n\n/**\n * Function computing the Monge-Elkan similarity.\n *\n * @param  {function}     similarity - Similarity function to use.\n * @param  {array|string} source     - Source sequence.\n * @param  {array|string} target     - Target sequence.\n * @return {number}                  - Monge-Elkan similarity.\n */\nfunction mongeElkan(similarity, source, target) {\n  if (source === target) return 1;\n  if (!source.length && !target.length) return 1;\n  if (!source.length || !target.length) return 0;\n\n  var sum = 0;\n\n  for (var i = 0, l = source.length; i < l; i++) {\n    var max = -Infinity;\n\n    for (var j = 0, m = target.length; j < m; j++) {\n      var score = similarity(source[i], target[j]);\n\n      if (score > max) max = score;\n    }\n\n    sum += max;\n  }\n\n  return sum / source.length;\n}\n\n/**\n * Function computing the symmetric Monge-Elkan similarity.\n * This is achieved by computing the mean of me(a, b) & me(b, a).\n */\nfunction symmetric(similarity, source, target) {\n  var a = mongeElkan(similarity, source, target),\n      b = mongeElkan(similarity, target, source);\n\n  return (a + b) / 2;\n}\n\n/**\n * Aliases.\n */\nvar similarity = mongeElkan;\n\nexports.similarity = similarity;\nmodule.exports = exports[\"default\"];\nexports[\"default\"].symmetric = exports.symmetric;\nexports[\"default\"].similarity = exports.similarity;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/overlap.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = overlap;\n/**\n * Talisman metrics/distance/overlap\n * ==================================\n *\n * Function computing the overlap coefficient.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Overlap_coefficient\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Global sets used by the overlap function. This way, we don't need to\n * create objects when computing the coefficient.\n */\nvar A = new Set(),\n    B = new Set();\n\n/**\n * Function returning the overlap coefficient between two sequences.\n *\n * @param  {mixed}  a     - The first sequence.\n * @param  {mixed}  b     - The second sequence.\n * @return {number}       - The overlap coefficient between a & b.\n */\nfunction overlap(a, b) {\n  if (a === b) return 1;\n\n  if (!a || !b) return 0;\n\n  A.clear();\n  B.clear();\n\n  for (var i = 0, l = a.length; i < l; i++) {\n    A.add(a[i]);\n  }for (var _i = 0, _l = b.length; _i < _l; _i++) {\n    B.add(b[_i]);\n  }var tmp = void 0;\n\n  // Let's find the shortest set\n  if (A.size > B.size) {\n    tmp = A;\n    A = B;\n    B = tmp;\n  }\n\n  // Computing intersection of both sets\n  var I = 0;\n\n  A.forEach(function (item) {\n    if (B.has(item)) I++;\n  });\n\n  return I / A.size;\n}\nmodule.exports = exports[\"default\"];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/prefix.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.similarity = similarity;\nexports.distance = distance;\n/**\n * Talisman metrics/distance/prefix\n * =================================\n *\n * Function computing the Prefix distance/similarity. This is basically the\n * ratio of the length of the common prefix to the length of the shortest\n * sequence.\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Prefix similarity.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n * @param  {number}         - Similarity between 0 & 1.\n */\nfunction similarity(a, b) {\n  if (a === b) return 1;\n\n  if (!a.length || !b.length) return 0;\n\n  if (a.length > b.length) {\n    ;\n\n    var _ref = [b, a];\n    a = _ref[0];\n    b = _ref[1];\n  }var i = 0;\n\n  var l = a.length;\n\n  for (; i < l; i++) {\n    if (a[i] !== b[i]) break;\n  }\n\n  return i / l;\n}\n\n/**\n * Prefix distance.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n * @param  {number}         - Distance between 0 & 1.\n */\nfunction distance(a, b) {\n  return 1 - similarity(a, b);\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/ratcliff-obershelp.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.similarity = similarity;\nexports.distance = distance;\n\nvar _suffixArray = require('mnemonist/suffix-array');\n\n/**\n * Abstract indexOf helper needed to find the given subsequence's starting\n * index in the given sequence. Note that this function may seem naive\n * because it misses cases when, for instance, the subsequence is not found\n * but this is of no concern because we use the function in cases when it's\n * not possible that the subsequence is not found.\n *\n * @param  {mixed}  haystack - Target sequence.\n * @param  {mixed}  needle   - Subsequence to find.\n * @return {number}          - The starting index.\n */\nfunction indexOf(haystack, needle) {\n  if (typeof haystack === 'string') return haystack.indexOf(needle);\n\n  for (var i = 0, j = 0, l = haystack.length, n = needle.length; i < l; i++) {\n    if (haystack[i] === needle[j]) {\n      j++;\n\n      if (j === n) return i - j + 1;\n    } else {\n      j = 0;\n    }\n  }\n\n  return -1;\n}\n\n/**\n * Function returning the number of Ratcliff-Obershelp matches. This works\n * by finding the LCS of both strings before recursively finding the LCS\n * of the substrings both before and after the LCS in the initial strings and\n * so on...\n *\n * @param  {mixed}  a  - The first sequence to process.\n * @param  {mixed}  b  - The second sequence to process.\n * @return {number}    - The number of matches.\n */\n/**\n * Talisman metrics/distance/ratcliff-obershelp\n * =============================================\n *\n * Function computing the Ratcliff-Obershelp similarity/distance.\n *\n * [References]:\n * https://xlinux.nist.gov/dads/HTML/ratcliffObershelp.html\n * http://collaboration.cmc.ec.gc.ca/science/rpn/biblio/ddj/Website/articles/DDJ/1988/8807/8807c/8807c.htm\n *\n * [Articles]:\n * PATTERN MATCHING: THE GESTALT APPROACH\n * John W. Ratcliff, David E. Metzener\n *\n * Paul E. Black, \"Ratcliff/Obershelp pattern recognition\", in Dictionary of\n * Algorithms and Data Structures [online], Vreda Pieterse and Paul E. Black,\n * eds. 17 December 2004.\n *\n * [Tags]: string metric.\n */\nfunction matches(a, b) {\n  var stack = [a, b];\n\n  var m = 0;\n\n  while (stack.length) {\n    a = stack.pop();\n    b = stack.pop();\n\n    if (!a.length || !b.length) continue;\n\n    var lcs = new _suffixArray.GeneralizedSuffixArray([a, b]).longestCommonSubsequence(),\n        length = lcs.length;\n\n    if (!length) continue;\n\n    // Increasing matches\n    m += length;\n\n    // Add to the stack\n    var aStart = indexOf(a, lcs),\n        bStart = indexOf(b, lcs);\n\n    stack.push(a.slice(0, aStart), b.slice(0, bStart));\n    stack.push(a.slice(aStart + length), b.slice(bStart + length));\n  }\n\n  return m;\n}\n\n/**\n * Function returning the Ratcliff-Obershelp similarity between two sequences.\n *\n * @param  {mixed}  a  - The first sequence to process.\n * @param  {mixed}  b  - The second sequence to process.\n * @return {number}    - The Ratcliff-Obershelp similarity between a & b.\n */\nfunction similarity(a, b) {\n  if (a === b) return 1;\n\n  if (!a.length || !b.length) return 0;\n\n  return 2 * matches(a, b) / (a.length + b.length);\n}\n\n/**\n * Function returning the Ratcliff-Obershelp distance between two sequences.\n *\n * @param  {mixed}  a  - The first sequence to process.\n * @param  {mixed}  b  - The second sequence to process.\n * @return {number}    - The Ratcliff-Obershelp distance between a & b.\n */\nfunction distance(a, b) {\n  return 1 - similarity(a, b);\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/sift4.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.custom = custom;\n/**\n * Talisman metrics/distance/sif4\n * ===============================\n *\n * Implementation of the SIFT4 distance which is a linear time approximation of\n * the Levenshtein or Damerau-Levenshtein distance.\n *\n * [Reference]:\n * https://siderite.blogspot.com/2014/11/super-fast-and-accurate-string-distance.html\n *\n * [Author]: Siderite Zackwehdex\n *\n * [Tags]: string metric, asymmetric.\n */\n\n// TODO: implement options of the most complex version.\n\n/**\n * Defaults.\n */\nvar DEFAULTS = {\n  transpositions: false,\n  maxOffset: 5\n};\n\n/**\n * Simplest version of the SIFT4 algorithm.\n *\n * @param  {number}       maxOffset   - Search window.\n * @param  {number}       maxDistance - Maximum distance before exiting.\n * @param  {string|array} a           - First sequence.\n * @param  {string|array} b           - Second sequence.\n * @return {number}                   - The distance.\n */\nfunction withoutTranspositions(maxOffset, maxDistance, a, b) {\n  // Early termination\n  if (a === b) return 0;\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la || !lb) return Math.max(la, lb);\n\n  var cursorA = 0,\n      cursorB = 0,\n      longestCommonSubsequence = 0,\n      localCommonSubstring = 0;\n\n  while (cursorA < la && cursorB < lb) {\n    if (a[cursorA] === b[cursorB]) {\n      localCommonSubstring++;\n    } else {\n      longestCommonSubsequence += localCommonSubstring;\n      localCommonSubstring = 0;\n\n      if (cursorA !== cursorB) cursorA = cursorB = Math.max(cursorA, cursorB);\n\n      for (var i = 0; i < maxOffset && (cursorA + i < la || cursorB + i < lb); i++) {\n        if (cursorA + i < la && a[cursorA + i] === b[cursorB]) {\n          cursorA += i;\n          localCommonSubstring++;\n          break;\n        }\n\n        if (cursorB + i < lb && a[cursorA] === b[cursorB + i]) {\n          cursorB += i;\n          localCommonSubstring++;\n          break;\n        }\n      }\n    }\n\n    cursorA++;\n    cursorB++;\n\n    if (maxDistance) {\n      var tempDistance = Math.max(cursorA, cursorB) - longestCommonSubsequence;\n\n      if (tempDistance === maxDistance) return maxDistance;\n\n      if (tempDistance > maxDistance) return Infinity;\n    }\n  }\n\n  longestCommonSubsequence += localCommonSubstring;\n\n  return Math.max(la, lb) - longestCommonSubsequence;\n}\n\n/**\n * Version of the SIFT4 function computing transpositions.\n *\n * @param  {number}       maxOffset   - Search window.\n * @param  {number}       maxDistance - Maximum distance before exiting.\n * @param  {string|array} a           - First sequence.\n * @param  {string|array} b           - Second sequence.\n * @return {number}                   - The distance.\n */\nfunction withTranspositions(maxOffset, maxDistance, a, b) {\n\n  // Early termination\n  if (a === b) return 0;\n\n  var la = a.length,\n      lb = b.length;\n\n  if (!la || !lb) return Math.max(la, lb);\n\n  var cursorA = 0,\n      cursorB = 0,\n      longestCommonSubsequence = 0,\n      localCommonSubstring = 0,\n      transpositions = 0;\n\n  var offsetArray = [];\n\n  while (cursorA < la && cursorB < lb) {\n\n    if (a[cursorA] === b[cursorB]) {\n      localCommonSubstring++;\n\n      var isTransposition = false,\n          i = 0;\n\n      while (i < offsetArray.length) {\n        var offset = offsetArray[i];\n\n        if (cursorA <= offset.cursorA || cursorB <= offset.cursorB) {\n\n          isTransposition = Math.abs(cursorB - cursorA) >= Math.abs(offset.cursorB - offset.cursorA);\n\n          if (isTransposition) {\n            transpositions++;\n          } else {\n            if (!offset.isTransposition) {\n              offset.isTransposition = true;\n              transpositions++;\n            }\n          }\n\n          break;\n        } else {\n\n          // NOTE: we could marginally enhance the performance of the algo\n          // by using an object rather than splicing the array\n          if (cursorA > offset.cursorB && cursorB > offset.cursorA) offsetArray.splice(i, 1);else i++;\n        }\n      }\n\n      offsetArray.push({\n        cursorA: cursorA,\n        cursorB: cursorB,\n        isTransposition: isTransposition\n      });\n    } else {\n      longestCommonSubsequence += localCommonSubstring;\n      localCommonSubstring = 0;\n\n      if (cursorA !== cursorB) cursorA = cursorB = Math.min(cursorA, cursorB);\n\n      for (var _i = 0; _i < maxOffset && (cursorA + _i < la || cursorB + _i < lb); _i++) {\n\n        if (cursorA + _i < la && a[cursorA + _i] === b[cursorB]) {\n          cursorA += _i - 1;\n          cursorB--;\n          break;\n        }\n\n        if (cursorB + _i < lb && a[cursorA] === b[cursorB + _i]) {\n          cursorA--;\n          cursorB += _i - 1;\n          break;\n        }\n      }\n    }\n\n    cursorA++;\n    cursorB++;\n\n    // NOTE: this was below maxDistance check in original implemenation but\n    // this looked suspicious\n    if (cursorA >= la || cursorB >= lb) {\n      longestCommonSubsequence += localCommonSubstring;\n      localCommonSubstring = 0;\n      cursorA = cursorB = Math.min(cursorA, cursorB);\n    }\n\n    if (maxDistance) {\n      var tempDistance = Math.max(cursorA, cursorB) - longestCommonSubsequence + transpositions;\n\n      if (tempDistance === maxDistance) return maxDistance;\n\n      if (tempDistance > maxDistance) return Infinity;\n    }\n  }\n\n  longestCommonSubsequence += localCommonSubstring;\n\n  return Math.max(la, lb) - longestCommonSubsequence + transpositions;\n}\n\n/**\n * Function computing the SIFT4 distance.\n *\n * @param  {object}       options         - Options:\n * @param  {boolean}        [symmetric]   - Symmetric version of the algorithm.\n * @param  {number}         [maxOffset]   - Search window.\n * @param  {number}         [maxDistance] - Maximum distance before exiting.\n * @param  {string|array} a               - First sequence.\n * @param  {string|array} b               - Second sequence.\n * @return {number}                       - The distance.\n */\nfunction custom(options, a, b) {\n  var maxOffset = options.maxOffset || DEFAULTS.maxOffset,\n      maxDistance = options.maxDistance,\n      transpositions = options.transpositions === true,\n      symmetric = options.symmetric === true;\n\n  var fn = transpositions ? withTranspositions : withoutTranspositions,\n      distance = fn(maxOffset, maxDistance, a, b);\n\n  if (symmetric) {\n    var reversedDistance = fn(maxOffset, maxDistance, b, a);\n\n    return Math.min(distance, reversedDistance);\n  }\n\n  return distance;\n}\n\n/**\n * Exporting default function.\n */\nvar sift4 = custom.bind(null, {});\nexports.default = sift4;\nmodule.exports = exports[\"default\"];\nexports[\"default\"].custom = exports.custom;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/smith-waterman.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.score = score;\n/**\n * Talisman metrics/distance/smith-waterman\n * =========================================\n *\n * Functions computing the Smith-Waterman distance.\n *\n * [Reference]: https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm\n *\n * [Article]:\n * Smith, Temple F. & Waterman, Michael S. (1981). \"Identification of Common\n * Molecular Subsequences\" (PDF). Journal of Molecular Biology. 147: 195–197.\n *\n * [Tags]: metric, string metric.\n */\nvar SIMILARITY = function SIMILARITY(a, b) {\n  return a === b ? 1 : 0;\n};\n\n/**\n * Function returning the Smith-Waterman score between two sequences.\n *\n * @param  {object}   options      - Options:\n * @param  {number}     gap        - Gap cost.\n * @param  {function}   similarity - Similarity function.\n * @param  {mixed}    a            - The first sequence to process.\n * @param  {mixed}    b            - The second sequence to process.\n * @return {number}                - The Smith-Waterman score between a & b.\n */\nfunction score(options, a, b) {\n  var _options$gap = options.gap,\n      gap = _options$gap === undefined ? 1 : _options$gap,\n      _options$similarity = options.similarity,\n      similarity = _options$similarity === undefined ? SIMILARITY : _options$similarity;\n\n  // Early terminations\n\n  if (a === b) return a.length;\n\n  var m = a.length,\n      n = b.length;\n\n  if (!m || !n) return 0;\n\n  // TODO: Possibility to optimize for common prefix, but need to know max substitution cost\n\n  var d = new Array(m + 1);\n\n  var D = 0;\n\n  for (var i = 0; i <= m; i++) {\n    d[i] = new Array(2);\n    d[i][0] = 0;\n  }\n\n  for (var j = 1; j <= n; j++) {\n    d[0][j % 2] = 0;\n\n    for (var _i = 1; _i <= m; _i++) {\n      var cost = similarity(a[_i - 1], b[j - 1]);\n\n      d[_i][j % 2] = Math.max(0, // Start over\n      d[_i - 1][(j - 1) % 2] + cost, // Substitution\n      d[_i - 1][j % 2] - gap, // Insertion\n      d[_i][(j - 1) % 2] - gap // Deletion\n      );\n\n      // Storing max\n      if (d[_i][j % 2] > D) D = d[_i][j % 2];\n    }\n  }\n\n  return D;\n}\n\n/**\n * Exporting standard distance.\n */\nvar smithWaterman = score.bind(null, {});\n\nexports.default = smithWaterman;\nmodule.exports = exports[\"default\"];\nexports[\"default\"].score = exports.score;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/sorensen.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.distance = exports.similarity = exports.coefficient = exports.index = undefined;\n\nvar _dice = require('./dice');\n\nvar _dice2 = _interopRequireDefault(_dice);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * The Sorensen index is the same as the Dice one.\n */\nexports.default = _dice2.default; /**\n                                   * Talisman metrics/distance/sorensen\n                                   * ===================================\n                                   *\n                                   * Functions computing the Sorensen index. Note that Sorensen index is\n                                   * actually the same as the Dice coefficient (metrics/dice).\n                                   *\n                                   * [Reference]:\n                                   * https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n                                   *\n                                   * [Article]:\n                                   * Sørensen, T. (1948). \"A method of establishing groups of equal amplitude in\n                                   * plant sociology based on similarity of species and its application to\n                                   * analyses of the vegetation on Danish commons\".\n                                   * Kongelige Danske Videnskabernes Selskab 5 (4): 1–34.\n                                   *\n                                   * [Tags]: semimetric, string metric.\n                                   */\n\nexports.index = _dice2.default;\nexports.coefficient = _dice2.default;\nexports.similarity = _dice2.default;\nexports.distance = _dice.distance;\nmodule.exports = exports['default'];\nexports['default'].index = exports.index;\nexports['default'].coefficient = exports.coefficient;\nexports['default'].similarity = exports.similarity;\nexports['default'].distance = exports.distance;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/metrics/distance/suffix.js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.similarity = similarity;\nexports.distance = distance;\n/**\n * Talisman metrics/distance/suffix\n * =================================\n *\n * Function computing the Suffix distance/similarity. This is basically the\n * ratio of the length of the common suffix to the length of the shortest\n * sequence.\n *\n * [Tags]: metric, string metric.\n */\n\n/**\n * Suffix similarity.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n * @param  {number}         - Similarity between 0 & 1.\n */\nfunction similarity(a, b) {\n  if (a === b) return 1;\n\n  if (!a.length || !b.length) return 0;\n\n  if (a.length > b.length) {\n    ;\n\n    var _ref = [b, a];\n    a = _ref[0];\n    b = _ref[1];\n  }var i = 0;\n\n  var la = a.length,\n      lb = b.length;\n\n  for (; i < la; i++) {\n    if (a[la - i - 1] !== b[lb - i - 1]) break;\n  }\n\n  return i / la;\n}\n\n/**\n * Suffix distance.\n *\n * @param  {array|string} a - First sequence.\n * @param  {array|string} b - Second sequence.\n * @param  {number}         - Distance between 0 & 1.\n */\nfunction distance(a, b) {\n  return 1 - similarity(a, b);\n}","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/french/fonem.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = fonem;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } } /**\n                                                                                                                                                                                                     * Talisman phonetics/french/fonem\n                                                                                                                                                                                                     * ================================\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * Implementation of the French phonetic algorithm \"FONEM\" designed to match\n                                                                                                                                                                                                     * family names from Saguenay.\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * [Reference]:\n                                                                                                                                                                                                     * http://www.persee.fr/doc/pop_0032-4663_1981_num_36_6_17248\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * [Article]:\n                                                                                                                                                                                                     * Bouchard Gérard, Brard Patrick, Lavoie Yolande. FONEM : Un code de\n                                                                                                                                                                                                     * transcription phonétique pour la reconstitution automatique des familles\n                                                                                                                                                                                                     * saguenayennes. In: Population, 36ᵉ année, n°6, 1981. pp. 1085-1103;\n                                                                                                                                                                                                     */\n\n\n/**\n * Constants.\n */\nvar VOWELS = 'AEIOUY',\n    CONSONANTS = '^' + VOWELS,\n    V = '[' + VOWELS + ']',\n    C = '[' + CONSONANTS + ']';\n\n/**\n * Rules.\n */\nvar RULES = {\n\n  // Vowels & vowel clusters\n  'V-1': [/E?AU/g, 'O'],\n  'V-2': [/(?:E?AU|O)LT$/, 'O'],\n  'V-3': [/E?AUT$/, 'O'],\n  'V-4': [/E?AUX$/, 'O'],\n  'V-5': [/(?:E?AU|O)LX$/, 'O'],\n  'V-6': [/E?AUL?D$/, 'O'],\n  'V-7': [/([^G])AY$/, '$1E'],\n  'V-8': [/EUX$/, 'EU'],\n  'V-9': ['EY(?=$|' + C + ')', 'E'],\n  'V-10': ['(' + C + ')?Y(?!' + V + ')', '$1I'],\n  'V-11': ['(' + V + ')I(?=' + V + ')', '$1Y'],\n  'V-12': ['(' + V + ')ILL', '$1Y'],\n  'V-13': [/OU(?=I(?!LL)|[AEOU])/g, 'W'],\n  'V-14': ['(' + V + ')\\\\1', '$1'],\n\n  // Nasals\n  'V-15': ['[AE]M(?=[' + CONSONANTS + 'N](?!$))', 'EN'],\n  'V-16': ['OM(?=[' + CONSONANTS + 'N])', 'ON'],\n  'V-17': ['AN(?=' + C + ')', 'EN'],\n  'V-18': ['(?:AIM|AIN|EIN)(?=' + C + '|$)', 'IN'],\n  'V-19': [/(?:BORNE?|BOURNE?|BURNE)$/, 'BURN'],\n  'V-20': ['(?:^IM|IM(?=' + C + '))(?=[' + CONSONANTS + 'N])', 'IN'],\n\n  // Consonants & consonant clusters\n  'C-1': [/BV/g, 'V'],\n  'C-2': ['(' + V + ')C(?=[EIY])', '$1SS'],\n  'C-3': [/([^CX])C(?=[EIY])/g, '$1S'],\n  'C-4': [/^C(?=[EIY])/, 'S'],\n  'C-5': [/^C(?=[AOU])/, 'K'],\n  'C-6': ['(' + V + ')C$', '$1K'],\n  'C-7': ['C(?=[' + CONSONANTS + 'CH])', 'K'],\n  'C-8': [/CC(?=[AOU])/g, 'K'],\n  'C-9': [/CC(?=[EIY])/g, 'X'],\n  'C-10': [/G(?=[EIY])/g, 'J'],\n  'C-11': [/GA(?=I?[MN])/g, 'G§'], // The paper is inconsistent so I cheated.\n  'C-12': [/(?:GEO|GEAU)/g, 'JO'],\n  'C-13': ['GNI(?=' + V + ')', 'GN'],\n  'C-14': [/(^|[^CPS])H/g, '$1'],\n  'C-15': [/JEA/g, 'JA'],\n  'C-16': ['^MAC(?=' + C + ')', 'M§'], // The paper is inconsistent so I cheated.\n  'C-17': [/^MC/, 'M§'],\n  'C-18': [/PH/g, 'F'],\n  'C-19': [/QU/g, 'K'],\n  'C-20': [/^SC(?=[EIY])/, 'S'],\n  'C-21': [/(.)SC(?=[EIY])/g, '$1SS'],\n  'C-22': [/(.)SC(?=[AOU])/g, '$1SK'],\n  'C-23': [/SH/g, 'CH'],\n  'C-24': [/TIA$/, 'SSIA'],\n  'C-25': [/([AIOUY])W/g, '$1'],\n  'C-26': [/X[CSZ]/g, 'X'],\n  'C-27': ['(?:Z(?=' + V + ')|(' + C + ')Z(?=' + C + '))', '$1S'],\n  'C-28': ['(?:([' + CONSONANTS + 'CLS])\\\\1|(C)C(?!' + V + ')|(.S)S(?!' + V + ')|([^I]L)L)', '$1$2$3$4'],\n  'C-28-bis': [/ILE$/, 'ILLE'],\n  'C-29': ['(?:(ILS)|([CS]H)|([MN]P)|(R[CFKLNSX])|(' + C + ')' + C + ')$', '$1$2$3$4$5'],\n  'C-30': [/^(?:SINT?|SAINT?|SEIN|SEIM|CINQ?)/, 'ST-'],\n  'C-31': [/^SAINTE/, 'STE-'],\n  'C-32': [/^ST(?!E)/, 'ST-'],\n  'C-33': [/^STE/, 'STE-']\n};\n\n// Compiling rules\nfor (var k in RULES) {\n  var rule = RULES[k];\n\n  if (!(rule[0] instanceof RegExp)) rule[0] = new RegExp(rule[0], 'g');\n}\n\n// Rules must be ordered\nvar ORDERED_RULES = ['V-14', 'C-28', 'C-28-bis', // START\n'C-12', 'C-9', 'C-10', 'C-16', 'C-17', 'C-20', 'C-2', 'C-3', 'C-7', 'V-2', 'V-3', 'V-4', 'V-5', 'V-6', 'V-1', 'C-14', 'C-11', 'C-33', 'C-32', 'C-31', 'C-30', // SAINT\n'V-15', 'V-17', 'V-18', 'V-7', 'V-8', 'V-9', 'V-10', 'V-11', 'V-12', 'V-13', 'V-16', 'V-19', 'V-20', // V\n'C-1', 'C-4', 'C-5', 'C-6', 'C-8', 'C-13', 'C-15', 'C-18', // C\n'C-19', 'C-21', 'C-22', 'C-23', 'C-24', 'C-25', 'C-26', 'C-27', // C\n'C-29', // END\n'V-14', 'C-28', 'C-28-bis' // ONCE AGAIN\n].map(function (key) {\n  return RULES[key];\n});\n\nvar FIXING_RULES = [[/G§/g, 'GA'], [/M§/g, 'MAC']];\n\n/**\n * Function taking a single name and computing its FONEM code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The FONEM code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction fonem(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/french/fonem: the given name is not a string.');\n\n  var code = (0, _deburr2.default)(name).toUpperCase().replace(/[^A-Z]/, '');\n\n  // Applying rules in order\n  for (var i = 0, l = ORDERED_RULES.length; i < l; i++) {\n    var _ORDERED_RULES$i = ORDERED_RULES[i],\n        pattern = _ORDERED_RULES$i[0],\n        replacement = _ORDERED_RULES$i[1];\n\n\n    code = code.replace(pattern, replacement);\n  }\n\n  // Fixing rules\n  for (var _i = 0, _l = FIXING_RULES.length; _i < _l; _i++) {\n    var _code;\n\n    code = (_code = code).replace.apply(_code, _toConsumableArray(FIXING_RULES[_i]));\n  }return code;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/french/phonetic.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = phonetic;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Helpers.\n */\n\n// NOTE: will only squeeze one letter, not more (e.g. AGREEE => AGREE)\nfunction squeeze(word) {\n  return word.replace(/(.)\\1/g, '$1');\n}\n\n/**\n * Rules.\n */\n/**\n * Talisman phonetics/french/phonetic\n * ===================================\n *\n * Implementation of the \"phonetic\" algorithm for the French language.\n *\n * [Author]: Edouard Bergé\n *\n * [Reference]:\n * http://www.roudoudou.com/phonetic.php\n */\nvar FIRST_PREPROCESSING = [[/O[O]+/g, 'OU'], [/SAOU/g, 'SOU'], [/OES/g, 'OS'], [/CCH/g, 'K'], [/CC([IYE])/g, 'KS$1']];\n\nvar SECOND_PREPROCESSING = [[/OIN[GT]$/g, 'OIN'], [/E[RS]$/g, 'E'], [/(C|CH)OEU/g, 'KE'], [/MOEU/g, 'ME'], [/OE([UI]+)([BCDFGHJKLMNPQRSTVWXZ])/g, 'E$1$2'], [/^GEN[TS]$/, 'JAN'], [/CUEI/g, 'KEI'], [/([^AEIOUYC])AE([BCDFGHJKLMNPQRSTVWXZ])/g, '$1E$2'], [/AE([QS])/g, 'E$1'], [/AIE([BCDFGJKLMNPQRSTVWXZ])/g, 'AI$1'], [/ANIEM/g, 'ANIM'], [/(DRA|TRO|IRO)P$/, '$1'], [/(LOM)B$/, '$1'], [/(RON|POR)C$/, '$1'], [/PECT$/, 'PET'], [/ECUL$/, 'CU'], [/(CHA|CA|E)M(P|PS)$/, '$1N'], [/(TAN|RAN)G$/, '$1']];\n\nvar RULES = [\n\n// YEUX\n[/([^VO])ILAG/g, '$1IAJ'], [/([^TRH])UIL(AR|E)(.+)/g, '$1UI$2$3'], [/([G])UIL([AEO])/g, '$1UI$2'], [/([NSPM])AIL([AEO])/g, '$1AI$2'], [/DIL(AI|ON|ER|EM)/g, 'DI$1'], [/RILON/g, 'RION'], [/TAILE/g, 'TAIE'], [/GAILET/g, 'GAIET'], [/AIL(A[IR])/g, 'AI$1'], [/OUILA/g, 'OUIA'], [/EIL(AI|AR|ER|EM)/g, 'AI$1'], [/REILET/g, 'RAIET'], [/EILET/g, 'EIET'], [/AILOL/g, 'AIOL'], [/([^AEIOUY])(SC|S)IEM([EA])/g, '$1$2IAM$3'], [/^(SC|S)IEM([EA])/g, '$1IAM$2'],\n\n// MP/MB -> NP/NB\n[/([OAI])MB/g, '$1NB'], [/([OA])MP/g, '$1NP'], [/GEMB/g, 'JANB'], [/EM([BP])/g, 'AN$1'], [/UMBL/g, 'INBL'], [/CIEN/g, 'SIAN'],\n\n// K sounds\n[/^ECEUR/, 'EKEUR'], [/^CH(OG+|OL+|OR+|EU+|ARIS|M+|IRO|ONDR)/, 'K$1'], [/(YN|RI)CH(OG+|OL+|OC+|OP+|OM+|ARIS|M+|IRO|ONDR)/g, '$1K$2'], [/CHS/g, 'CH'], [/CH(AIQ)/g, 'K$1'], [/^ECHO([^UIPY])/, 'EKO$1'], [/ISCH(I|E)/g, 'ISK$1'], [/^ICHT/, 'IKT'], [/ORCHID/g, 'ORKID'], [/ONCHIO/g, 'ONKIO'], [/ACHIA/g, 'AKIA'], [/([^C])ANICH/g, '$1ANIK'], [/OMANIK/g, 'OMANICH'], [/ACHY([^D])/g, 'AKI$1'], [/([AEIOU])C([BDFGJKLMNPQRTVWXZ])/g, '$1K$2'], [/EUCHA/g, 'EKA'], [/YCH(IA|A|O|ED)/g, 'IK$1'], [/([AR])CHEO/g, '$1KEO'], [/RCHES/g, 'RKES'], [/ECHN/g, 'EKN'], [/OCHTO/g, 'OKTO'], [/CHO(RA|NDR|RE)/g, 'KO$1'], [/MACHM/g, 'MAKM'], [/BRONCHO/g, 'BRONKO'], [/LICHO([SC])/g, 'LIKO$1'],\n\n// WEUH\n[/WA/g, 'OI'], [/WO/g, 'O'], [/(?:WI|WHI|WHY)/g, 'OUI'], [/WHA/g, 'OUA'], [/WHO/g, 'OU'],\n\n// GUEU, GNEU, JEU etc.\n[/GNE([STR])/g, 'NIE$1'], [/GNE/g, 'NE'], [/GI/g, 'JI'], [/GNI/g, 'NI'], [/GN(A|OU|UR)/g, 'NI$1'], [/GY/g, 'JI'], [/OUGAIN/g, 'OUGIN'], [/AGEO([LT])/g, 'AJO$1'], [/GEORG/g, 'JORJ'], [/GEO(LO|M|P|G|S|R)/g, 'JEO$1'], [/([NU])GEOT/g, '$1JOT'], [/GEO([TDC])/g, 'JEO$1'], [/GE([OA])/g, 'J$1'], [/GE/g, 'JE'], [/QU?/g, 'K'], [/C[YI]/g, 'SI'], [/CN/g, 'KN'], [/ICM/g, 'IKM'], [/CEAT/g, 'SAT'], [/CE/g, 'SE'], [/C([RO])/g, 'K$1'], [/CUEI/g, 'KEI'], [/CU/g, 'KU'], [/VENCA/g, 'VANSA'], [/C([AS])/g, 'K$1'], [/CLEN/g, 'KLAN'], [/C([LZ])/g, 'K$1'], [/CTIQ/g, 'KTIK'], [/CTI[CS]/g, 'KTIS'], [/CTI([FL])/g, 'KTI$1'], [/CTIO/g, 'KSIO'], [/CT([IUEOR])?/g, 'KT$1'], [/PH/g, 'F'], [/TH/g, 'T'], [/OW/g, 'OU'], [/LH/g, 'L'], [/RDL/g, 'RL'], [/CH(LO|R)/g, 'K$1'], [/PTIA/g, 'PSIA'], [/GU([^RLMBSTPZN])/g, 'G$1'], [/GNO(?=[MLTNRKG])/g, 'NIO'],\n\n// TI -> SI\n[/BUTI([EA])/g, 'BUSI$1'], [/BATIA/g, 'BASIA'], [/ANTIEL/g, 'ANSIEL'], [/RETION/g, 'RESION'], [/ENTI([EA])L/g, 'ENSI$1L'], [/ENTIO/g, 'ENSIO'], [/ENTIAI/g, 'ENSIAI'], [/UJETION/g, 'UJESION'], [/ATIEM/g, 'ASIAM'], [/PETIEN/g, 'PESIEN'], [/CETIE/g, 'CESIE'], [/OFETIE/g, 'OFESIE'], [/IPETI/g, 'IPESI'], [/LBUTION/g, 'LBUSION'], [/BLUTION/g, 'BLUSION'], [/L([EA])TION/g, 'L$1SION'], [/SATIET/g, 'SASIET'], [/(.+)ANTI(AL|O)/g, '$1ANSI$2'], [/(.+)INUTI([^V])/g, '$1INUSI$2'], [/([^O])UTIEN/g, '$1USIEN'], [/([^DE])RATI([E])$/, '$1RASI$2'], [/([^SNEU]|KU|KO|RU|LU|BU|TU|AU)T(IEN|ION)/g, '$1S$2'],\n\n// Silent H\n[/([^CS])H/g, '$1'], [/([EN])SH/g, '$1S'], [/SH/g, 'CH'],\n\n// Nasals\n[/OMT/g, 'ONT'], [/IM([BP])/g, 'IN$1'], [/UMD/g, 'OND'], [/([TRD])IENT/g, '$1IANT'], [/IEN/g, 'IN'], [/YM([UOAEIN])/g, 'IM$1'], [/YM/g, 'IN'], [/AHO/g, 'AO'], [/([FDS])AIM/g, '$1IN'], [/EIN/g, 'AIN'], [/AINS/g, 'INS'],\n\n// AIN -> IN\n[/AIN$/, 'IN'], [/AIN([BTDK])/g, 'IN$1'],\n\n// UN -> IN\n[/([^O])UND/g, '$1IND'], [/([JTVLFMRPSBD])UN([^IAE])/g, '$1IN$2'], [/([JTVLFMRPSBD])UN$/, '$1IN'], [/RFUM$/, 'RFIN'], [/LUMB/g, 'LINB'],\n\n// EN -> AN\n[/([^BCDFGHJKLMNPQRSTVWXZ])EN/g, '$1AN'], [/([VTLJMRPDSBFKNG])EN(?=[BRCTDKZSVN])/g, '$1AN'], [/^EN([BCDFGHJKLNPQRSTVXZ]|CH|IV|ORG|OB|UI|UA|UY)/, 'AN$1'], [/(^[JRVTH])EN([DRTFGSVJMP])/, '$1AN$2'], [/SEN([ST])/g, 'SAN$1'], [/^DESENIV/g, 'DESANIV'], [/([^M])EN(U[IY])/g, '$1AN$2'], [/(.+[JTVLFMRPSBD])EN([JLFDSTG])/g, '$1AN$2'],\n\n// EI -> AI\n[/([VSBSTNRLPM])E[IY]([ACDFRJLGZ])/g, '$1AI$2'],\n\n// Ô\n[/EAU/g, 'O'], [/EU/g, 'E'], [/Y/g, 'I'], [/EOI/g, 'OI'], [/JEA/g, 'JA'], [/OIEM/g, 'OIM'], [/OUANJ/g, 'OUENJ'], [/OUA/g, 'OI'], [/OUENJ/g, 'OUANJ'], [/AU([^E])/g, 'O$1'],\n\n// Refining\n[/^BENJ/, 'BINJ'], [/RTIEL/g, 'RSIEL'], [/PINK/g, 'PONK'], [/KIND/g, 'KOND'], [/KUM(N|P)/g, 'KON$1'], [/LKOU/g, 'LKO'], [/EDBE/g, 'EBE'], [/ARCM/g, 'ARKM'], [/SCH/g, 'CH'], [/^OINI/, 'ONI'], [/([^NDCGRHKO])APT/g, '$1AT'], [/([L]|KON)PT/g, '$1T'], [/OTB/g, 'OB'], [/IXA/g, 'ISA'], [/TG/g, 'G'], [/^TZ/, 'TS'], [/PTIE/g, 'TIE'], [/GT/g, 'T'], [/ANKIEM/g, 'ANKILEM'], [/(LO|RE)KEMAN/g, '$1KAMAN'], [/NT(B|M)/g, 'N$1'], [/GSU/g, 'SU'], [/ESD/g, 'ED'], [/LESKEL/g, 'LEKEL'], [/CK/g, 'K']];\n\nvar FIRST_ENDINGS = [[/USIL$/, 'USI'], [/X$|[TD]S$|[DS]$/, ''], [/([^KL]+)T$/, '$1'],\n\n// Not really an ending\n[/^[H]/, '']];\n\nvar SECOND_ENDINGS = [[/TIL$/, 'TI'], [/LC$/, 'LK'], [/L[E]?[S]?$/, 'L'], [/(.+)N[E]?[S]?$/, '$1N'], [/EZ$/, 'E'], [/OIG$/, 'OI'], [/OUP$/, 'OU'], [/([^R])OM$/, '$1ON'], [/LOP$/, 'LO'], [/NTANP$/, 'NTAN'], [/TUN$/, 'TIN'], [/AU$/, 'O'], [/EI$/, 'AI'], [/R[DG]$/, 'R'], [/ANC$/, 'AN'], [/KROC$/, 'KRO'], [/HOUC$/, 'HOU'], [/OMAC$/, 'OMA'], [/([J])O([NU])[CG]$/, '$1O$2'], [/([^GTR])([AO])NG$/, '$1$2N'], [/UC$/, 'UK'], [/AING$/, 'IN'], [/([EISOARN])C$/, '$1K'], [/([ABD-MO-Z]+)[EH]+$/, '$1'], [/EN$/, 'AN'], [/(NJ)EN$/, '$1AN'], [/^PAIEM/, 'PAIM'], [/([^NTB])EF$/, '$1']];\n\n/**\n * Exceptions.\n */\nvar EXCEPTIONS = {\n  CD: 'CD',\n  BD: 'BD',\n  BV: 'BV',\n  TABAC: 'TABA',\n  FEU: 'FE',\n  FE: 'FE',\n  FER: 'FER',\n  FIEF: 'FIEF',\n  FJORD: 'FJORD',\n  GOAL: 'GOL',\n  FLEAU: 'FLEO',\n  HIER: 'IER',\n  HEU: 'E',\n  HE: 'E',\n  OS: 'OS',\n  RIZ: 'RI',\n  RAZ: 'RA',\n\n  // Catching up exceptions placed elsewhere in the original algorithm\n  ECHO: 'EKO'\n};\n\nvar ABBREVIATION_REGEX = /[BCDFGHJKLMNPQRSTVWXYZ][BCDFGHJKLMNPQRSTVWXYZ][BCDFGHJKLMNPQRSTVWXYZ][BCDFGHJKLMNPQRSTVWXYZ]*/;\n\nvar SIMPLE_WORDS_REGEX = /[RFMLVSPJDF][AEIOU]/;\n\n/**\n * Function taking a single word and computing its phonetic code.\n *\n * @param  {string}  word - The word to process.\n * @return {string}       - The phonetic code.\n *\n * @throws {Error} The function expects the word to be a string.\n */\nfunction phonetic(word) {\n  if (typeof word !== 'string') throw Error('talisman/phonetics/french/phonetic: the given word is not a string.');\n\n  // Preparing the word\n  word = word.toUpperCase().replace(/Œ/g, 'OEU').replace(/Æ/g, 'E').replace(/Ç/g, 'S');\n\n  word = (0, _deburr2.default)(word).replace(/[^A-Z]/g, '');\n\n  var code = word;\n\n  // First preprocessing\n  for (var i = 0, l = FIRST_PREPROCESSING.length; i < l; i++) {\n    var _FIRST_PREPROCESSING$ = FIRST_PREPROCESSING[i],\n        pattern = _FIRST_PREPROCESSING$[0],\n        replacement = _FIRST_PREPROCESSING$[1];\n\n\n    code = code.replace(pattern, replacement);\n  }\n\n  // Squeezing\n  code = squeeze(code);\n\n  // Is the word an exception?\n  var exception = EXCEPTIONS[code];\n\n  if (exception) return exception;\n\n  // Second preprocessing\n  for (var _i = 0, _l = SECOND_PREPROCESSING.length; _i < _l; _i++) {\n    var _SECOND_PREPROCESSING = SECOND_PREPROCESSING[_i],\n        pattern = _SECOND_PREPROCESSING[0],\n        replacement = _SECOND_PREPROCESSING[1];\n\n\n    code = code.replace(pattern, replacement);\n  }\n\n  // Applying rules\n  for (var _i2 = 0, _l2 = RULES.length; _i2 < _l2; _i2++) {\n    var _RULES$_i = RULES[_i2],\n        pattern = _RULES$_i[0],\n        replacement = _RULES$_i[1];\n\n\n    code = code.replace(pattern, replacement);\n  }\n\n  // First endings\n  for (var _i3 = 0, _l3 = FIRST_ENDINGS.length; _i3 < _l3; _i3++) {\n    var _FIRST_ENDINGS$_i = FIRST_ENDINGS[_i3],\n        pattern = _FIRST_ENDINGS$_i[0],\n        replacement = _FIRST_ENDINGS$_i[1];\n\n\n    code = code.replace(pattern, replacement);\n  }\n\n  // Saving the code for very short words\n  var backupCode = code;\n\n  // Second endings\n  for (var _i4 = 0, _l4 = SECOND_ENDINGS.length; _i4 < _l4; _i4++) {\n    var _SECOND_ENDINGS$_i = SECOND_ENDINGS[_i4],\n        pattern = _SECOND_ENDINGS$_i[0],\n        replacement = _SECOND_ENDINGS$_i[1];\n\n\n    code = code.replace(pattern, replacement);\n  }\n\n  // Squeezing the code again\n  code = squeeze(code);\n\n  // Special cases\n  if (code === 'FUEL') code = 'FIOUL';\n\n  // If the code is \"O\" we return it (only acceptable code with only 1 letter)\n  if (code === 'O') return code;\n\n  // Attempting to save short codes\n  if (code.length < 2) {\n\n    // Abbreviations\n    if (ABBREVIATION_REGEX.test(word)) return word;\n\n    if (SIMPLE_WORDS_REGEX.test(word)) {\n      if (word.length === 3 || word.length === 4) return word.slice(0, -1);\n    }\n\n    if (backupCode.length > 1) return backupCode;\n  }\n\n  if (code.length > 1) return code;\n\n  return '';\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/french/sonnex.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = sonnex;\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\n/* eslint no-confusing-arrow: 0 */\n/**\n * Talisman phonetics/french/sonnex\n * =================================\n *\n * Implementation of the French phonetic algorithm \"Sonnex\".\n *\n * [Author]: Frédéric Bisson\n * [Revision]: Guillaume Plique\n *\n * [Reference]:\n * https://github.com/Zigazou/Sonnex\n *\n * [Note]:\n * The orignal algorithm has been slightly modified to better account for some\n * more cases.\n */\n\n/**\n * Helpers.\n */\nvar VOWELS = new Set('aâàäeéèêëiîïoôöuùûüyœ'),\n    CONSONANTS = new Set('bcçdfghjklmnpqrstvwxyz'),\n    SIMPLE_QUOTES = '’‘`‛\\'';\n\nvar DROP_SIMPLE_QUOTES = new RegExp('[' + SIMPLE_QUOTES + ']', 'g');\n\nfunction isVowel(letter) {\n  return VOWELS.has(letter);\n}\n\nfunction isConsonant(letter) {\n  return CONSONANTS.has(letter);\n}\n\n/**\n * Rules.\n */\nvar EXCEPTIONS = {\n  cerf: 'sEr',\n  cerfs: 'sEr',\n  de: 'de',\n  est: 'E',\n  es: 'E',\n  huit: 'uit',\n  les: 'lE',\n  mer: 'mEr',\n  mes: 'mE',\n  ressent: 'res2',\n  serf: 'sEr',\n  serfs: 'sEr',\n  sept: 'sEt',\n  septième: 'sEtiEm',\n  ses: 'sE',\n  tes: 'tE',\n\n  // NOTE: those exceptions have been added\n  eschatologie: 'Eskatoloji'\n};\n\n// Rules expressed in the following format:\n//   [0]: The pattern to match (string if exact, regex if fuzzy)\n//   [1]: The encoding. If passed as a function, the function must return\n//        both the encoding and the continuation string.\n//\n// Note: it's possible to optimize the rules not to use regular expression\n//       at all.\nvar RULES = {\n  a: [['a', 'a'], ['aient', 'E'], ['ain', '1'], [/ain(.)(.*)$/, function (v, cs) {\n    if (isVowel(v)) return ['E', v + cs];\n    return ['1', v + cs];\n  }], ['ais', 'E'], [/^ais(.)(.*)/, function (v, cs) {\n    if (v === 's') return ['Es', cs];\n    if (isVowel(v)) return ['Ez', v + cs];\n    return ['Es', v + cs];\n  }], ['ail', 'ai'], [/^aill(.*)/, 'ai'], [/^ai(.*)/, 'E'], [/^amm(.*)/, 'am'], [/^am(.)(.*)/, function (c, cs) {\n    if (c === 'm') return ['am', cs];\n    if (isVowel(c)) return ['am', c + cs];\n    return ['2', c + cs];\n  }], ['an', '2'], [/^an(.)(.*)/, function (c, cs) {\n    if (c === 'n') return ['an', cs];\n    if (isVowel(c)) return ['an', c + cs];\n    return ['2', c + cs];\n  }], ['assent', 'as'], [/^as(.)(.*)/, function (c, cs) {\n    if (c === 's') return ['as', cs];\n    if (isConsonant(c)) return ['as', c + cs];\n    return ['az', c + cs];\n  }], [/^au(.*)/, function (cs) {\n    return ['o', cs];\n  }], ['ay', 'E'], ['ays', 'E']],\n\n  à: [[/^à(.*)/, 'a']],\n\n  â: [[/^â(.*)/, 'a']],\n\n  b: [['b', ''], [/^bb(.*)/, 'b']],\n\n  c: [['c', ''], [/^c(a.*)/, 'k'], [/^cc(.)(.*)/, function (v, cs) {\n    if (v === 'o' || v === 'u') return ['k', v + cs];\n    return ['ks', cs];\n  }], [/^c(e.*)/, 's'], [/^c'(.*)/, 's'],\n\n  // NOTE: adding a rule to account for the Greek root \"chiro\"\n  [/^chiro([^u].*)/, 'kiro'], [/^ch(ao.*)/, 'k'], [/^chl(.*)/, 'kl'], [/^ch(oe.*)/, 'k'], [/^chr(.*)/, 'kr'], [/^ch(.*)/, 'C'], [/^c(i.*)/, 's'], [/^ck(.*)/, 'k'], [/^c(oeu.*)/, 'k'], [/^compt(.*)/, 'k3t'], [/^c(o.*)/, 'k'], [/^cue(i.*)/, 'ke'], [/^c(u.*)/, 'k'], [/^c(y.*)/, 's'], [/^c(.*)/, 'k']],\n\n  ç: [[/^ç(.*)/, 's']],\n\n  d: [['d', ''], ['ds', ''], [/^dd(.*)/, 'd']],\n\n  e: [['e', ''], ['ec', 'Ec'], ['ef', 'Ef'], ['eaux', 'o'], [/^eann(.*)/, 'an'], [/^ean(.*)/, '2'], [/^eau(.*)/, 'o'], [/^eff(.*)/, 'Ef'], [/^e(gm.*)/, 'E'], ['ein', '1'], [/^ein(.)(.*)/, function (c, cs) {\n    if (c === 'n') return ['En', cs];\n    if (isVowel(c)) return ['En', c + cs];\n    return ['1', c + cs];\n  }], [/^ei(.*)/, 'E'], [/^ell(.*)/, 'El'], [/^el(.)(.*)/, function (c, cs) {\n    if (isConsonant(c)) return ['E', 'l' + c + cs];\n    return ['e', 'l' + c + cs];\n  }], [/^emm(.*)/, 'Em'],\n\n  // NOTE: this rule has been modified to better handle \"emp\"\n  [/^emp(.)(.*)/, function (c, cs) {\n    if (c === 'h') return ['2', 'p' + c + cs];\n    if (!isVowel(c) && !cs) return ['2', cs];\n    return ['2p', c + cs];\n  }], [/^enn(.*)/, 'En'], ['en', '2'], [/^en(.)(.*)/, function (c, cs) {\n    if (isVowel(c)) return ['en', c + cs];\n    return ['2', c + cs];\n  }], ['er', 'E'], ['ert', 'Er'], [/^err(.*)/, 'Er'], [/^er(f.*)/, 'Er'], ['es', ''], [/^esch(.*)/, 'EC'], ['essent', 'Es'], [/^es(.)(.*)/, function (c, cs) {\n    if (c === 'h' || c === 'n') return ['E', c + cs];\n    if (c === 's') return ['Es', cs];\n    if (isConsonant(c)) return ['Es', c + cs];\n    return ['ez', c + cs];\n  }], [/^és(.)(.*)/, function (c, cs) {\n    if (c === 's') return ['Es', cs];\n    if (isConsonant(c)) return ['Es', c + cs];\n    return ['Ez', c + cs];\n  }], [/^ett(.*)/, 'Et'], ['et', 'E'], [/^et(.*)/, 'et'], [/^eun(.)(.*)/, function (c, cs) {\n    if (isVowel(c)) return ['en', c + cs];\n    return ['1', c + cs];\n  }], ['eux', 'e'], [/^eux(i.*)/, 'ez'], [/^eu(.*)/, 'e'], ['ex', 'Eks'], [/^ey(.)(.*)/, function (c, cs) {\n    if (isConsonant(c)) return ['E', c + cs];\n    return ['E', 'y' + c + cs];\n  }], ['ez', 'E']],\n\n  è: [[/^è(.*)/, 'E']],\n\n  ê: [[/ê(.*)/, 'E']],\n\n  ë: [[/^ë(l.*)/, 'E']],\n\n  é: [['é', 'E'], [/^é(.)(.*)/, function (c, cs) {\n    if (c === 't') return ['Et', cs];\n    return ['E', c + cs];\n  }]],\n\n  f: [[/^ff(.*)/, 'f']],\n\n  g: [['g', ''], [/^g(e.*)/, 'j'], [/^gé(.*)/, 'jE'], [/^g(i.*)/, 'j'], [/^gn(.*)/, 'n'], [/^g(y.*)/, 'j'], [/^guë(.*)/, 'gu'], [/^gu(.*)/, 'g'], [/^gg(.*)/, 'g']],\n\n  h: [[/^h(.*)/, '']],\n\n  i: [['ic', 'ik'], ['ics', 'ik'], [/^ienn(.*)/, 'iEn'], [/^ien(.*)/, 'i1'], ['in', '1'], [/^in(.)(.*)/, function (c, cs) {\n    if (c === 'n') return ['in', cs];\n    if (isVowel(c)) return ['in', c + cs];\n    return ['1', c + cs];\n  }], ['issent', 'is'], [/^is(.)(.*)/, function (c, cs) {\n    if (c === 's') return ['is', cs];\n    if (isConsonant(c)) return ['is', c + cs];\n    return ['iz', c + cs];\n  }], [/^ix(i.*)/, 'iz'], [/^ill(.*)/, 'i'], [/^i(.*)/, 'i']],\n\n  ï: [[/^ï(.*)/, 'i']],\n\n  l: [[/^ll(.*)/, 'l']],\n\n  m: [[/^mm(.*)/, 'm']],\n\n  n: [[/^nn(.*)/, 'n']],\n\n  o: [[/^occ(.*)/, 'ok'], [/^oeu?(.*)/, 'e'], ['oient', 'Ua'], [/^oin(.*)/, 'U1'], [/^oi(.*)/, 'Ua'], [/^omm(.*)/, 'om'], [/^om(.)(.*)/, function (c, cs) {\n    if (isVowel(c)) return ['om', c + cs];\n    return ['3', c + cs];\n  }], [/^onn(.*)/, 'on'], [/^on(.*)/, '3'], ['ossent', 'os'], [/^os(.)(.*)/, function (c, cs) {\n    if (c === 's') return ['os', cs];\n    if (isConsonant(c)) return ['os', c + cs];\n    return ['oz', c + cs];\n  }], [/^o[uùû](.*)/, 'U']],\n\n  ô: [[/^ô(.*)/, 'o']],\n\n  ö: [[/^ô(.*)/, 'o']],\n\n  p: [['p', ''], [/^ph(.*)/, 'f'], [/^pp(.*)/, 'p'], [/^pays(.*)/, function (cs) {\n    return ['pE', 'is' + cs];\n  }]],\n\n  q: [[/^qu(r.*)/, 'ku'], [/^qu(.*)/, 'k'], [/^q(.*)/, 'k']],\n\n  r: [[/^rr(.*)/, 'r']],\n\n  s: [['s', ''], [/^ss(.*)/, 's'], [/^st(.*)/, 'st'], [/^sc(i.*)/, 's']],\n\n  t: [['t', ''], [/^t(ier.*)/, 't'], [/^ti(.)(.*)/, function (v, cs) {\n    if (isVowel(v)) return ['s', 'i' + v + cs];\n    return ['t', 'i' + v + cs];\n  }], [/^tt(.*)/, 't']],\n\n  u: [['un', '1'], ['ussent', 'us'], [/^us(.*)/, function (c, cs) {\n    if (c === 's') return ['us', cs];\n    if (isConsonant(c)) return ['us', c + cs];\n    return ['uz', c + cs];\n  }]],\n\n  û: [[/^û(.*)/, 'u']],\n\n  w: [[/^w(.*)/, 'v']],\n\n  x: [['x', ''], [/^x(.)(.*)/, function (c, cs) {\n    if (c === 'c') return ['ks', cs];\n    if (isVowel(c)) return ['kz', c + cs];\n    return ['ks', c + cs];\n  }]],\n\n  y: [[/^y(.*)/, 'i']],\n\n  z: [[/^zz(.*)/, 'z']]\n};\n\n/**\n * Function taking a single word and computing its Sonnex code.\n *\n * @param  {string}  word - The word to process.\n * @return {string}       - The Sonnex code.\n *\n * @throws {Error} The function expects the word to be a string.\n */\nfunction sonnex(word) {\n  if (typeof word !== 'string') throw Error('talisman/phonetics/french/sonnex: the given word is not a string.');\n\n  word = word.toLowerCase().replace(DROP_SIMPLE_QUOTES, '').replace(/œ/g, 'oe');\n\n  // Some exceptions\n  var exception = EXCEPTIONS[word];\n\n  if (exception) return exception;\n\n  // Applying the rules\n  var current = word,\n      code = '';\n\n  // If the word starts with \"tien\", we skip encoding the \"t\"\n  if (/^tien/.test(current)) {\n    current = current.slice(1);\n    code = 't';\n  }\n\n  // Encoding each letter of the word\n  while (current.length) {\n    var firstLetter = current[0];\n\n    // Retrieving the proper set of rules\n    var rules = RULES[firstLetter];\n\n    // If there is no rules for the letter, we skip to the next one\n    if (!rules) {\n      code += firstLetter;\n      current = current.slice(1);\n      continue;\n    }\n\n    var found = false;\n\n    // Iterating through rules\n    for (var i = 0, l = rules.length; i < l; i++) {\n      var pattern = rules[i][0];\n      var encoding = rules[i][1];\n\n      // Simple pattern\n      if (typeof pattern === 'string') {\n        if (current === pattern) {\n          found = true;\n          code += encoding;\n          current = '';\n          break;\n        }\n\n        continue;\n      }\n\n      // Regex pattern\n      var match = current.match(pattern);\n\n      if (match) {\n        found = true;\n\n        if (typeof encoding === 'string') {\n          current = match[1] || '';\n        } else {\n          var _encoding = encoding.apply(undefined, _toConsumableArray(match.slice(1)));\n\n          encoding = _encoding[0];\n          current = _encoding[1];\n        }\n\n        code += encoding;\n\n        break;\n      }\n    }\n\n    if (!found) {\n      code += firstLetter;\n      current = current.slice(1);\n    }\n  }\n\n  return code;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/french/soundex2.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = soundex2;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _helpers = require('../../helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } } /**\n                                                                                                                                                                                                     * Talisman phonetics/french/soundex2\n                                                                                                                                                                                                     * ===================================\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * French phonetic algorithm loosely based upon the classifcal Soundex.\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * [Reference]:\n                                                                                                                                                                                                     * http://www-info.univ-lemans.fr/~carlier/recherche/soundex.html\n                                                                                                                                                                                                     * http://sqlpro.developpez.com/cours/soundex/\n                                                                                                                                                                                                     */\n\n\n/**\n * Rules.\n */\nvar GROUPS = [[/GU([IE])/g, 'K$1'], [/G([AO])/g, 'K$1'], [/GU/g, 'K'], [/C([AOU])/g, 'K$1'], [/(?:Q|CC|CK)/g, 'K']];\n\nvar PREFIXES = [\n\n// Note: the way the algorithm is described, it is highly probable that\n// the 'MAC' rule cannot work because of precendent modifications\n['MAC', 'MCC'], ['SCH', 'SSS'], ['ASA', 'AZA'], ['KN', 'NN'], ['PH', 'FF'], ['PF', 'FF']];\n\n/**\n * Helpers.\n */\nfunction pad(code) {\n  return code.slice(0, 4);\n}\n\n/**\n * Function taking a single name and computing its Soundex2 code.\n *\n * Note: the description of the algorithm says to pad the code using spaces, but\n * as I cannot see why one would do that (plus it is quite error-prone when\n * debugging), I decided to drop it.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The Soundex2 code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction soundex2(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/french/soundex2: the given name is not a string.');\n\n  var code = (0, _deburr2.default)(name.trim()).toUpperCase().replace(/[^A-Z]/, '');\n\n  // Replacing some letter groups\n  for (var i = 0, l = GROUPS.length; i < l; i++) {\n    var _code;\n\n    code = (_code = code).replace.apply(_code, _toConsumableArray(GROUPS[i]));\n  } // Replacing vowels\n  code = code.charAt(0) + code.slice(1).replace(/[AEIOU]/g, 'A');\n\n  // Replacing prefixes\n  for (var _i = 0, _l = PREFIXES.length; _i < _l; _i++) {\n    var _PREFIXES$_i = PREFIXES[_i],\n        prefix = _PREFIXES$_i[0],\n        replacement = _PREFIXES$_i[1],\n        length = prefix.length;\n\n\n    if (code.slice(0, length) === prefix) code = replacement + code.slice(length);\n  }\n\n  // Handling the letter H\n  code = code.replace(/([^CS])H/g, '$1');\n\n  // Handling the letter Y\n  code = code.replace(/([^A])Y/g, '$1');\n\n  // Removing some endings\n  code = code.replace(/[ADTS]$/, '');\n\n  // Removing non-leading vowels\n  code = code.charAt(0) + code.slice(1).replace(/A/g, '');\n\n  return pad((0, _helpers.squeeze)(code));\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/german/cologne.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = cologne;\n\nvar _helpers = require('../../helpers');\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Maps.\n */\n/**\n * Talisman phonetics/german/cologne\n * ==================================\n *\n * The cologne algorithm.\n *\n * [Reference]:\n * https://en.wikipedia.org/wiki/Cologne_phonetics\n *\n * [Article]:\n * Hans Joachim Postel: Die Kölner Phonetik. Ein Verfahren zur Identifizierung\n * von Personennamen auf der Grundlage der Gestaltanalyse.\n * in: IBM-Nachrichten, 19. Jahrgang, 1969, S. 925-931.\n */\nvar CODES = {\n  H: null,\n\n  A: 0,\n  E: 0,\n  I: 0,\n  O: 0,\n  U: 0,\n  J: 0,\n  Y: 0,\n\n  B: 1,\n  P: 1,\n\n  F: 3,\n  V: 3,\n  W: 3,\n\n  G: 4,\n  K: 4,\n  Q: 4,\n\n  L: 5,\n\n  M: 6,\n  N: 6,\n\n  R: 7,\n\n  S: 8,\n  Z: 8\n};\n\nvar DT = new Set(['C', 'S', 'Z']),\n    CFollowing1 = new Set(['A', 'H', 'K', 'L', 'O', 'Q', 'R', 'U', 'X']),\n    CFollowing2 = new Set(['A', 'H', 'K', 'O', 'Q', 'U', 'X']),\n    CPrevious = new Set(['S', 'Z']),\n    X = new Set(['C', 'Q', 'K']);\n\n/**\n * Helpers.\n */\nfunction germanicSubstitutions(name) {\n  return name.replace(/Ä/g, 'A').replace(/Ö/g, 'O').replace(/Ü/g, 'U').replace(/ß/g, 'SS').replace(/PH/g, 'F');\n}\n\n/**\n * Function taking a single name and computing its cologne code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The cologne code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction cologne(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/german/cologne: the given name is not a string.');\n\n  // Preparing the name\n  name = (0, _deburr2.default)(germanicSubstitutions(name.toUpperCase())).replace(/[^A-Z]/g, '');\n\n  // Processing the letters of the name\n  var code = [];\n\n  for (var i = 0, l = name.length; i < l; i++) {\n    var letter = name[i],\n        possibleCode = CODES[letter];\n\n    if (possibleCode !== undefined) code.push(possibleCode);\n\n    // Handling D/T\n    else if (letter === 'D' || letter === 'T') code.push(DT.has(name[i + 1]) ? 8 : 2);\n\n      // Handling C\n      else if (letter === 'C') {\n          var previous = name[i - 1],\n              following = name[i + 1];\n\n          if (!previous && CFollowing1.has(following) || CFollowing2.has(following) && !CPrevious.has(previous)) {\n            code.push(4);\n          } else {\n            code.push(8);\n          }\n        }\n\n        // Handling X\n        else if (letter === 'X') code.push(X.has(name[i - 1]) ? 8 : 48);\n  }\n\n  // Squeezing and dropping 0 if not first letter\n  code = (0, _helpers.squeeze)(code).filter(function (letter, i) {\n    return !i || letter;\n  });\n\n  return code.join('');\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/phonetics/german/phonem.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = phonem;\n\nvar _helpers = require('../../helpers');\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } } /**\n                                                                                                                                                                                                     * Talisman phonetics/german/phonem\n                                                                                                                                                                                                     * =================================\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * The phonem algorithm.\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * [Reference]:\n                                                                                                                                                                                                     * http://web.archive.org/web/20070209153423/http://uni-koeln.de/phil-fak/phonetik/Lehre/MA-Arbeiten/magister_wilz.pdf\n                                                                                                                                                                                                     *\n                                                                                                                                                                                                     * [Article]:\n                                                                                                                                                                                                     * Wilde, Georg ; Meyer, Carsten: Doppelgänger gesucht - Ein Programm fur\n                                                                                                                                                                                                     * kontext-sensitive phonetische Textumwandlung. In: ct Magazin fur\n                                                                                                                                                                                                     * Computer & Technik 25 (1988)\n                                                                                                                                                                                                     */\n\n\n/**\n * Rules.\n */\nvar SUBSTITUTIONS = [[/(?:SC|SZ|CZ|TZ|TS)/g, 'C'], [/KS/g, 'X'], [/(?:PF|PH)/g, 'V'], [/QU/g, 'KW'], [/UE/g, 'Y'], [/AE/g, 'E'], [/OE/g, 'Ö'], [/E[IY]/g, 'AY'], [/EU/g, 'OY'], [/AU/g, 'A§'], [/OU/g, '§']];\n\nvar TRANSLATION = (0, _helpers.translation)('ZKGQÇÑßFWPTÁÀÂÃÅÄÆÉÈÊËIJÌÍÎÏÜÝ§ÚÙÛÔÒÓÕØ', 'CCCCCNSVVBDAAAAAEEEEEEYYYYYYYYUUUUOOOOÖ');\n\nvar ACCEPTABLE_LETTERS = new Set('ABCDLMNORSUVWXYÖ');\n\n/**\n * Function taking a single name and computing its phonem code.\n *\n * @param  {string}  name - The name to process.\n * @return {string}       - The phonem code.\n *\n * @throws {Error} The function expects the name to be a string.\n */\nfunction phonem(name) {\n  if (typeof name !== 'string') throw Error('talisman/phonetics/german/phonem: the given name is not a string.');\n\n  var code = name.toUpperCase();\n\n  for (var i = 0, l = SUBSTITUTIONS.length; i < l; i++) {\n    var _code;\n\n    code = (_code = code).replace.apply(_code, _toConsumableArray(SUBSTITUTIONS[i]));\n  }var translatedCode = '';\n  for (var _i = 0, _l = code.length; _i < _l; _i++) {\n    translatedCode += TRANSLATION[code[_i]] || code[_i];\n  }translatedCode = (0, _helpers.squeeze)(translatedCode);\n\n  code = '';\n  for (var _i2 = 0, _l2 = translatedCode.length; _i2 < _l2; _i2++) {\n    if (ACCEPTABLE_LETTERS.has(translatedCode[_i2])) code += translatedCode[_i2];\n  }\n\n  return code;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/french/carry.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = carry;\n/**\n * Talisman stemmers/french/carry\n * ===============================\n *\n * The Carry stemmer for the French language.\n *\n * [Reference]:\n * http://www.otlet-institute.org/docs/Carry.pdf\n *\n * [Article]:\n * Carry, un algorithme de désuffixation pour le français. M. Paternostre,\n * P. Francq, J. Lamoral, D. Wartel et M. Saerens. 2002\n *\n * [Note]:\n * This algorithm has been edited to handle some more cases and is thus\n * lightly different from the original paper (modifications by Guillaume\n * Plique).\n */\n\n/**\n * Constants.\n */\nvar VOWELS = 'aeiouyâàëéêèïîôûùœæ',\n    V = '[' + VOWELS + ']',\n    C = '[^' + VOWELS + ']';\n\nvar LC = new RegExp('^' + C + '+'),\n    TV = new RegExp(V + '+$'),\n    M = new RegExp('(' + V + '+' + C + '+)');\n\n/**\n * Helpers.\n */\nfunction computeM(string) {\n\n  // Removing leading consonants\n  string = string.replace(LC, '').replace(TV, '');\n\n  return (string.match(M) || []).length;\n}\n\n/**\n * Rules.\n */\nvar STEP1 = [[0, 'issaient'], [0, 'ellement', 'el'], [0, 'issement'], [0, 'alement', 'al'], [0, 'eraient'], [0, 'iraient'], [0, 'eassent'], [0, 'ussent'], [0, 'amment'], [0, 'emment'], [0, 'issant'], [0, 'issent'], [0, 'assent'], [0, 'eaient'], [0, 'issait'], [0, 'èrent'], [0, 'erent'], [0, 'irent'], [0, 'erait'], [0, 'irait'], [0, 'iront'], [0, 'eront'], [0, 'ement'], [0, 'aient'], [0, 'îrent'], [0, 'eont'], [0, 'eant'], [0, 'eait'], [0, 'ient'], [0, 'ent'], [0, 'ont'], [0, 'ant'], [0, 'eât'], [0, 'ait'], [0, 'at'], [0, 'ât'], [0, 'it'], [0, 'ît'], [0, 't'], [0, 'uction'], [1, 'ication'], [1, 'iation'], [1, 'ation'], [0, 'ition'], [0, 'tion'], [1, 'ateur'], [1, 'teur'], [0, 'eur'], [0, 'ier'], [0, 'er'], [0, 'ir'], [0, 'r'], [0, 'eassiez'], [0, 'issiez'], [0, 'assiez'], [0, 'ussiez'], [0, 'issez'], [0, 'assez'], [0, 'eriez'], [0, 'iriez'], [0, 'erez'], [0, 'irez'], [0, 'iez'], [0, 'ez'], [0, 'erai'], [0, 'irai'], [0, 'eai'], [0, 'ai'], [0, 'i'], [0, 'ira'], [0, 'era'], [0, 'ea'], [0, 'a'], [0, 'f', 'v'], [0, 'yeux', 'oeil'], [0, 'eux'], [0, 'aux', 'al'], [0, 'x'], [0, 'issante'], [1, 'atrice'], // Added\n[0, 'eresse'], [0, 'eante'], [0, 'easse'], [0, 'eure'], [0, 'esse'], [0, 'asse'], [0, 'ance'], [0, 'ence'], [0, 'aise'], [0, 'euse'], [0, 'oise', 'o'], [0, 'isse'], [0, 'ante'], [0, 'ouse', 'ou'], [0, 'ière'], [0, 'ete'], [0, 'ète'], [0, 'iere'], [0, 'aire'], [1, 'ure'], [0, 'erie'], [0, 'étude'], [0, 'etude'], [0, 'itude'], [0, 'ade'], [0, 'isme'], [0, 'age'], [0, 'trice'], [0, 'cque', 'c'], [0, 'que', 'c'], [0, 'eille', 'eil'], [0, 'elle'], [0, 'able'], [0, 'iste'], [0, 'ulle', 'ul'], [0, 'gue', 'g'], [0, 'ette'], [0, 'nne', 'n'], [0, 'itée'], [0, 'ité'], [0, 'té'], [0, 'ée'], [0, 'é'], [0, 'usse'], [0, 'aise'], [0, 'ate'], [0, 'ite'], [0, 'ee'], [0, 'e'], [0, 'issements'], [0, 'issantes'], [1, 'ications'], [0, 'eassions'], [0, 'eresses'], [0, 'issions'], [0, 'assions'], [1, 'atrices'], // Added\n[1, 'iations'], [0, 'issants'], [0, 'ussions'], [0, 'ements'], [0, 'eantes'], [0, 'issons'], [0, 'assons'], [0, 'easses'], [0, 'études'], [0, 'etudes'], [0, 'itudes'], [0, 'issais'], [0, 'trices'], [0, 'eilles', 'eil'], [0, 'irions'], [0, 'erions'], [1, 'ateurs'], [1, 'ations'], [0, 'usses'], [0, 'tions'], [0, 'ances'], [0, 'entes'], [1, 'teurs'], [0, 'eants'], [0, 'ables'], [0, 'irons'], [0, 'irais'], [0, 'ences'], [0, 'ients'], [0, 'ieres'], [0, 'eures'], [0, 'aires'], [0, 'erons'], [0, 'esses'], [0, 'euses'], [0, 'ulles', 'ul'], [0, 'cques', 'c'], [0, 'elles'], [0, 'ables'], [0, 'istes'], [0, 'aises'], [0, 'asses'], [0, 'isses'], [0, 'oises', 'o'], [0, 'tions'], [0, 'ouses', 'ou'], [0, 'ières'], [0, 'eries'], [0, 'antes'], [0, 'ismes'], [0, 'erais'], [0, 'eâtes'], [0, 'eâmes'], [0, 'itées'], [0, 'ettes'], [0, 'ages'], [0, 'eurs'], [0, 'ents'], [0, 'ètes'], [0, 'etes'], [0, 'ions'], [0, 'ités'], [0, 'ites'], [0, 'ates'], [0, 'âtes'], [0, 'îtes'], [0, 'eurs'], [0, 'iers'], [0, 'iras'], [0, 'eras'], [1, 'ures'], [0, 'ants'], [0, 'îmes'], [0, 'ûmes'], [0, 'âmes'], [0, 'ades'], [0, 'eais'], [0, 'eons'], [0, 'ques', 'c'], [0, 'gues', 'g'], [0, 'nnes', 'n'], [0, 'ttes'], [0, 'îtes'], [0, 'tés'], [0, 'ons'], [0, 'ais'], [0, 'ées'], [0, 'ees'], [0, 'ats'], [0, 'eas'], [0, 'ts'], [0, 'rs'], [0, 'as'], [0, 'es'], [0, 'fs', 'v'], [0, 'és'], [0, 'is'], [0, 's'], [0, 'eau'], [0, 'au']];\n\nvar STEP2 = [[1, 'ation'], [1, 'ition'], [1, 'tion'], [1, 'ent'], [1, 'el'], [0, 'i']];\n\nvar STEP3 = [[0, 'll', 'l'], [0, 'mm', 'm'], [0, 'nn', 'n'], [0, 'pp', 'p'], [0, 'tt', 't'], [0, 'ss', 's'], [0, 'y'], [0, 't'], [0, 'qu', 'c']];\n\n/**\n * Function used to apply a set of rules to the current stem.\n *\n * @param  {string} stem - Target stem.\n * @return {string}      - The resulting stem.\n */\nfunction applyRules(rules, stem) {\n\n  for (var i = 0, l = rules.length; i < l; i++) {\n    var _rules$i = rules[i],\n        min = _rules$i[0],\n        pattern = _rules$i[1],\n        _rules$i$ = _rules$i[2],\n        replacement = _rules$i$ === undefined ? '' : _rules$i$;\n\n\n    if (stem.slice(-pattern.length) === pattern) {\n      var newStem = stem.slice(0, -pattern.length) + replacement,\n          m = computeM(newStem);\n\n      if (m <= min) continue;\n\n      return newStem;\n    }\n  }\n\n  return stem;\n}\n\n/**\n * Function stemming the given world using the Carry algorithm for the French\n * language.\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\nfunction carry(word) {\n  var stem = word.toLowerCase();\n\n  stem = applyRules(STEP1, stem);\n  stem = applyRules(STEP2, stem);\n  stem = applyRules(STEP3, stem);\n\n  return stem;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/french/eda.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = eda;\n\nvar _deburr = require('lodash/deburr');\n\nvar _deburr2 = _interopRequireDefault(_deburr);\n\nvar _helpers = require('../../helpers');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Constants.\n */\n/**\n * Talisman stemmers/french/eda\n * =============================\n *\n * The EDA stemmer for the French language. Note that this stemmers orignally\n * targets words from the medical world.\n *\n * [Reference]:\n * https://cedric.cnam.fr/fichiers/RC1314.pdf\n *\n * [Author]:\n * Didier Nakache\n *\n * [Article]:\n * Extraction automatique des diagnostics à partir des comptes rendus médicaux\n * textuels. Didier Nakache, 2007.\n */\nvar PHONETIC_RULES = [[/(?:cqu|qu|ck?)/g, 'k'], [/y/g, 'i']];\n\nvar SUFFIXES = ['s', 'e', 'x', 'ant', 'al', 'au', 'tion', 'sion', 'er', 'iv', 'if', 'abl', 'ibl', 'ment', 'tele', 'tel', 'tos', 'ik', 'ton', 'tos', 'ent', 'en', 'tik', 'toid', 'o', 'i', 's', 'dien', 'u', 'e', 'era', 'ank', 'enk', 'teur', 'trice', 'i'];\n\n/**\n * Function stemming the given world using the EDA algorithm for the French\n * language.\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\nfunction eda(word) {\n  var stem = (0, _helpers.squeeze)((0, _deburr2.default)(word.toLowerCase()));\n\n  // Early termination\n  if (stem.length <= 5) {\n    if (stem.slice(-1) === 'e') stem = stem.slice(0, -1);\n    if (stem.slice(-1) === 's') stem = stem.slice(0, -1);\n\n    return stem;\n  }\n\n  // Applying phonetic rules\n  for (var i = 0, l = PHONETIC_RULES.length; i < l; i++) {\n    var _PHONETIC_RULES$i = PHONETIC_RULES[i],\n        pattern = _PHONETIC_RULES$i[0],\n        replacement = _PHONETIC_RULES$i[1];\n\n\n    stem = stem.replace(pattern, replacement);\n  }\n\n  // Removing suffixes\n  for (var _i = 0, _l = SUFFIXES.length; _i < _l; _i++) {\n    var suffix = SUFFIXES[_i];\n\n    if (stem.slice(-suffix.length) === suffix) {\n      stem = stem.slice(0, -suffix.length);\n\n      if (stem.length <= 5) {\n        if (stem.slice(-1) === 'e') stem = stem.slice(0, -1);\n        if (stem.slice(-1) === 's') stem = stem.slice(0, -1);\n\n        return stem;\n      }\n    }\n  }\n\n  return stem;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/french/unine.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.minimal = minimal;\nexports.complex = complex;\n/**\n * Talisman stemmers/french/unine\n * ===============================\n *\n * The UniNE (University of Neuchâtel) stemmers for the French language.\n *\n * [Reference]:\n * http://members.unine.ch/jacques.savoy/clef/\n *\n * [Articles]:\n * Savoy, J. (1993). Stemming of French words based on grammatical category.\n * Journal of the American Society for Information Science, 44(1), 1-9.\n *\n * Savoy, J. (1999). A stemming procedure and stopword list for general French\n * corpora. Journal of the American Society for Information Science, 50(10),\n * 944-952.\n *\n * [Note]:\n * It should be possible to fix some bug relevant to SOLR's implementation.\n */\n\n/**\n * Function replacing the character at the given index in the target string.\n *\n * @param  {string} string - The target string.\n * @param  {number} index  - Index of the character to substitute.\n * @param  {string} char   - The replacing character.\n * @return {string}        - The resulting string.\n */\nfunction replaceAt(string, index, char) {\n  return string.substr(0, index) + char + string.substr(index + char.length);\n}\n\n/**\n * Function deleting the character at the given index in the target string.\n *\n * @param  {string} string - The target string.\n * @param  {number} index  - Index of the character to substitute.\n * @return {string}        - The resulting string.\n */\nfunction deleteAt(string, index) {\n  return string.substr(0, index) + string.substr(index + 1);\n}\n\n/**\n * Function checking whether the string has the given suffix.\n *\n * @param  {string} string - The target string.\n * @param  {number} length - Length offset.\n * @param  {string} suffix - The considered suffix.\n * @return {boolean}\n */\nfunction endsWith(string, length, suffix) {\n  if (suffix.length > length) return false;\n  return string.slice(0, length).slice(-suffix.length) === suffix;\n}\n\n/**\n * Function stemming the given world using the minimal UniNE algorithm for the\n * French language.\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\nfunction minimal(word) {\n  if (word.length < 6) return word;\n\n  var length = word.length;\n\n  if (word[length - 1] === 'x') {\n    if (word[length - 3] === 'a' && word[length - 2] === 'u') return word.slice(0, -2) + 'l';\n\n    return word.slice(0, -1);\n  }\n\n  if (word[length - 1] === 's') length--;\n  if (word[length - 1] === 'r') length--;\n  if (word[length - 1] === 'e') length--;\n  if (word[length - 1] === 'é') length--;\n  if (word[length - 1] === word[length - 2]) length--;\n\n  return word.slice(0, length);\n}\n\nexports.default = minimal;\n\n/**\n * Function stemming the given world using the complex UniNE algorithm for the\n * French language.\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\n\nfunction normalize(stem, length) {\n  if (length > 4) {\n    for (var i = 0; i < length; i++) {\n      switch (stem[i]) {\n        case 'à':\n        case 'á':\n        case 'â':\n          stem = replaceAt(stem, i, 'a');\n          break;\n        case 'ô':\n          stem = replaceAt(stem, i, 'o');\n          break;\n        case 'è':\n        case 'é':\n        case 'ê':\n          stem = replaceAt(stem, i, 'e');\n          break;\n        case 'ù':\n        case 'û':\n          stem = replaceAt(stem, i, 'u');\n          break;\n        case 'î':\n          stem = replaceAt(stem, i, 'i');\n          break;\n        case 'ç':\n          stem = replaceAt(stem, i, 'c');\n          break;\n        default:\n      }\n    }\n\n    var character = stem[0];\n\n    for (var _i = 1; _i < length; _i++) {\n      if (stem[_i] === character && /[^\\W\\d]/.test(character)) {\n        stem = deleteAt(stem, _i--);\n        length--;\n      } else {\n        character = stem[_i];\n      }\n    }\n  }\n\n  if (length > 4 && endsWith(stem, length, 'ie')) length -= 2;\n\n  if (length > 4) {\n    if (stem[length - 1] === 'r') length--;\n    if (stem[length - 1] === 'e') length--;\n    if (stem[length - 1] === 'e') length--;\n    if (stem[length - 1] === stem[length - 2] && /[^\\W\\d]/.test(stem[length - 1])) length--;\n  }\n\n  return stem.slice(0, length);\n}\n\nfunction complex(word) {\n  var length = word.length,\n      stem = word;\n\n  if (length > 5 && stem[length - 1] === 'x') {\n    if (stem[length - 3] === 'a' && stem[length - 2] === 'u' && stem[length - 4] !== 'e') {\n      stem = replaceAt(stem, length - 2, 'l');\n    }\n    length--;\n  }\n\n  if (length > 3 && stem[length - 1] === 'x') length--;\n\n  if (length > 3 && stem[length - 1] === 's') length--;\n\n  if (length > 9 && endsWith(stem, length, 'issement')) {\n    length -= 6;\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 8 && endsWith(stem, length, 'issant')) {\n    length -= 4;\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 6 && endsWith(stem, length, 'ement')) {\n    length -= 4;\n\n    if (length > 3 && endsWith(stem, length, 'ive')) {\n      length--;\n      stem = replaceAt(stem, length - 1, 'f');\n    }\n\n    return normalize(stem, length);\n  }\n\n  if (length > 11 && endsWith(stem, length, 'ficatrice')) {\n    length -= 5;\n    stem = replaceAt(stem, length - 2, 'e');\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 10 && endsWith(stem, length, 'ficateur')) {\n    length -= 4;\n    stem = replaceAt(stem, length - 2, 'e');\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 9 && endsWith(stem, length, 'catrice')) {\n    length -= 3;\n    stem = replaceAt(stem, length - 4, 'q');\n    stem = replaceAt(stem, length - 3, 'u');\n    stem = replaceAt(stem, length - 2, 'e');\n    return normalize(stem, length);\n  }\n\n  if (length > 8 && endsWith(stem, length, 'cateur')) {\n    length -= 2;\n    stem = replaceAt(stem, length - 4, 'q');\n    stem = replaceAt(stem, length - 3, 'u');\n    stem = replaceAt(stem, length - 2, 'e');\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 8 && endsWith(stem, length, 'atrice')) {\n    length -= 4;\n    stem = replaceAt(stem, length - 2, 'e');\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 7 && endsWith(stem, length, 'ateur')) {\n    length -= 3;\n    stem = replaceAt(stem, length - 2, 'e');\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 6 && endsWith(stem, length, 'trice')) {\n    length--;\n    stem = replaceAt(stem, length - 3, 'e');\n    stem = replaceAt(stem, length - 2, 'u');\n    stem = replaceAt(stem, length - 1, 'r');\n  }\n\n  if (length > 5 && endsWith(stem, length, 'ième')) return normalize(stem, length - 4);\n\n  if (length > 7 && endsWith(stem, length, 'teuse')) {\n    length -= 2;\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 6 && endsWith(stem, length, 'teur')) {\n    length--;\n    stem = replaceAt(stem, length - 1, 'r');\n    return normalize(stem, length);\n  }\n\n  if (length > 5 && endsWith(stem, length, 'euse')) return normalize(stem, length - 2);\n\n  if (length > 8 && endsWith(stem, length, 'ère')) {\n    length--;\n    stem = replaceAt(stem, length - 2, 'e');\n    return normalize(stem, length);\n  }\n\n  if (length > 7 && endsWith(stem, length, 'ive')) {\n    length--;\n    stem = replaceAt(stem, length - 1, 'f');\n    return normalize(stem, length);\n  }\n\n  if (length > 4 && (endsWith(stem, length, 'folle') || endsWith(stem, length, 'molle'))) {\n    length -= 2;\n    stem = replaceAt(stem, length - 1, 'u');\n    return normalize(stem, length);\n  }\n\n  if (length > 9 && endsWith(stem, length, 'nnelle')) return normalize(stem, length - 5);\n\n  if (length > 9 && endsWith(stem, length, 'nnel')) return normalize(stem, length - 3);\n\n  if (length > 4 && endsWith(stem, length, 'ète')) {\n    length--;\n    stem = replaceAt(stem, length - 2, 'e');\n  }\n\n  if (length > 8 && endsWith(stem, length, 'ique')) length -= 4;\n\n  if (length > 8 && endsWith(stem, length, 'esse')) return normalize(stem, length - 3);\n\n  if (length > 7 && endsWith(stem, length, 'inage')) return normalize(stem, length - 3);\n\n  if (length > 9 && endsWith(stem, length, 'isation')) {\n    length -= 7;\n    if (length > 5 && endsWith(stem, length, 'ual')) stem = replaceAt(stem, length - 2, 'e');\n    return normalize(stem, length);\n  }\n\n  if (length > 9 && endsWith(stem, length, 'isateur')) return normalize(stem, length - 7);\n\n  if (length > 8 && endsWith(stem, length, 'ation')) return normalize(stem, length - 5);\n\n  if (length > 8 && endsWith(stem, length, 'ition')) return normalize(stem, length - 5);\n\n  return normalize(stem, length);\n}\nmodule.exports = exports['default'];\nexports['default'].minimal = exports.minimal;\nexports['default'].complex = exports.complex;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/german/caumanns.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = caumanns;\n/**\n * Talisman stemmers/german/caumanns\n * ==================================\n *\n * The Caumanns stemmer for the German language.\n *\n * [Reference]:\n * http://edocs.fu-berlin.de/docs/servlets/MCRFileNodeServlet/FUDOCS_derivate_000000000350/tr-b-99-16.pdf\n *\n * [Article]:\n * Jörg Caumanns (1999) A Fast and Simple Stemming Algorithm for German Words.\n */\n\n/**\n * Function stemming the given world using the Caumanns algorithm.\n *\n * @param  {string} word - The word to stem.\n * @return {string}      - The resulting stem.\n */\nfunction caumanns(word) {\n  if (!word) return '';\n\n  // Note: this test would break on non-alpha characters\n  var upperInitial = word[0] === word.toUpperCase();\n\n  // Basic substitutions\n  word = word.toLowerCase().replace(/ä/g, 'a').replace(/ö/g, 'o').replace(/ü/g, 'u').replace(/ß/g, 'ss');\n\n  // Special squeezing\n  var stem = word[0];\n  for (var i = 1, l = word.length; i < l; i++) {\n    stem += word[i] !== word[i - 1] ? word[i] : '*';\n  } // Replacing some combinations of letters\n  stem = stem.replace(/sch/g, '$').replace(/ch/g, '§').replace(/ei/g, '%').replace(/ie/g, '&').replace(/ig/g, '#').replace(/st/g, '!');\n\n  // Recursive context-free stripping\n  while (stem.length > 3) {\n    var lastTwoLetters = stem.slice(-2),\n        lastLetter = stem[stem.length - 1];\n\n    if (stem.length > 4 && (lastTwoLetters === 'em' || lastTwoLetters === 'er') || stem.length > 5 && lastTwoLetters === 'nd') {\n      stem = stem.slice(0, -2);\n    } else if (lastLetter === 'e' || lastLetter === 's' || lastLetter === 'n' || !upperInitial && (lastLetter === 't' || lastLetter === '!')) {\n      stem = stem.slice(0, -1);\n    } else {\n      break;\n    }\n  }\n\n  // Optimizations\n  if (stem.length > 5 && stem.slice(-5) === 'erin*') stem = stem.slice(0, -1);\n\n  if (stem[stem.length - 1] === 'z') stem = stem.slice(0, -1) + 'x';\n\n  // Reverse substitutions\n  stem = stem.replace(/\\$/g, 'sch').replace(/§/g, 'ch').replace(/%/g, 'ei').replace(/&/g, 'ie').replace(/#/g, 'ig').replace(/!/g, 'st');\n\n  // Expand doubled\n  var finalStem = stem[0];\n  for (var _i = 1, _l = stem.length; _i < _l; _i++) {\n    finalStem += stem[_i] === '*' ? finalStem[_i - 1] : stem[_i];\n  }if (finalStem.length < 4) finalStem = finalStem.replace('gege', 'ge');\n\n  return finalStem;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/stemmers/latin/schinke.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nexports.default = function (word) {\n\n  // Preparing the word\n  var preparedWord = normalizeLetters(word.toLowerCase().replace(/[^a-z]/g, ''));\n\n  // Dropping the -que suffix\n  var stem = preparedWord.replace(/que$/, '');\n\n  // Checking whether the word ends in -que & is a protected stem\n  if (preparedWord !== stem && QUE_SET.has(preparedWord)) return {\n    noun: preparedWord,\n    verb: preparedWord\n  };\n\n  var nounStem = stem,\n      verbStem = stem;\n\n  // Computing the noun stem\n  for (var i = 0, l = SIMPLE_SUFFIXES.length; i < l; i++) {\n    var newStem = nounStem.replace(SIMPLE_SUFFIXES[i], '');\n\n    if (newStem !== stem) {\n      nounStem = newStem;\n      break;\n    }\n  }\n\n  // Computing the verb stem\n  for (var _i = 0, _l = VERB_SUFFIXES.length; _i < _l; _i++) {\n    var _VERB_SUFFIXES$_i = VERB_SUFFIXES[_i],\n        match = _VERB_SUFFIXES$_i[0],\n        replacement = _VERB_SUFFIXES$_i[1];\n\n\n    if (match.test(verbStem)) {\n      var pattern = new RegExp((replacement ? '(.{2,})' : '') + match.source);\n\n      verbStem = verbStem.replace(pattern, replacement || '');\n      break;\n    }\n  }\n\n  // Returning the stem only if longer than one character\n  return {\n    noun: nounStem.length > 1 ? nounStem : stem,\n    verb: verbStem.length > 1 ? verbStem : stem\n  };\n};\n\n/**\n * Talisman stemmers/latin/schinke\n * ================================\n *\n * The Schinke stemming algorithm (latin).\n *\n * [Reference]:\n * http://snowball.tartarus.org/otherapps/schinke/intro.html\n */\n\n/**\n * Rules.\n */\nvar QUE_SET = new Set(['atque', 'quoque', 'neque', 'itaque', 'absque', 'apsque', 'abusque', 'adaeque', 'adusque', 'denique', 'deque', 'susque', 'oblique', 'peraeque', 'plenisque', 'quandoque', 'quisque', 'quaeque', 'cuiusque', 'cuique', 'quemque', 'quamque', 'quaque', 'quique', 'quorumque', 'quarumque', 'quibusque', 'quosque', 'quasque', 'quotusquisque', 'quousque', 'ubique', 'undique', 'usque', 'uterque', 'utique', 'utroque', 'utribique', 'torque', 'coque', 'concoque', 'contorque', 'detorque', 'decoque', 'excoque', 'extorque', 'obtorque', 'optorque', 'retorque', 'recoque', 'attorque', 'incoque', 'intorque', 'praetorque']);\n\nvar SIMPLE_SUFFIXES = [/ibus$/, /ius$/, /ae$/, /am$/, /as$/, /em$/, /es$/, /ia$/, /is$/, /nt$/, /os$/, /ud$/, /um$/, /us$/, /a$/, /e$/, /i$/, /o$/, /u$/];\n\nvar VERB_SUFFIXES = [[/iuntur$/, '$1i'], [/erunt$/, '$1i'], [/untur$/, '$1i'], [/iunt$/, '$1i'], [/unt$/, '$1i'], [/beris$/, '$1bi'], [/bor$/, '$1bi'], [/bo$/, '$1bi'], [/ero$/, '$1eri'], [/mini$/], [/ntur$/], [/stis$/], [/mur$/], [/mus$/], [/ris$/], [/sti$/], [/tis$/], [/tur$/], [/ns$/], [/nt$/], [/ri$/], [/m$/], [/r$/], [/s$/], [/t$/]];\n\n/**\n * Helpers.\n */\nfunction normalizeLetters(stem) {\n  return stem.replace(/j/g, 'i').replace(/v/g, 'u');\n}\n\n/**\n * Function stemming the given latin word using the Schinke algorithm and\n * returning a noun stem and a verb stem.\n *\n * @param  {string} word - The word to stem.\n * @return {objet}       - The resulting stems (noun & verb).\n */\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/hyphenation/liang.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = liang;\n\nvar _vectors = require('../../helpers/vectors');\n\n/**\n * Data.\n */\nvar EXCEPTIONS = {\n  associate: ['as', 'so', 'ciate'],\n  associates: ['as', 'so', 'ciates'],\n  declination: ['de', 'cli', 'na', 'tion'],\n  obligatory: ['oblig', 'a', 'tory'],\n  philanthropic: ['phil', 'an', 'thropic'],\n  present: ['present'],\n  presents: ['presents'],\n  project: ['project'],\n  projects: ['projects'],\n  reciprocity: ['reci', 'procity'],\n  recognizance: ['re', 'cog', 'ni', 'zance'],\n  reformantion: ['ref', 'or', 'ma', 'tion'],\n  retribution: ['ret', 'ri', 'bu', 'tion'],\n  table: ['ta', 'ble']\n}; /**\n    * Talisman tokenizers/hyphenation/liang\n    * ======================================\n    *\n    * Implementation of Frank Liang's hyphenation.\n    *\n    * [Reference]:\n    * https://tug.org/docs/liang/\n    *\n    * [Article]:\n    * Liang, Franklin Mark. \"Word Hy-phen-a-tion by Com-pu-ter\". PhD dissertation,\n    * Stanford University Department of Computer Science.\n    * Report number STAN-CS-83-977, August 1983.\n    *\n    * [Note]:\n    * This implementation follows the python one described here:\n    * http://nedbatchelder.com/code/modules/hyphenate.html\n    */\n\n\nvar PATTERNS = '\\n.ach4 .ad4der .af1t .al3t .am5at .an5c .ang4 .ani5m .ant4 .an3te .anti5s .ar5s\\n.ar4tie .ar4ty .as3c .as1p .as1s .aster5 .atom5 .au1d .av4i .awn4 .ba4g .ba5na\\n.bas4e .ber4 .be5ra .be3sm .be5sto .bri2 .but4ti .cam4pe .can5c .capa5b .car5ol\\n.ca4t .ce4la .ch4 .chill5i .ci2 .cit5r .co3e .co4r .cor5ner .de4moi .de3o .de3ra\\n.de3ri .des4c .dictio5 .do4t .du4c .dumb5 .earth5 .eas3i .eb4 .eer4 .eg2 .el5d\\n.el3em .enam3 .en3g .en3s .eq5ui5t .er4ri .es3 .eu3 .eye5 .fes3 .for5mer .ga2\\n.ge2 .gen3t4 .ge5og .gi5a .gi4b .go4r .hand5i .han5k .he2 .hero5i .hes3 .het3\\n.hi3b .hi3er .hon5ey .hon3o .hov5 .id4l .idol3 .im3m .im5pin .in1 .in3ci .ine2\\n.in2k .in3s .ir5r .is4i .ju3r .la4cy .la4m .lat5er .lath5 .le2 .leg5e .len4\\n.lep5 .lev1 .li4g .lig5a .li2n .li3o .li4t .mag5a5 .mal5o .man5a .mar5ti .me2\\n.mer3c .me5ter .mis1 .mist5i .mon3e .mo3ro .mu5ta .muta5b .ni4c .od2 .odd5\\n.of5te .or5ato .or3c .or1d .or3t .os3 .os4tl .oth3 .out3 .ped5al .pe5te .pe5tit\\n.pi4e .pio5n .pi2t .pre3m .ra4c .ran4t .ratio5na .ree2 .re5mit .res2 .re5stat\\n.ri4g .rit5u .ro4q .ros5t .row5d .ru4d .sci3e .self5 .sell5 .se2n .se5rie .sh2\\n.si2 .sing4 .st4 .sta5bl .sy2 .ta4 .te4 .ten5an .th2 .ti2 .til4 .tim5o5 .ting4\\n.tin5k .ton4a .to4p .top5i .tou5s .trib5ut .un1a .un3ce .under5 .un1e .un5k\\n.un5o .un3u .up3 .ure3 .us5a .ven4de .ve5ra .wil5i .ye4 4ab. a5bal a5ban abe2\\nab5erd abi5a ab5it5ab ab5lat ab5o5liz 4abr ab5rog ab3ul a4car ac5ard ac5aro\\na5ceou ac1er a5chet 4a2ci a3cie ac1in a3cio ac5rob act5if ac3ul ac4um a2d ad4din\\nad5er. 2adi a3dia ad3ica adi4er a3dio a3dit a5diu ad4le ad3ow ad5ran ad4su 4adu\\na3duc ad5um ae4r aeri4e a2f aff4 a4gab aga4n ag5ell age4o 4ageu ag1i 4ag4l ag1n\\na2go 3agog ag3oni a5guer ag5ul a4gy a3ha a3he ah4l a3ho ai2 a5ia a3ic. ai5ly\\na4i4n ain5in ain5o ait5en a1j ak1en al5ab al3ad a4lar 4aldi 2ale al3end a4lenti\\na5le5o al1i al4ia. ali4e al5lev 4allic 4alm a5log. a4ly. 4alys 5a5lyst 5alyt\\n3alyz 4ama am5ab am3ag ama5ra am5asc a4matis a4m5ato am5era am3ic am5if am5ily\\nam1in ami4no a2mo a5mon amor5i amp5en a2n an3age 3analy a3nar an3arc anar4i\\na3nati 4and ande4s an3dis an1dl an4dow a5nee a3nen an5est. a3neu 2ang ang5ie\\nan1gl a4n1ic a3nies an3i3f an4ime a5nimi a5nine an3io a3nip an3ish an3it a3niu\\nan4kli 5anniz ano4 an5ot anoth5 an2sa an4sco an4sn an2sp ans3po an4st an4sur\\nantal4 an4tie 4anto an2tr an4tw an3ua an3ul a5nur 4ao apar4 ap5at ap5ero a3pher\\n4aphi a4pilla ap5illar ap3in ap3ita a3pitu a2pl apoc5 ap5ola apor5i apos3t\\naps5es a3pu aque5 2a2r ar3act a5rade ar5adis ar3al a5ramete aran4g ara3p ar4at\\na5ratio ar5ativ a5rau ar5av4 araw4 arbal4 ar4chan ar5dine ar4dr ar5eas a3ree\\nar3ent a5ress ar4fi ar4fl ar1i ar5ial ar3ian a3riet ar4im ar5inat ar3io ar2iz\\nar2mi ar5o5d a5roni a3roo ar2p ar3q arre4 ar4sa ar2sh 4as. as4ab as3ant ashi4\\na5sia. a3sib a3sic 5a5si4t ask3i as4l a4soc as5ph as4sh as3ten as1tr asur5a a2ta\\nat3abl at5ac at3alo at5ap ate5c at5ech at3ego at3en. at3era ater5n a5terna\\nat3est at5ev 4ath ath5em a5then at4ho ath5om 4ati. a5tia at5i5b at1ic at3if\\nation5ar at3itu a4tog a2tom at5omiz a4top a4tos a1tr at5rop at4sk at4tag at5te\\nat4th a2tu at5ua at5ue at3ul at3ura a2ty au4b augh3 au3gu au4l2 aun5d au3r\\nau5sib aut5en au1th a2va av3ag a5van ave4no av3era av5ern av5ery av1i avi4er\\nav3ig av5oc a1vor 3away aw3i aw4ly aws4 ax4ic ax4id ay5al aye4 ays4 azi4er azz5i\\n5ba. bad5ger ba4ge bal1a ban5dag ban4e ban3i barbi5 bari4a bas4si 1bat ba4z 2b1b\\nb2be b3ber bbi4na 4b1d 4be. beak4 beat3 4be2d be3da be3de be3di be3gi be5gu 1bel\\nbe1li be3lo 4be5m be5nig be5nu 4bes4 be3sp be5str 3bet bet5iz be5tr be3tw be3w\\nbe5yo 2bf 4b3h bi2b bi4d 3bie bi5en bi4er 2b3if 1bil bi3liz bina5r4 bin4d bi5net\\nbi3ogr bi5ou bi2t 3bi3tio bi3tr 3bit5ua b5itz b1j bk4 b2l2 blath5 b4le. blen4\\n5blesp b3lis b4lo blun4t 4b1m 4b3n bne5g 3bod bod3i bo4e bol3ic bom4bi bon4a\\nbon5at 3boo 5bor. 4b1ora bor5d 5bore 5bori 5bos4 b5ota both5 bo4to bound3 4bp\\n4brit broth3 2b5s2 bsor4 2bt bt4l b4to b3tr buf4fer bu4ga bu3li bumi4 bu4n\\nbunt4i bu3re bus5ie buss4e 5bust 4buta 3butio b5uto b1v 4b5w 5by. bys4 1ca\\ncab3in ca1bl cach4 ca5den 4cag4 2c5ah ca3lat cal4la call5in 4calo can5d can4e\\ncan4ic can5is can3iz can4ty cany4 ca5per car5om cast5er cas5tig 4casy ca4th\\n4cativ cav5al c3c ccha5 cci4a ccompa5 ccon4 ccou3t 2ce. 4ced. 4ceden 3cei 5cel.\\n3cell 1cen 3cenc 2cen4e 4ceni 3cent 3cep ce5ram 4cesa 3cessi ces5si5b ces5t cet4\\nc5e4ta cew4 2ch 4ch. 4ch3ab 5chanic ch5a5nis che2 cheap3 4ched che5lo 3chemi\\nch5ene ch3er. ch3ers 4ch1in 5chine. ch5iness 5chini 5chio 3chit chi2z 3cho2\\nch4ti 1ci 3cia ci2a5b cia5r ci5c 4cier 5cific. 4cii ci4la 3cili 2cim 2cin c4ina\\n3cinat cin3em c1ing c5ing. 5cino cion4 4cipe ci3ph 4cipic 4cista 4cisti 2c1it\\ncit3iz 5ciz ck1 ck3i 1c4l4 4clar c5laratio 5clare cle4m 4clic clim4 cly4 c5n 1co\\nco5ag coe2 2cog co4gr coi4 co3inc col5i 5colo col3or com5er con4a c4one con3g\\ncon5t co3pa cop3ic co4pl 4corb coro3n cos4e cov1 cove4 cow5a coz5e co5zi c1q\\ncras5t 5crat. 5cratic cre3at 5cred 4c3reta cre4v cri2 cri5f c4rin cris4 5criti\\ncro4pl crop5o cros4e cru4d 4c3s2 2c1t cta4b ct5ang c5tant c2te c3ter c4ticu\\nctim3i ctu4r c4tw cud5 c4uf c4ui cu5ity 5culi cul4tis 3cultu cu2ma c3ume cu4mi\\n3cun cu3pi cu5py cur5a4b cu5ria 1cus cuss4i 3c4ut cu4tie 4c5utiv 4cutr 1cy cze4\\n1d2a 5da. 2d3a4b dach4 4daf 2dag da2m2 dan3g dard5 dark5 4dary 3dat 4dativ 4dato\\n5dav4 dav5e 5day d1b d5c d1d4 2de. deaf5 deb5it de4bon decan4 de4cil de5com\\n2d1ed 4dee. de5if deli4e del5i5q de5lo d4em 5dem. 3demic dem5ic. de5mil de4mons\\ndemor5 1den de4nar de3no denti5f de3nu de1p de3pa depi4 de2pu d3eq d4erh 5derm\\ndern5iz der5s des2 d2es. de1sc de2s5o des3ti de3str de4su de1t de2to de1v dev3il\\n4dey 4d1f d4ga d3ge4t dg1i d2gy d1h2 5di. 1d4i3a dia5b di4cam d4ice 3dict 3did\\n5di3en d1if di3ge di4lato d1in 1dina 3dine. 5dini di5niz 1dio dio5g di4pl dir2\\ndi1re dirt5i dis1 5disi d4is3t d2iti 1di1v d1j d5k2 4d5la 3dle. 3dled 3dles.\\n4dless 2d3lo 4d5lu 2dly d1m 4d1n4 1do 3do. do5de 5doe 2d5of d4og do4la doli4\\ndo5lor dom5iz do3nat doni4 doo3d dop4p d4or 3dos 4d5out do4v 3dox d1p 1dr\\ndrag5on 4drai dre4 drea5r 5dren dri4b dril4 dro4p 4drow 5drupli 4dry 2d1s2 ds4p\\nd4sw d4sy d2th 1du d1u1a du2c d1uca duc5er 4duct. 4ducts du5el du4g d3ule dum4be\\ndu4n 4dup du4pe d1v d1w d2y 5dyn dy4se dys5p e1a4b e3act ead1 ead5ie ea4ge\\nea5ger ea4l eal5er eal3ou eam3er e5and ear3a ear4c ear5es ear4ic ear4il ear5k\\near2t eart3e ea5sp e3ass east3 ea2t eat5en eath3i e5atif e4a3tu ea2v eav3en\\neav5i eav5o 2e1b e4bel. e4bels e4ben e4bit e3br e4cad ecan5c ecca5 e1ce ec5essa\\nec2i e4cib ec5ificat ec5ifie ec5ify ec3im eci4t e5cite e4clam e4clus e2col\\ne4comm e4compe e4conc e2cor ec3ora eco5ro e1cr e4crem ec4tan ec4te e1cu e4cul\\nec3ula 2e2da 4ed3d e4d1er ede4s 4edi e3dia ed3ib ed3ica ed3im ed1it edi5z 4edo\\ne4dol edon2 e4dri e4dul ed5ulo ee2c eed3i ee2f eel3i ee4ly ee2m ee4na ee4p1\\nee2s4 eest4 ee4ty e5ex e1f e4f3ere 1eff e4fic 5efici efil4 e3fine ef5i5nite\\n3efit efor5es e4fuse. 4egal eger4 eg5ib eg4ic eg5ing e5git5 eg5n e4go. e4gos\\neg1ul e5gur 5egy e1h4 eher4 ei2 e5ic ei5d eig2 ei5gl e3imb e3inf e1ing e5inst\\neir4d eit3e ei3th e5ity e1j e4jud ej5udi eki4n ek4la e1la e4la. e4lac elan4d\\nel5ativ e4law elaxa4 e3lea el5ebra 5elec e4led el3ega e5len e4l1er e1les el2f\\nel2i e3libe e4l5ic. el3ica e3lier el5igib e5lim e4l3ing e3lio e2lis el5ish\\ne3liv3 4ella el4lab ello4 e5loc el5og el3op. el2sh el4ta e5lud el5ug e4mac e4mag\\ne5man em5ana em5b e1me e2mel e4met em3ica emi4e em5igra em1in2 em5ine em3i3ni\\ne4mis em5ish e5miss em3iz 5emniz emo4g emoni5o em3pi e4mul em5ula emu3n e3my\\nen5amo e4nant ench4er en3dic e5nea e5nee en3em en5ero en5esi en5est en3etr e3new\\nen5ics e5nie e5nil e3nio en3ish en3it e5niu 5eniz 4enn 4eno eno4g e4nos en3ov\\nen4sw ent5age 4enthes en3ua en5uf e3ny. 4en3z e5of eo2g e4oi4 e3ol eop3ar e1or\\neo3re eo5rol eos4 e4ot eo4to e5out e5ow e2pa e3pai ep5anc e5pel e3pent ep5etitio\\nephe4 e4pli e1po e4prec ep5reca e4pred ep3reh e3pro e4prob ep4sh ep5ti5b e4put\\nep5uta e1q equi3l e4q3ui3s er1a era4b 4erand er3ar 4erati. 2erb er4bl er3ch\\ner4che 2ere. e3real ere5co ere3in er5el. er3emo er5ena er5ence 4erene er3ent\\nere4q er5ess er3est eret4 er1h er1i e1ria4 5erick e3rien eri4er er3ine e1rio\\n4erit er4iu eri4v e4riva er3m4 er4nis 4ernit 5erniz er3no 2ero er5ob e5roc ero4r\\ner1ou er1s er3set ert3er 4ertl er3tw 4eru eru4t 5erwau e1s4a e4sage. e4sages\\nes2c e2sca es5can e3scr es5cu e1s2e e2sec es5ecr es5enc e4sert. e4serts e4serva\\n4esh e3sha esh5en e1si e2sic e2sid es5iden es5igna e2s5im es4i4n esis4te esi4u\\ne5skin es4mi e2sol es3olu e2son es5ona e1sp es3per es5pira es4pre 2ess es4si4b\\nestan4 es3tig es5tim 4es2to e3ston 2estr e5stro estruc5 e2sur es5urr es4w eta4b\\neten4d e3teo ethod3 et1ic e5tide etin4 eti4no e5tir e5titio et5itiv 4etn et5ona\\ne3tra e3tre et3ric et5rif et3rog et5ros et3ua et5ym et5z 4eu e5un e3up eu3ro\\neus4 eute4 euti5l eu5tr eva2p5 e2vas ev5ast e5vea ev3ell evel3o e5veng even4i\\nev1er e5verb e1vi ev3id evi4l e4vin evi4v e5voc e5vu e1wa e4wag e5wee e3wh ewil5\\new3ing e3wit 1exp 5eyc 5eye. eys4 1fa fa3bl fab3r fa4ce 4fag fain4 fall5e 4fa4ma\\nfam5is 5far far5th fa3ta fa3the 4fato fault5 4f5b 4fd 4fe. feas4 feath3 fe4b\\n4feca 5fect 2fed fe3li fe4mo fen2d fend5e fer1 5ferr fev4 4f1f f4fes f4fie\\nf5fin. f2f5is f4fly f2fy 4fh 1fi fi3a 2f3ic. 4f3ical f3ican 4ficate f3icen\\nfi3cer fic4i 5ficia 5ficie 4fics fi3cu fi5del fight5 fil5i fill5in 4fily 2fin\\n5fina fin2d5 fi2ne f1in3g fin4n fis4ti f4l2 f5less flin4 flo3re f2ly5 4fm 4fn\\n1fo 5fon fon4de fon4t fo2r fo5rat for5ay fore5t for4i fort5a fos5 4f5p fra4t\\nf5rea fres5c fri2 fril4 frol5 2f3s 2ft f4to f2ty 3fu fu5el 4fug fu4min fu5ne\\nfu3ri fusi4 fus4s 4futa 1fy 1ga gaf4 5gal. 3gali ga3lo 2gam ga5met g5amo gan5is\\nga3niz gani5za 4gano gar5n4 gass4 gath3 4gativ 4gaz g3b gd4 2ge. 2ged geez4\\ngel4in ge5lis ge5liz 4gely 1gen ge4nat ge5niz 4geno 4geny 1geo ge3om g4ery 5gesi\\ngeth5 4geto ge4ty ge4v 4g1g2 g2ge g3ger gglu5 ggo4 gh3in gh5out gh4to 5gi. 1gi4a\\ngia5r g1ic 5gicia g4ico gien5 5gies. gil4 g3imen 3g4in. gin5ge 5g4ins 5gio 3gir\\ngir4l g3isl gi4u 5giv 3giz gl2 gla4 glad5i 5glas 1gle gli4b g3lig 3glo glo3r g1m\\ng4my gn4a g4na. gnet4t g1ni g2nin g4nio g1no g4non 1go 3go. gob5 5goe 3g4o4g\\ngo3is gon2 4g3o3na gondo5 go3ni 5goo go5riz gor5ou 5gos. gov1 g3p 1gr 4grada\\ng4rai gran2 5graph. g5rapher 5graphic 4graphy 4gray gre4n 4gress. 4grit g4ro\\ngruf4 gs2 g5ste gth3 gu4a 3guard 2gue 5gui5t 3gun 3gus 4gu4t g3w 1gy 2g5y3n\\ngy5ra h3ab4l hach4 hae4m hae4t h5agu ha3la hala3m ha4m han4ci han4cy 5hand.\\nhan4g hang5er hang5o h5a5niz han4k han4te hap3l hap5t ha3ran ha5ras har2d hard3e\\nhar4le harp5en har5ter has5s haun4 5haz haz3a h1b 1head 3hear he4can h5ecat h4ed\\nhe5do5 he3l4i hel4lis hel4ly h5elo hem4p he2n hena4 hen5at heo5r hep5 h4era\\nhera3p her4ba here5a h3ern h5erou h3ery h1es he2s5p he4t het4ed heu4 h1f h1h\\nhi5an hi4co high5 h4il2 himer4 h4ina hion4e hi4p hir4l hi3ro hir4p hir4r his3el\\nhis4s hith5er hi2v 4hk 4h1l4 hlan4 h2lo hlo3ri 4h1m hmet4 2h1n h5odiz h5ods ho4g\\nhoge4 hol5ar 3hol4e ho4ma home3 hon4a ho5ny 3hood hoon4 hor5at ho5ris hort3e\\nho5ru hos4e ho5sen hos1p 1hous house3 hov5el 4h5p 4hr4 hree5 hro5niz hro3po\\n4h1s2 h4sh h4tar ht1en ht5es h4ty hu4g hu4min hun5ke hun4t hus3t4 hu4t h1w\\nh4wart hy3pe hy3ph hy2s 2i1a i2al iam4 iam5ete i2an 4ianc ian3i 4ian4t ia5pe\\niass4 i4ativ ia4tric i4atu ibe4 ib3era ib5ert ib5ia ib3in ib5it. ib5ite i1bl\\nib3li i5bo i1br i2b5ri i5bun 4icam 5icap 4icar i4car. i4cara icas5 i4cay iccu4\\n4iceo 4ich 2ici i5cid ic5ina i2cip ic3ipa i4cly i2c5oc 4i1cr 5icra i4cry ic4te\\nictu2 ic4t3ua ic3ula ic4um ic5uo i3cur 2id i4dai id5anc id5d ide3al ide4s i2di\\nid5ian idi4ar i5die id3io idi5ou id1it id5iu i3dle i4dom id3ow i4dr i2du id5uo\\n2ie4 ied4e 5ie5ga ield3 ien5a4 ien4e i5enn i3enti i1er. i3esc i1est i3et 4if.\\nif5ero iff5en if4fr 4ific. i3fie i3fl 4ift 2ig iga5b ig3era ight3i 4igi i3gib\\nig3il ig3in ig3it i4g4l i2go ig3or ig5ot i5gre igu5i ig1ur i3h 4i5i4 i3j 4ik\\ni1la il3a4b i4lade i2l5am ila5ra i3leg il1er ilev4 il5f il1i il3ia il2ib il3io\\nil4ist 2ilit il2iz ill5ab 4iln il3oq il4ty il5ur il3v i4mag im3age ima5ry\\nimenta5r 4imet im1i im5ida imi5le i5mini 4imit im4ni i3mon i2mu im3ula 2in.\\ni4n3au 4inav incel4 in3cer 4ind in5dling 2ine i3nee iner4ar i5ness 4inga 4inge\\nin5gen 4ingi in5gling 4ingo 4ingu 2ini i5ni. i4nia in3io in1is i5nite. 5initio\\nin3ity 4ink 4inl 2inn 2i1no i4no4c ino4s i4not 2ins in3se insur5a 2int. 2in4th\\nin1u i5nus 4iny 2io 4io. ioge4 io2gr i1ol io4m ion3at ion4ery ion3i io5ph ior3i\\ni4os io5th i5oti io4to i4our 2ip ipe4 iphras4 ip3i ip4ic ip4re4 ip3ul i3qua\\niq5uef iq3uid iq3ui3t 4ir i1ra ira4b i4rac ird5e ire4de i4ref i4rel4 i4res ir5gi\\nir1i iri5de ir4is iri3tu 5i5r2iz ir4min iro4g 5iron. ir5ul 2is. is5ag is3ar\\nisas5 2is1c is3ch 4ise is3er 3isf is5han is3hon ish5op is3ib isi4d i5sis is5itiv\\n4is4k islan4 4isms i2so iso5mer is1p is2pi is4py 4is1s is4sal issen4 is4ses\\nis4ta. is1te is1ti ist4ly 4istral i2su is5us 4ita. ita4bi i4tag 4ita5m i3tan\\ni3tat 2ite it3era i5teri it4es 2ith i1ti 4itia 4i2tic it3ica 5i5tick it3ig\\nit5ill i2tim 2itio 4itis i4tism i2t5o5m 4iton i4tram it5ry 4itt it3uat i5tud\\nit3ul 4itz. i1u 2iv iv3ell iv3en. i4v3er. i4vers. iv5il. iv5io iv1it i5vore\\niv3o3ro i4v3ot 4i5w ix4o 4iy 4izar izi4 5izont 5ja jac4q ja4p 1je jer5s 4jestie\\n4jesty jew3 jo4p 5judg 3ka. k3ab k5ag kais4 kal4 k1b k2ed 1kee ke4g ke5li k3en4d\\nk1er kes4 k3est. ke4ty k3f kh4 k1i 5ki. 5k2ic k4ill kilo5 k4im k4in. kin4de\\nk5iness kin4g ki4p kis4 k5ish kk4 k1l 4kley 4kly k1m k5nes 1k2no ko5r kosh4 k3ou\\nkro5n 4k1s2 k4sc ks4l k4sy k5t k1w lab3ic l4abo laci4 l4ade la3dy lag4n lam3o\\n3land lan4dl lan5et lan4te lar4g lar3i las4e la5tan 4lateli 4lativ 4lav la4v4a\\n2l1b lbin4 4l1c2 lce4 l3ci 2ld l2de ld4ere ld4eri ldi4 ld5is l3dr l4dri le2a\\nle4bi left5 5leg. 5legg le4mat lem5atic 4len. 3lenc 5lene. 1lent le3ph le4pr\\nlera5b ler4e 3lerg 3l4eri l4ero les2 le5sco 5lesq 3less 5less. l3eva lev4er.\\nlev4era lev4ers 3ley 4leye 2lf l5fr 4l1g4 l5ga lgar3 l4ges lgo3 2l3h li4ag li2am\\nliar5iz li4as li4ato li5bi 5licio li4cor 4lics 4lict. l4icu l3icy l3ida lid5er\\n3lidi lif3er l4iff li4fl 5ligate 3ligh li4gra 3lik 4l4i4l lim4bl lim3i li4mo\\nl4im4p l4ina 1l4ine lin3ea lin3i link5er li5og 4l4iq lis4p l1it l2it. 5litica\\nl5i5tics liv3er l1iz 4lj lka3 l3kal lka4t l1l l4law l2le l5lea l3lec l3leg l3lel\\nl3le4n l3le4t ll2i l2lin4 l5lina ll4o lloqui5 ll5out l5low 2lm l5met lm3ing\\nl4mod lmon4 2l1n2 3lo. lob5al lo4ci 4lof 3logic l5ogo 3logu lom3er 5long lon4i\\nl3o3niz lood5 5lope. lop3i l3opm lora4 lo4rato lo5rie lor5ou 5los. los5et\\n5losophiz 5losophy los4t lo4ta loun5d 2lout 4lov 2lp lpa5b l3pha l5phi lp5ing\\nl3pit l4pl l5pr 4l1r 2l1s2 l4sc l2se l4sie 4lt lt5ag ltane5 l1te lten4 ltera4\\nlth3i l5ties. ltis4 l1tr ltu2 ltur3a lu5a lu3br luch4 lu3ci lu3en luf4 lu5id\\nlu4ma 5lumi l5umn. 5lumnia lu3o luo3r 4lup luss4 lus3te 1lut l5ven l5vet4 2l1w\\n1ly 4lya 4lyb ly5me ly3no 2lys4 l5yse 1ma 2mab ma2ca ma5chine ma4cl mag5in 5magn\\n2mah maid5 4mald ma3lig ma5lin mal4li mal4ty 5mania man5is man3iz 4map ma5rine.\\nma5riz mar4ly mar3v ma5sce mas4e mas1t 5mate math3 ma3tis 4matiza 4m1b mba4t5\\nm5bil m4b3ing mbi4v 4m5c 4me. 2med 4med. 5media me3die m5e5dy me2g mel5on mel4t\\nme2m mem1o3 1men men4a men5ac men4de 4mene men4i mens4 mensu5 3ment men4te me5on\\nm5ersa 2mes 3mesti me4ta met3al me1te me5thi m4etr 5metric me5trie me3try me4v\\n4m1f 2mh 5mi. mi3a mid4a mid4g mig4 3milia m5i5lie m4ill min4a 3mind m5inee\\nm4ingl min5gli m5ingly min4t m4inu miot4 m2is mis4er. mis5l mis4ti m5istry 4mith\\nm2iz 4mk 4m1l m1m mma5ry 4m1n mn4a m4nin mn4o 1mo 4mocr 5mocratiz mo2d1 mo4go\\nmois2 moi5se 4mok mo5lest mo3me mon5et mon5ge moni3a mon4ism mon4ist mo3niz\\nmonol4 mo3ny. mo2r 4mora. mos2 mo5sey mo3sp moth3 m5ouf 3mous mo2v 4m1p mpara5\\nmpa5rab mpar5i m3pet mphas4 m2pi mpi4a mp5ies m4p1in m5pir mp5is mpo3ri mpos5ite\\nm4pous mpov5 mp4tr m2py 4m3r 4m1s2 m4sh m5si 4mt 1mu mula5r4 5mult multi3 3mum\\nmun2 4mup mu4u 4mw 1na 2n1a2b n4abu 4nac. na4ca n5act nag5er. nak4 na4li na5lia\\n4nalt na5mit n2an nanci4 nan4it nank4 nar3c 4nare nar3i nar4l n5arm n4as nas4c\\nnas5ti n2at na3tal nato5miz n2au nau3se 3naut nav4e 4n1b4 ncar5 n4ces. n3cha\\nn5cheo n5chil n3chis nc1in nc4it ncour5a n1cr n1cu n4dai n5dan n1de nd5est.\\nndi4b n5d2if n1dit n3diz n5duc ndu4r nd2we 2ne. n3ear ne2b neb3u ne2c 5neck 2ned\\nne4gat neg5ativ 5nege ne4la nel5iz ne5mi ne4mo 1nen 4nene 3neo ne4po ne2q n1er\\nnera5b n4erar n2ere n4er5i ner4r 1nes 2nes. 4nesp 2nest 4nesw 3netic ne4v n5eve\\nne4w n3f n4gab n3gel nge4n4e n5gere n3geri ng5ha n3gib ng1in n5git n4gla ngov4\\nng5sh n1gu n4gum n2gy 4n1h4 nha4 nhab3 nhe4 3n4ia ni3an ni4ap ni3ba ni4bl ni4d\\nni5di ni4er ni2fi ni5ficat n5igr nik4 n1im ni3miz n1in 5nine. nin4g ni4o 5nis.\\nnis4ta n2it n4ith 3nitio n3itor ni3tr n1j 4nk2 n5kero n3ket nk3in n1kl 4n1l n5m\\nnme4 nmet4 4n1n2 nne4 nni3al nni4v nob4l no3ble n5ocl 4n3o2d 3noe 4nog noge4\\nnois5i no5l4i 5nologis 3nomic n5o5miz no4mo no3my no4n non4ag non5i n5oniz 4nop\\n5nop5o5li nor5ab no4rary 4nosc nos4e nos5t no5ta 1nou 3noun nov3el3 nowl3 n1p4\\nnpi4 npre4c n1q n1r nru4 2n1s2 ns5ab nsati4 ns4c n2se n4s3es nsid1 nsig4 n2sl\\nns3m n4soc ns4pe n5spi nsta5bl n1t nta4b nter3s nt2i n5tib nti4er nti2f n3tine\\nn4t3ing nti4p ntrol5li nt4s ntu3me nu1a nu4d nu5en nuf4fe n3uin 3nu3it n4um\\nnu1me n5umi 3nu4n n3uo nu3tr n1v2 n1w4 nym4 nyp4 4nz n3za 4oa oad3 o5a5les oard3\\noas4e oast5e oat5i ob3a3b o5bar obe4l o1bi o2bin ob5ing o3br ob3ul o1ce och4\\no3chet ocif3 o4cil o4clam o4cod oc3rac oc5ratiz ocre3 5ocrit octor5a oc3ula\\no5cure od5ded od3ic odi3o o2do4 odor3 od5uct. od5ucts o4el o5eng o3er oe4ta o3ev\\no2fi of5ite ofit4t o2g5a5r og5ativ o4gato o1ge o5gene o5geo o4ger o3gie 1o1gis\\nog3it o4gl o5g2ly 3ogniz o4gro ogu5i 1ogy 2ogyn o1h2 ohab5 oi2 oic3es oi3der\\noiff4 oig4 oi5let o3ing oint5er o5ism oi5son oist5en oi3ter o5j 2ok o3ken ok5ie\\no1la o4lan olass4 ol2d old1e ol3er o3lesc o3let ol4fi ol2i o3lia o3lice ol5id.\\no3li4f o5lil ol3ing o5lio o5lis. ol3ish o5lite o5litio o5liv olli4e ol5ogiz\\nolo4r ol5pl ol2t ol3ub ol3ume ol3un o5lus ol2v o2ly om5ah oma5l om5atiz om2be\\nom4bl o2me om3ena om5erse o4met om5etry o3mia om3ic. om3ica o5mid om1in o5mini\\n5ommend omo4ge o4mon om3pi ompro5 o2n on1a on4ac o3nan on1c 3oncil 2ond on5do\\no3nen on5est on4gu on1ic o3nio on1is o5niu on3key on4odi on3omy on3s onspi4\\nonspir5a onsu4 onten4 on3t4i ontif5 on5um onva5 oo2 ood5e ood5i oo4k oop3i o3ord\\noost5 o2pa ope5d op1er 3opera 4operag 2oph o5phan o5pher op3ing o3pit o5pon\\no4posi o1pr op1u opy5 o1q o1ra o5ra. o4r3ag or5aliz or5ange ore5a o5real or3ei\\nore5sh or5est. orew4 or4gu 4o5ria or3ica o5ril or1in o1rio or3ity o3riu or2mi\\norn2e o5rof or3oug or5pe 3orrh or4se ors5en orst4 or3thi or3thy or4ty o5rum o1ry\\nos3al os2c os4ce o3scop 4oscopi o5scr os4i4e os5itiv os3ito os3ity osi4u os4l\\no2so os4pa os4po os2ta o5stati os5til os5tit o4tan otele4g ot3er. ot5ers o4tes\\n4oth oth5esi oth3i4 ot3ic. ot5ica o3tice o3tif o3tis oto5s ou2 ou3bl ouch5i\\nou5et ou4l ounc5er oun2d ou5v ov4en over4ne over3s ov4ert o3vis oviti4 o5v4ol\\now3der ow3el ow5est ow1i own5i o4wo oy1a 1pa pa4ca pa4ce pac4t p4ad 5pagan\\np3agat p4ai pain4 p4al pan4a pan3el pan4ty pa3ny pa1p pa4pu para5bl par5age\\npar5di 3pare par5el p4a4ri par4is pa2te pa5ter 5pathic pa5thy pa4tric pav4 3pay\\n4p1b pd4 4pe. 3pe4a pear4l pe2c 2p2ed 3pede 3pedi pedia4 ped4ic p4ee pee4d pek4\\npe4la peli4e pe4nan p4enc pen4th pe5on p4era. pera5bl p4erag p4eri peri5st\\nper4mal perme5 p4ern per3o per3ti pe5ru per1v pe2t pe5ten pe5tiz 4pf 4pg 4ph.\\nphar5i phe3no ph4er ph4es. ph1ic 5phie ph5ing 5phisti 3phiz ph2l 3phob 3phone\\n5phoni pho4r 4phs ph3t 5phu 1phy pi3a pian4 pi4cie pi4cy p4id p5ida pi3de 5pidi\\n3piec pi3en pi4grap pi3lo pi2n p4in. pind4 p4ino 3pi1o pion4 p3ith pi5tha pi2tu\\n2p3k2 1p2l2 3plan plas5t pli3a pli5er 4plig pli4n ploi4 plu4m plum4b 4p1m 2p3n\\npo4c 5pod. po5em po3et5 5po4g poin2 5point poly5t po4ni po4p 1p4or po4ry 1pos\\npos1s p4ot po4ta 5poun 4p1p ppa5ra p2pe p4ped p5pel p3pen p3per p3pet ppo5site\\npr2 pray4e 5preci pre5co pre3em pref5ac pre4la pre3r p3rese 3press pre5ten pre3v\\n5pri4e prin4t3 pri4s pris3o p3roca prof5it pro3l pros3e pro1t 2p1s2 p2se ps4h\\np4sib 2p1t pt5a4b p2te p2th pti3m ptu4r p4tw pub3 pue4 puf4 pul3c pu4m pu2n\\npur4r 5pus pu2t 5pute put3er pu3tr put4ted put4tin p3w qu2 qua5v 2que. 3quer\\n3quet 2rab ra3bi rach4e r5acl raf5fi raf4t r2ai ra4lo ram3et r2ami rane5o ran4ge\\nr4ani ra5no rap3er 3raphy rar5c rare4 rar5ef 4raril r2as ration4 rau4t ra5vai\\nrav3el ra5zie r1b r4bab r4bag rbi2 rbi4f r2bin r5bine rb5ing. rb4o r1c r2ce\\nrcen4 r3cha rch4er r4ci4b rc4it rcum3 r4dal rd2i rdi4a rdi4er rdin4 rd3ing 2re.\\nre1al re3an re5arr 5reav re4aw r5ebrat rec5oll rec5ompe re4cre 2r2ed re1de\\nre3dis red5it re4fac re2fe re5fer. re3fi re4fy reg3is re5it re1li re5lu r4en4ta\\nren4te re1o re5pin re4posi re1pu r1er4 r4eri rero4 re5ru r4es. re4spi ress5ib\\nres2t re5stal re3str re4ter re4ti4z re3tri reu2 re5uti rev2 re4val rev3el\\nr5ev5er. re5vers re5vert re5vil rev5olu re4wh r1f rfu4 r4fy rg2 rg3er r3get\\nr3gic rgi4n rg3ing r5gis r5git r1gl rgo4n r3gu rh4 4rh. 4rhal ri3a ria4b ri4ag\\nr4ib rib3a ric5as r4ice 4rici 5ricid ri4cie r4ico rid5er ri3enc ri3ent ri1er\\nri5et rig5an 5rigi ril3iz 5riman rim5i 3rimo rim4pe r2ina 5rina. rin4d rin4e\\nrin4g ri1o 5riph riph5e ri2pl rip5lic r4iq r2is r4is. ris4c r3ish ris4p ri3ta3b\\nr5ited. rit5er. rit5ers rit3ic ri2tu rit5ur riv5el riv3et riv3i r3j r3ket rk4le\\nrk4lin r1l rle4 r2led r4lig r4lis rl5ish r3lo4 r1m rma5c r2me r3men rm5ers\\nrm3ing r4ming. r4mio r3mit r4my r4nar r3nel r4ner r5net r3ney r5nic r1nis4 r3nit\\nr3niv rno4 r4nou r3nu rob3l r2oc ro3cr ro4e ro1fe ro5fil rok2 ro5ker 5role.\\nrom5ete rom4i rom4p ron4al ron4e ro5n4is ron4ta 1room 5root ro3pel rop3ic ror3i\\nro5ro ros5per ros4s ro4the ro4ty ro4va rov5el rox5 r1p r4pea r5pent rp5er. r3pet\\nrp4h4 rp3ing r3po r1r4 rre4c rre4f r4reo rre4st rri4o rri4v rron4 rros4 rrys4\\n4rs2 r1sa rsa5ti rs4c r2se r3sec rse4cr rs5er. rs3es rse5v2 r1sh r5sha r1si\\nr4si4b rson3 r1sp r5sw rtach4 r4tag r3teb rten4d rte5o r1ti rt5ib rti4d r4tier\\nr3tig rtil3i rtil4l r4tily r4tist r4tiv r3tri rtroph4 rt4sh ru3a ru3e4l ru3en\\nru4gl ru3in rum3pl ru2n runk5 run4ty r5usc ruti5n rv4e rvel4i r3ven rv5er.\\nr5vest r3vey r3vic rvi4v r3vo r1w ry4c 5rynge ry3t sa2 2s1ab 5sack sac3ri s3act\\n5sai salar4 sal4m sa5lo sal4t 3sanc san4de s1ap sa5ta 5sa3tio sat3u sau4 sa5vor\\n5saw 4s5b scan4t5 sca4p scav5 s4ced 4scei s4ces sch2 s4cho 3s4cie 5scin4d scle5\\ns4cli scof4 4scopy scour5a s1cu 4s5d 4se. se4a seas4 sea5w se2c3o 3sect 4s4ed\\nse4d4e s5edl se2g seg3r 5sei se1le 5self 5selv 4seme se4mol sen5at 4senc sen4d\\ns5ened sen5g s5enin 4sentd 4sentl sep3a3 4s1er. s4erl ser4o 4servo s1e4s se5sh\\nses5t 5se5um 5sev sev3en sew4i 5sex 4s3f 2s3g s2h 2sh. sh1er 5shev sh1in sh3io\\n3ship shiv5 sho4 sh5old shon3 shor4 short5 4shw si1b s5icc 3side. 5sides 5sidi\\nsi5diz 4signa sil4e 4sily 2s1in s2ina 5sine. s3ing 1sio 5sion sion5a si2r sir5a\\n1sis 3sitio 5siu 1siv 5siz sk2 4ske s3ket sk5ine sk5ing s1l2 s3lat s2le slith5\\n2s1m s3ma small3 sman3 smel4 s5men 5smith smol5d4 s1n4 1so so4ce soft3 so4lab\\nsol3d2 so3lic 5solv 3som 3s4on. sona4 son4g s4op 5sophic s5ophiz s5ophy sor5c\\nsor5d 4sov so5vi 2spa 5spai spa4n spen4d 2s5peo 2sper s2phe 3spher spho5 spil4\\nsp5ing 4spio s4ply s4pon spor4 4spot squal4l s1r 2ss s1sa ssas3 s2s5c s3sel\\ns5seng s4ses. s5set s1si s4sie ssi4er ss5ily s4sl ss4li s4sn sspend4 ss2t ssur5a\\nss5w 2st. s2tag s2tal stam4i 5stand s4ta4p 5stat. s4ted stern5i s5tero ste2w\\nstew5a s3the st2i s4ti. s5tia s1tic 5stick s4tie s3tif st3ing 5stir s1tle 5stock\\nstom3a 5stone s4top 3store st4r s4trad 5stratu s4tray s4trid 4stry 4st3w s2ty\\n1su su1al su4b3 su2g3 su5is suit3 s4ul su2m sum3i su2n su2r 4sv sw2 4swo s4y\\n4syc 3syl syn5o sy5rin 1ta 3ta. 2tab ta5bles 5taboliz 4taci ta5do 4taf4 tai5lo\\nta2l ta5la tal5en tal3i 4talk tal4lis ta5log ta5mo tan4de tanta3 ta5per ta5pl\\ntar4a 4tarc 4tare ta3riz tas4e ta5sy 4tatic ta4tur taun4 tav4 2taw tax4is 2t1b\\n4tc t4ch tch5et 4t1d 4te. tead4i 4teat tece4 5tect 2t1ed te5di 1tee teg4 te5ger\\nte5gi 3tel. teli4 5tels te2ma2 tem3at 3tenan 3tenc 3tend 4tenes 1tent ten4tag\\n1teo te4p te5pe ter3c 5ter3d 1teri ter5ies ter3is teri5za 5ternit ter5v 4tes.\\n4tess t3ess. teth5e 3teu 3tex 4tey 2t1f 4t1g 2th. than4 th2e 4thea th3eas the5at\\nthe3is 3thet th5ic. th5ica 4thil 5think 4thl th5ode 5thodic 4thoo thor5it\\ntho5riz 2ths 1tia ti4ab ti4ato 2ti2b 4tick t4ico t4ic1u 5tidi 3tien tif2 ti5fy\\n2tig 5tigu till5in 1tim 4timp tim5ul 2t1in t2ina 3tine. 3tini 1tio ti5oc tion5ee\\n5tiq ti3sa 3tise tis4m ti5so tis4p 5tistica ti3tl ti4u 1tiv tiv4a 1tiz ti3za\\nti3zen 2tl t5la tlan4 3tle. 3tled 3tles. t5let. t5lo 4t1m tme4 2t1n2 1to to3b\\nto5crat 4todo 2tof to2gr to5ic to2ma tom4b to3my ton4ali to3nat 4tono 4tony\\nto2ra to3rie tor5iz tos2 5tour 4tout to3war 4t1p 1tra tra3b tra5ch traci4\\ntrac4it trac4te tras4 tra5ven trav5es5 tre5f tre4m trem5i 5tria tri5ces 5tricia\\n4trics 2trim tri4v tro5mi tron5i 4trony tro5phe tro3sp tro3v tru5i trus4 4t1s2\\nt4sc tsh4 t4sw 4t3t2 t4tes t5to ttu4 1tu tu1a tu3ar tu4bi tud2 4tue 4tuf4 5tu3i\\n3tum tu4nis 2t3up. 3ture 5turi tur3is tur5o tu5ry 3tus 4tv tw4 4t1wa twis4 4two\\n1ty 4tya 2tyl type3 ty5ph 4tz tz4e 4uab uac4 ua5na uan4i uar5ant uar2d uar3i\\nuar3t u1at uav4 ub4e u4bel u3ber u4bero u1b4i u4b5ing u3ble. u3ca uci4b uc4it\\nucle3 u3cr u3cu u4cy ud5d ud3er ud5est udev4 u1dic ud3ied ud3ies ud5is u5dit\\nu4don ud4si u4du u4ene uens4 uen4te uer4il 3ufa u3fl ugh3en ug5in 2ui2 uil5iz\\nui4n u1ing uir4m uita4 uiv3 uiv4er. u5j 4uk u1la ula5b u5lati ulch4 5ulche\\nul3der ul4e u1len ul4gi ul2i u5lia ul3ing ul5ish ul4lar ul4li4b ul4lis 4ul3m\\nu1l4o 4uls uls5es ul1ti ultra3 4ultu u3lu ul5ul ul5v um5ab um4bi um4bly u1mi\\nu4m3ing umor5o um2p unat4 u2ne un4er u1ni un4im u2nin un5ish uni3v un3s4 un4sw\\nunt3ab un4ter. un4tes unu4 un5y un5z u4ors u5os u1ou u1pe uper5s u5pia up3ing\\nu3pl up3p upport5 upt5ib uptu4 u1ra 4ura. u4rag u4ras ur4be urc4 ur1d ure5at\\nur4fer ur4fr u3rif uri4fic ur1in u3rio u1rit ur3iz ur2l url5ing. ur4no uros4\\nur4pe ur4pi urs5er ur5tes ur3the urti4 ur4tie u3ru 2us u5sad u5san us4ap usc2\\nus3ci use5a u5sia u3sic us4lin us1p us5sl us5tere us1tr u2su usur4 uta4b u3tat\\n4ute. 4utel 4uten uten4i 4u1t2i uti5liz u3tine ut3ing ution5a u4tis 5u5tiz u4t1l\\nut5of uto5g uto5matic u5ton u4tou uts4 u3u uu4m u1v2 uxu3 uz4e 1va 5va. 2v1a4b\\nvac5il vac3u vag4 va4ge va5lie val5o val1u va5mo va5niz va5pi var5ied 3vat 4ve.\\n4ved veg3 v3el. vel3li ve4lo v4ely ven3om v5enue v4erd 5vere. v4erel v3eren\\nver5enc v4eres ver3ie vermi4n 3verse ver3th v4e2s 4ves. ves4te ve4te vet3er\\nve4ty vi5ali 5vian 5vide. 5vided 4v3iden 5vides 5vidi v3if vi5gn vik4 2vil\\n5vilit v3i3liz v1in 4vi4na v2inc vin5d 4ving vio3l v3io4r vi1ou vi4p vi5ro\\nvis3it vi3so vi3su 4viti vit3r 4vity 3viv 5vo. voi4 3vok vo4la v5ole 5volt 3volv\\nvom5i vor5ab vori4 vo4ry vo4ta 4votee 4vv4 v4y w5abl 2wac wa5ger wag5o wait5\\nw5al. wam4 war4t was4t wa1te wa5ver w1b wea5rie weath3 wed4n weet3 wee5v wel4l\\nw1er west3 w3ev whi4 wi2 wil2 will5in win4de win4g wir4 3wise with3 wiz5 w4k\\nwl4es wl3in w4no 1wo2 wom1 wo5ven w5p wra4 wri4 writa4 w3sh ws4l ws4pe w5s4t 4wt\\nwy4 x1a xac5e x4ago xam3 x4ap xas5 x3c2 x1e xe4cuto x2ed xer4i xe5ro x1h xhi2\\nxhil5 xhu4 x3i xi5a xi5c xi5di x4ime xi5miz x3o x4ob x3p xpan4d xpecto5 xpe3d\\nx1t2 x3ti x1u xu3a xx4 y5ac 3yar4 y5at y1b y1c y2ce yc5er y3ch ych4e ycom4 ycot4\\ny1d y5ee y1er y4erf yes4 ye4t y5gi 4y3h y1i y3la ylla5bl y3lo y5lu ymbol5 yme4\\nympa3 yn3chr yn5d yn5g yn5ic 5ynx y1o4 yo5d y4o5g yom4 yo5net y4ons y4os y4ped\\nyper5 yp3i y3po y4poc yp2ta y5pu yra5m yr5ia y3ro yr4r ys4c y3s2e ys3ica ys3io\\n3ysis y4so yss4 ys1t ys3ta ysur4 y3thin yt3ic y1w za1 z5a2b zar2 4zb 2ze ze4n\\nze4p z1er ze3ro zet4 2z1i z4il z4is 5zl 4zm 1zo zo4m zo5ol zte4 4z1z2 z4zy\\n.con5gr .de5riva .dri5v4 .eth1y6l1 .eu4ler .ev2 .ever5si5b .ga4s1om1 .ge4ome\\n.ge5ot1 .he3mo1 .he3p6a .he3roe .in5u2t .kil2n3i .ko6r1te1 .le6ices .me4ga1l\\n.met4ala .mim5i2c1 .mi1s4ers .ne6o3f .noe1th .non1e2m .poly1s .post1am .pre1am\\n.rav5en1o .semi5 .sem4ic .semid6 .semip4 .semir4 .sem6is4 .semiv4 .sph6in1\\n.spin1o .ta5pes1tr .te3legr .to6pog .to2q .un3at5t .un5err5 .vi2c3ar .we2b1l\\n.re1e4c a5bolic a2cabl af6fish am1en3ta5b anal6ys ano5a2c ans5gr ans3v anti1d\\nan3ti1n2 anti1re a4pe5able ar3che5t ar2range as5ymptot ath3er1o1s at6tes.\\naugh4tl au5li5f av3iou back2er. ba6r1onie ba1thy bbi4t be2vie bi5d2if bil2lab\\nbio5m bi1orb bio1rh b1i3tive blan2d1 blin2d1 blon2d2 bor1no5 bo2t1u1l brus4q\\nbus6i2er bus6i2es buss4ing but2ed. but4ted cad5e1m cat1a1s2 4chs. chs3hu chie5vo\\ncig3a3r cin2q cle4ar co6ph1o3n cous2ti cri3tie croc1o1d cro5e2co c2tro3me6c\\n1cu2r1ance 2d3alone data1b dd5a5b d2d5ib de4als. de5clar1 de2c5lina de3fin3iti\\nde2mos des3ic de2tic dic1aid dif5fra 3di1methy di2ren di2rer 2d1lead 2d1li2e\\n3do5word dren1a5l drif2t1a d1ri3pleg5 drom3e5d d3tab du2al. du1op1o1l ea4n3ies\\ne3chas edg1l ed1uling eli2t1is e1loa en1dix eo3grap 1e6p3i3neph1 e2r3i4an.\\ne3spac6i eth1y6l1ene 5eu2clid1 feb1rua fermi1o 3fich fit5ted. fla1g6el flow2er.\\n3fluor gen2cy. ge3o1d ght1we g1lead get2ic. 4g1lish 5glo5bin 1g2nac gnet1ism\\ngno5mo g2n1or. g2noresp 2g1o4n3i1za graph5er. griev1 g1utan hair1s ha2p3ar5r\\nhatch1 hex2a3 hite3sid h3i5pel1a4 hnau3z ho6r1ic. h2t1eou hypo1tha id4ios\\nifac1et ign4it ignit1er i4jk im3ped3a infra1s2 i5nitely. irre6v3oc i1tesima\\nith5i2l itin5er5ar janu3a japan1e2s je1re1m 1ke6ling 1ki5netic 1kovian k3sha\\nla4c3i5e lai6n3ess lar5ce1n l3chai l3chil6d1 lead6er. lea4s1a 1lec3ta6b\\nle3g6en2dre 1le1noid lith1o5g ll1fl l2l3ish l5mo3nell lo1bot1o1 lo2ges. load4ed.\\nload6er. l3tea lth5i2ly lue1p 1lunk3er 1lum5bia. 3lyg1a1mi ly5styr ma1la1p m2an.\\nman3u1sc mar1gin1 medi2c med3i3cin medio6c1 me3gran3 m2en. 3mi3da5b 3milita\\nmil2l1ag mil5li5li mi6n3is. mi1n2ut1er mi1n2ut1est m3ma1b 5maph1ro1 5moc1ra1t\\nmo5e2las mol1e5c mon4ey1l mono3ch mo4no1en moro6n5is mono1s6 moth4et2 m1ou3sin\\nm5shack2 mu2dro mul2ti5u n3ar4chs. n3ch2es1t ne3back 2ne1ski n1dieck nd3thr\\nnfi6n3ites 4n5i4an. nge5nes ng1ho ng1spr nk3rup n5less 5noc3er1os nom1a6l\\nnom5e1no n1o1mist non1eq non1i4so 5nop1oly. no1vemb ns5ceiv ns4moo ntre1p\\nobli2g1 o3chas odel3li odit1ic oerst2 oke1st o3les3ter oli3gop1o1 o1lo3n4om\\no3mecha6 onom1ic o3norma o3no2t1o3n o3nou op1ism. or4tho3ni4t orth1ri or5tively\\no4s3pher o5test1er o5tes3tor oth3e1o1s ou3ba3do o6v3i4an. oxi6d1ic pal6mat\\nparag6ra4 par4a1le param4 para3me pee2v1 phi2l3ant phi5lat1e3l pi2c1a3d pli2c1ab\\npli5nar poin3ca 1pole. poly1e po3lyph1ono 1prema3c pre1neu pres2pli pro2cess\\nproc3i3ty. pro2g1e 3pseu2d pseu3d6o3d2 pseu3d6o3f2 pto3mat4 p5trol3 pu5bes5c\\nquain2t1e qu6a3si3 quasir6 quasis6 quin5tes5s qui3v4ar r1abolic 3rab1o1loi\\nra3chu r3a3dig radi1o6g r2amen 3ra4m5e1triz ra3mou ra5n2has ra1or r3bin1ge\\nre2c3i1pr rec5t6ang re4t1ribu r3ial. riv1o1l 6rk. rk1ho r1krau 6rks. r5le5qu\\nro1bot1 ro5e2las ro5epide1 ro3mesh ro1tron r3pau5li rse1rad1i r1thou r1treu\\nr1veil rz1sc sales3c sales5w 5sa3par5il sca6p1er sca2t1ol s4chitz schro1ding1\\n1sci2utt scrap4er. scy4th1 sem1a1ph se3mes1t se1mi6t5ic sep3temb shoe1st sid2ed.\\nside5st side5sw si5resid sky1sc 3slova1kia 3s2og1a1my so2lute 3s2pace 1s2pacin\\nspe3cio spher1o spi2c1il spokes5w sports3c sports3w s3qui3to s2s1a3chu1 ss3hat\\ns2s3i4an. s5sign5a3b 1s2tamp s2t1ant5shi star3tli sta1ti st5b 1stor1ab strat1a1g\\nstrib5ut st5scr stu1pi4d1 styl1is su2per1e6 1sync 1syth3i2 swimm6 5tab1o1lism\\nta3gon. talk1a5 t1a1min t6ap6ath 5tar2rh tch1c tch3i1er t1cr teach4er. tele2g\\ntele1r6o 3ter1gei ter2ic. t3ess2es tha4l1am tho3don th1o5gen1i tho1k2er thy4l1an\\nthy3sc 2t3i4an. ti2n3o1m t1li2er tolo2gy tot3ic trai3tor1 tra1vers travers3a3b\\ntreach1e tr4ial. 3tro1le1um trof4ic. tro3fit tro1p2is 3trop1o5les 3trop1o5lis\\nt1ro1pol3it tsch3ie ttrib1ut1 turn3ar t1wh ty2p5al ua3drati uad1ratu u5do3ny\\nuea1m u2r1al. uri4al. us2er. v1ativ v1oir5du1 va6guer vaude3v 1verely. v1er1eig\\nves1tite vi1vip3a3r voice1p waste3w6a2 wave1g4 w3c week1n wide5sp wo4k1en\\nwrap3aro writ6er. x1q xquis3 y5che3d ym5e5try y1stro yes5ter1y z3ian. z3o1phr\\nz2z3w\\n';\n\nvar TREE = {};\n\n// Compiling the patterns\nPATTERNS = PATTERNS.trim().replace(/\\n/g, ' ').split(' ');\n\n// Building the tree\nfor (var i = 0, l = PATTERNS.length; i < l; i++) {\n  var pattern = PATTERNS[i],\n      characters = pattern.replace(/\\d/g, ''),\n      points = pattern.split(/[.a-z]/).map(function (d) {\n    return +d || 0;\n  });\n\n  var branch = TREE;\n\n  for (var c = 0, m = characters.length; c < m; c++) {\n    var character = characters[c];\n\n    if (!(character in branch)) branch[character] = {};\n    branch = branch[character];\n  }\n  branch.points = points;\n}\n\n// Cleaning up patterns from memory\nPATTERNS = null;\n\n/**\n * Function returning the hyphenation of the given word.\n *\n * @param  {string} word - The word to hyphenate.\n * @return {array}       - The word's parts.\n */\nfunction liang(word) {\n\n  // If the word is too short, it doesn't need to be hyphenated\n  if (word.length <= 4) return [word];\n\n  // Checking whether the word is an exception\n  var exception = EXCEPTIONS[word.toLowerCase()];\n\n  if (exception) return exception;\n\n  // Retrieving the stored points\n  var code = '.' + word.toLowerCase() + '.',\n      points = (0, _vectors.vec)(code.length + 1, 0);\n\n  for (var _i = 0, _l = code.length; _i < _l; _i++) {\n    var _branch = TREE;\n\n    for (var j = _i; j < _l; j++) {\n      var _character = code[j];\n\n      if (_character in _branch) {\n        _branch = _branch[_character];\n\n        if (_branch.points) {\n          for (var k = 0, n = _branch.points.length; k < n; k++) {\n            points[_i + k] = Math.max(points[_i + k], _branch.points[k]);\n          }\n        }\n      } else {\n        break;\n      }\n    }\n  }\n\n  // No hyphens in the first two characters or the last two\n  points[1] = 0;\n  points[2] = 0;\n  points[points.length - 2] = 0;\n  points[points.length - 3] = 0;\n\n  // Building the tokens\n  var tokens = [''];\n\n  for (var _i2 = 0, _l2 = word.length; _i2 < _l2; _i2++) {\n    tokens[tokens.length - 1] += word[_i2];\n    if (points[_i2 + 2] % 2) tokens.push('');\n  }\n\n  return tokens;\n}\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/sentences/punkt.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.PunktSentenceTokenizer = exports.PunktTrainer = exports.PunktBaseClass = exports.PunktToken = exports.PunktLanguageVariables = undefined;\n\nvar _helpers = require('../../helpers');\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } } /* eslint no-console: 0 */\n/**\n * Talisman tokenizers/sentences/punkt\n * ====================================\n *\n * The Punkt unsupervised sentence tokenizer. Note that this is a port of the\n * nltk version of the trainer written in python. This means I did not try\n * too much to change the code architecture and sticked quite directly to\n * the original implementation's classes etc.\n *\n * TODO: the architecture can be changed a bit to fit JS more and allow for\n * easier customization.\n *\n * [Reference]:\n * http://www.nltk.org/_modules/nltk/tokenize/punkt.html\n *\n * [Article]:\n * Kiss, Tibor and Strunk, Jan (2006): Unsupervised Multilingual Sentence\n * Boundary Detection.  Computational Linguistics 32: 485-525.\n */\n\n\n/**\n * Hash separator.\n *\n * Note: this is necessary because of JavaScript's lack of tuples and the\n * derived possibility to use tuples as object keys. (ES6 Map won't resolve\n * the issue either since the key comparison is done through reference\n * comparison & not by hashing).\n */\nvar SEP = '‡';\n\n/**\n * Orthographic context constants.\n *\n * BEG = beginning\n * MID = middle\n * UNK = unknown\n * UC = uppercase\n * LC = lowercase\n * NC = no case\n */\nvar ORTHO_BEG_UC = 1 << 1,\n    ORTHO_MID_UC = 1 << 2,\n    ORTHO_UNK_UC = 1 << 3,\n    ORTHO_BEG_LC = 1 << 4,\n    ORTHO_MID_LC = 1 << 5,\n    ORTHO_UNK_LC = 1 << 6;\n\nvar ORTHO_UC = ORTHO_BEG_UC + ORTHO_MID_UC + ORTHO_UNK_UC,\n    ORTHO_LC = ORTHO_BEG_LC + ORTHO_MID_LC + ORTHO_UNK_LC;\n\nvar ORTHO_MAP = {\n  'initial§upper': ORTHO_BEG_UC,\n  'internal§upper': ORTHO_MID_UC,\n  'unknown§upper': ORTHO_UNK_UC,\n  'initial§lower': ORTHO_BEG_LC,\n  'internal§lower': ORTHO_MID_LC,\n  'unknown§lower': ORTHO_UNK_LC\n};\n\n/**\n * Class representing a basic frequency distribution.\n *\n * @constructor\n */\n\nvar FrequencyDistribution = function () {\n  function FrequencyDistribution() {\n    _classCallCheck(this, FrequencyDistribution);\n\n    this.counts = {};\n    this.N = 0;\n  }\n\n  /**\n   * Method used to add a single value to the distribution.\n   *\n   * @param  {string} value          - The value to add.\n   * @return {FrequencyDistribution} - Itself for chaining purposes.\n   */\n\n\n  FrequencyDistribution.prototype.add = function add(value) {\n    this.counts[value] = this.counts[value] || 0;\n    this.counts[value]++;\n    this.N++;\n  };\n\n  /**\n   * Method used to get the frequency for a single value.\n   *\n   * @param  {string} value - The targeted value.\n   * @return {number}       - The frequency for the given value.\n   */\n\n\n  FrequencyDistribution.prototype.get = function get(value) {\n    return this.counts[value] || 0;\n  };\n\n  /**\n   * Method used to get the unique values stored by the distribution.\n   *\n   * @return {array} - An array of the unique values.\n   */\n\n\n  FrequencyDistribution.prototype.values = function values() {\n    return Object.keys(this.counts);\n  };\n\n  return FrequencyDistribution;\n}();\n\n/**\n * Class representing language dependent variables.\n *\n * @constructor\n */\n\n\nvar PunktLanguageVariables = exports.PunktLanguageVariables = function () {\n  function PunktLanguageVariables() {\n    _classCallCheck(this, PunktLanguageVariables);\n\n    // Characters which are candidates for sentence boundaries\n    this.sentenceEndCharacters = new Set('.?!');\n\n    // Internal punctuation\n    this.internalPunctuation = new Set(',:;');\n\n    // Boundary realignement\n    this.reBoundaryRealignment = /[\"')\\]}]+?(?:\\s+|(?=--)|$)/;\n\n    // Excluding some characters from starting word tokens\n    this.reWordStart = /[^\\(\"\\`{\\[:;&\\#\\*@\\)}\\]\\-,]/;\n\n    // Characters that cannot appear within a word\n    this.reNonWordCharacters = /(?:[?!)\";}\\]\\*:@\\'\\({\\[])/;\n\n    // Hyphen & ellipsis are multi-character punctuation\n    this.reMultiCharacterPunctuation = /(?:\\-{2,}|\\.{2,}|(?:\\.\\s){2,}\\.)/;\n\n    var nonWord = this.reNonWordCharacters.source,\n        multiChar = this.reMultiCharacterPunctuation.source,\n        wordStart = this.reWordStart.source,\n        sentEndChars = [].concat(_toConsumableArray(this.sentenceEndCharacters)).join('');\n\n    var wordTokenizerPattern = ['(', multiChar, '|', '(?=' + wordStart + ')\\\\S+?', '(?=', '\\\\s|', '$|', nonWord + '|' + multiChar + '|', ',(?=$|\\\\s|' + nonWord + '|' + multiChar + ')', ')', '|', '\\\\S', ')'].join('');\n\n    this.reWordTokenizer = new RegExp(wordTokenizerPattern, 'g');\n\n    // After token is $1 and next token is $2\n    var periodContextPattern = ['\\\\S*', '[' + sentEndChars + ']', '(?=(', nonWord, '|', '\\\\s+(\\\\S+)', '))'].join('');\n\n    this.rePeriodContext = new RegExp(periodContextPattern, 'g');\n  }\n\n  /**\n   * Method used to tokenize the words in the given string.\n   *\n   * @param  {string} string - String to tokenize.\n   * @return {array}         - An array of matches.\n   */\n\n\n  PunktLanguageVariables.prototype.tokenizeWords = function tokenizeWords(string) {\n    return string.match(this.reWordTokenizer);\n  };\n\n  return PunktLanguageVariables;\n}();\n\n/**\n * Class storing the data used to perform sentence boundary detection with the\n * Punkt algorithm.\n *\n * @constructor\n */\n\n\nvar PunktParameters = function () {\n  function PunktParameters() {\n    _classCallCheck(this, PunktParameters);\n\n    // A set of word types for known abbreviations.\n    this.abbreviationTypes = new Set();\n\n    // A set of word type tuples for known common collocations where the first\n    // word ends in a period ('S. Bach', for instance is a common collocation\n    // in a text discussing 'Johann S. Bach').\n    this.collocations = new Set();\n\n    // A set of word types for words that often appear at the beginning of\n    // sentences.\n    this.sentenceStarters = new Set();\n\n    // A dictionary mapping word types to the the set of orthographic contexts\n    // that word type appears in.\n    this.orthographicContext = {};\n  }\n\n  /**\n   * Method used to add a context to the given word type.\n   *\n   * @param  {string}         type - The word type.\n   * @param  {number}         flag - The context's flag.\n   * @return {PunktParameter}      - Returns itself for chaining purposes.\n   */\n\n\n  PunktParameters.prototype.addOrthographicContext = function addOrthographicContext(type, flag) {\n    this.orthographicContext[type] = this.orthographicContext[type] || 0;\n    this.orthographicContext[type] |= flag;\n    return this;\n  };\n\n  return PunktParameters;\n}();\n\n/**\n * Regular expressions used by the tokens.\n */\n\n\nvar RE_ELLIPSIS = /^\\.\\.+$/,\n    RE_NUMERIC = /^-?[\\.,]?\\d[\\d,\\.-]*\\.?$/,\n    RE_INITIAL = /^[^\\W\\d]\\.$/,\n    RE_ALPHA = /^[^\\W\\d]+$/,\n    RE_NON_PUNCT = /[^\\W\\d]/;\n\n/**\n * Class representing a token of text with annotations produced during\n * sentence boundary detection.\n *\n * @constructor\n * @param {string} string - The token's string.\n * @param {params} object - Custom flags.\n */\n\nvar PunktToken = exports.PunktToken = function () {\n  function PunktToken(string) {\n    var params = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n    _classCallCheck(this, PunktToken);\n\n    // Properties\n    this.string = string;\n    this.periodFinal = string[string.length - 1] === '.';\n    this.type = string.toLowerCase().replace(RE_NUMERIC, '##number##');\n\n    // TODO: this is fishy, since it collides with ellipsis. Maybe refine\n    this.isEllipsis = RE_ELLIPSIS.test(string);\n    this.isNumber = this.type === '##number##';\n    this.isInitial = RE_INITIAL.test(string);\n    this.isAlpha = RE_ALPHA.test(string);\n    this.isNonPunctuation = RE_NON_PUNCT.test(string);\n    this.isInitialAlpha = /^[^\\W\\d]/.test(string);\n\n    for (var k in params) {\n      this[k] = params[k];\n    }\n  }\n\n  /**\n   * Method used to retrieve the token's type with its final period removed if\n   * it has one.\n   *\n   * @return {string}\n   */\n\n\n  PunktToken.prototype.typeNoPeriod = function typeNoPeriod() {\n    if (this.type.length > 1 && this.type.slice(-1) === '.') return this.type.slice(0, -1);\n    return this.type;\n  };\n\n  /**\n   * Method used to retrieve the token's type with its final period removed if\n   * it is marked as a sentence break.\n   *\n   * @return {string}\n   */\n\n\n  PunktToken.prototype.typeNoSentencePeriod = function typeNoSentencePeriod() {\n    if (this.sentenceBreak) return this.typeNoPeriod();\n    return this.type;\n  };\n\n  /**\n   * Method used to return whether the token's first character is uppercase.\n   *\n   * @return {boolean}\n   */\n\n\n  PunktToken.prototype.firstUpper = function firstUpper() {\n    return this.isInitialAlpha && this.string[0] === this.string[0].toUpperCase();\n  };\n\n  /**\n   * Method used to return whether the token's first character is lowercase.\n   *\n   * @return {boolean}\n   */\n\n\n  PunktToken.prototype.firstLower = function firstLower() {\n    return this.isInitialAlpha && this.string[0] === this.string[0].toLowerCase();\n  };\n\n  /**\n   * Method used to return the token's first character's case.\n   *\n   * @return {string} - \"lower\" or \"upper\".\n   */\n\n\n  PunktToken.prototype.firstCase = function firstCase() {\n    if (this.firstLower()) return 'lower';\n    if (this.firstUpper()) return 'upper';\n    return 'none';\n  };\n\n  /**\n   * Method used for string coercion.\n   *\n   * @return {string} - The token's string representation.\n   */\n\n\n  PunktToken.prototype.toString = function toString() {\n    return this.string;\n  };\n\n  return PunktToken;\n}();\n\n/**\n * Customization variables.\n */\n\n\nvar ABBREV = 0.3,\n    IGNORE_ABBREV_PENALTY = false,\n    ABBREV_BACKOFF = 5,\n    COLLOCATION = 7.88,\n    SENT_STARTER = 30,\n    INCLUDE_ALL_COLLOCS = false,\n    INCLUDE_ABBREV_COLLOCS = false,\n    MIN_COLLOC_FREQ = 1,\n    PUNCTUATION = new Set(';:,.!?');\n\n/**\n * Punkt abstract class used by both the Trainer & the Tokenizer classes.\n *\n * @constructor\n * @param {object}                 [options]        - Instantiation options.\n * @param {PunktLanguageVariables} [options.vars]   - Language variables.\n * @param {PunktParameters}        [options.params] - Parameters\n */\n\nvar PunktBaseClass = exports.PunktBaseClass = function () {\n  function PunktBaseClass(options) {\n    _classCallCheck(this, PunktBaseClass);\n\n    var _ref = options || {},\n        _ref$vars = _ref.vars,\n        vars = _ref$vars === undefined ? new PunktLanguageVariables() : _ref$vars,\n        _ref$params = _ref.params,\n        params = _ref$params === undefined ? new PunktParameters() : _ref$params;\n\n    this.params = params;\n    this.vars = vars;\n  }\n\n  /**\n   * Method used to tokenize the given text into tokens, using the Punkt word\n   * segmentation regular expression, and generate the resulting list of\n   * tokens.\n   *\n   * @param  {string} text - The raw text to tokenize.\n   * @return {array}       - The resulting tokens.\n   */\n\n\n  PunktBaseClass.prototype.tokenizeWords = function tokenizeWords(text) {\n    var paragraphStart = false;\n\n    var lines = text.split(/\\r?\\n/g),\n        tokens = [];\n\n    for (var i = 0, l = lines.length; i < l; i++) {\n      var line = lines[i].trim();\n\n      if (line) {\n        var words = this.vars.tokenizeWords(line);\n\n        tokens.push(new PunktToken(words[0], { lineStart: true, paragraphStart: paragraphStart }));\n\n        paragraphStart = false;\n\n        for (var j = 1, m = words.length; j < m; j++) {\n          tokens.push(new PunktToken(words[j]));\n        }\n      } else {\n        paragraphStart = true;\n      }\n    }\n\n    return tokens;\n  };\n\n  /**\n   * Method used to perform the first pass of token annotation, which makes\n   * decisions based purely based of the word type of each word:\n   *   - \"?\", \"!\", and \".\" are marked as sentence breaks.\n   *   - sequences of two or more periods are marked as ellipsis.\n   *   - any word ending in \".\" that is a known abbreviation is marked as such.\n   *   - any othe word ending in \".\" is marked as a sentence break.\n   *\n   * @param  {array} tokens   - The tokens to annotate.\n   * @return {PunktBaseClass} - Returns itself for chaining purposes.\n   */\n\n\n  PunktBaseClass.prototype._annotateFirstPass = function _annotateFirstPass(tokens) {\n    for (var i = 0, l = tokens.length; i < l; i++) {\n      var token = tokens[i],\n          string = token.string;\n\n      if (this.vars.sentenceEndCharacters.has(string)) {\n        token.sentenceBreak = true;\n      } else if (token.isEllipsis) {\n        token.ellipsis = true;\n      } else if (token.periodFinal && !string.endsWith('..')) {\n        var t = string.slice(0, -1).toLowerCase();\n\n        if (this.params.abbreviationTypes.has(t) || this.params.abbreviationTypes.has(t.split('-').slice(-1)[0])) {\n          token.abbreviation = true;\n        } else {\n          token.sentenceBreak = true;\n        }\n      }\n    }\n\n    return this;\n  };\n\n  return PunktBaseClass;\n}();\n\n/**\n * Miscellaneous helpers.\n */\n\n/**\n * Computing the Dunning log-likelihood ratio scores for abbreviation\n * candidates.\n *\n * @param {number} a  - Count of <a>.\n * @param {number} b  - Count of <b>.\n * @param {number} ab - Count of <ab>.\n * @param {number} N  - Number of elements in the distribution.\n * @return {number}   - The log-likelihood.\n */\n\n\nfunction dunningLogLikelihood(a, b, ab, N) {\n  var p1 = b / N,\n      p2 = 0.99;\n\n  var nullHypothesis = ab * Math.log(p1) + (a - ab) * Math.log(1 - p1),\n      alternativeHyphothesis = ab * Math.log(p2) + (a - ab) * Math.log(1 - p2);\n\n  var likelihood = nullHypothesis - alternativeHyphothesis;\n\n  return -2 * likelihood;\n}\n\n/**\n * A function that wil just compute log-likelihood estimate, in the original\n * paper, it's described in algorithm 6 and 7.\n *\n * Note: this SHOULD be the original Dunning log-likelihood values.\n *\n * @param {number} a  - Count of <a>.\n * @param {number} b  - Count of <b>.\n * @param {number} ab - Count of <ab>.\n * @param {number} N  - Number of elements in the distribution.\n * @return {number}   - The log-likelihood.\n */\nfunction colLogLikelihood(a, b, ab, N) {\n  var p = b / N,\n      p1 = ab / a,\n      p2 = (b - ab) / (N - a);\n\n  var summand1 = ab * Math.log(p) + (a - ab) * Math.log(1 - p),\n      summand2 = (b - ab) * Math.log(p) + (N - a - b + ab) * Math.log(1 - p);\n\n  var summand3 = 0;\n  if (a !== ab) summand3 = ab * Math.log(p1) + (a - ab) * Math.log(1 - p1);\n\n  var summand4 = 0;\n  if (b !== ab) summand4 = (b - ab) * Math.log(p2) + (N - a - b + ab) * Math.log(1 - p2);\n\n  var likelihood = summand1 + summand2 - summand3 - summand4;\n\n  return -2 * likelihood;\n}\n\n/**\n * Class representing the Punkt trainer.\n *\n * @constructor\n * @param {object}  [options]         - Instantiation options.\n * @param {boolean} [options.verbose] - Should the trainer log information?\n */\n\nvar PunktTrainer = exports.PunktTrainer = function (_PunktBaseClass) {\n  _inherits(PunktTrainer, _PunktBaseClass);\n\n  function PunktTrainer(options) {\n    _classCallCheck(this, PunktTrainer);\n\n    var _ref2 = options || {},\n        _ref2$verbose = _ref2.verbose,\n        verbose = _ref2$verbose === undefined ? false : _ref2$verbose;\n\n    // Should the trainer log information?\n    var _this = _possibleConstructorReturn(this, _PunktBaseClass.call(this, options));\n\n    _this.verbose = verbose;\n\n    // A frequency distribution giving the frequenct of each case-normalized\n    // token type in the training data.\n    _this.typeFdist = new FrequencyDistribution();\n\n    // Number of words ending in period in the training data.\n    _this.periodTokenCount = 0;\n\n    // A frequency distribution giving the frequency of all bigrams in the\n    // training data where the first word ends in a period.\n    _this.collocationFdist = new FrequencyDistribution();\n\n    // A frequency distribution givin the frequency of all bigrams in the\n    // training data where the first word ends in a period.\n    _this.sentenceStarterFdist = new FrequencyDistribution();\n\n    // The total number of sentence breaks identified in training, used for\n    // calculating the frequent sentence starter heuristic.\n    _this.sentenceBreakCount = 0;\n\n    // A flag controlling whether the training has been finalized by finding\n    // collocations and sentence starters, or whether training still needs to be\n    // finalized\n    _this.finalized = true;\n    return _this;\n  }\n\n  /**---------------------------------------------------------------------------\n   * Overhead reduction.\n   **---------------------------------------------------------------------------\n   */\n\n  // TODO: figure out this part\n\n  /**---------------------------------------------------------------------------\n   * Orthographic data.\n   **---------------------------------------------------------------------------\n   */\n\n  /**\n   * Method used to collect information about whether each token type occurs\n   * with different case patterns (i) overall, (ii) at sentence-initial\n   * positions, and (iii) at sentence-internal positions.\n   *\n   * @param  {array}   tokens - Training tokens.\n   * @return {PunktTrainer}        - Returns itself for chaining purposes.\n   */\n\n\n  PunktTrainer.prototype._getOrthographyData = function _getOrthographyData(tokens) {\n    var context = 'internal';\n\n    for (var i = 0, l = tokens.length; i < l; i++) {\n      var token = tokens[i];\n\n      // If we encounter a paragraph break, then it's a good sign that it's\n      // a sentence break. But err on the side of caution (by not positing\n      // a sentence break) if we just saw an abbreviation.\n      if (token.paragraphStart && context !== 'unknown') context = 'initial';\n\n      // If we are at the beginning of a line, then we can't decide between\n      // \"internal\" and \"initial\"\n      if (token.lineStart && context === 'internal') context = 'unknown';\n\n      // Find the case-normalized type of the token. If it's a sentence-final\n      // token, strip off the period.\n      var type = token.typeNoSentencePeriod();\n\n      // Update the orthographic context table.\n      var flag = ORTHO_MAP[context + '\\xA7' + token.firstCase()] || 0;\n\n      if (flag) this.params.addOrthographicContext(type, flag);\n\n      // Decide whether the newt word is at a sentence boundary\n      if (token.sentenceBreak) {\n        if (!(token.isNumber || token.isInitial)) context = 'initial';else context = 'unknown';\n      } else if (token.ellipsis || token.abbreviation) {\n        context = 'unknown';\n      } else {\n        context = 'internal';\n      }\n    }\n  };\n\n  /**---------------------------------------------------------------------------\n   * Abbreviation.\n   **---------------------------------------------------------------------------\n   */\n\n  /**\n   * Method used to reclassify the given token's type if:\n   *   - it is period-final and not a know abbreviation\n   *   - it is not period-final and is otherwise a known abbreviation by\n   *     checking whether its previous classification still holds according to\n   *     the heuristics of section 3.\n   *\n   * @param  {string} type - A token type.\n   * @return {array|null}  - Returns a triple containing the following:\n   *         {string}        [0]: the abbreviation.\n   *         {number}        [1]: log-likelihood with penalties applied.\n   *         {boolean}       [2]: whether the present type is a candidate for\n   *                              inclusion or exclusion as an abbreviation.\n   */\n\n\n  PunktTrainer.prototype._reclassifyAbbreviationType = function _reclassifyAbbreviationType(type) {\n    var isAdd = void 0;\n\n    // Check some basic conditions, to rule out words that are clearly not\n    // abbreviation types.\n    if (type === '##number##\"' || !RE_NON_PUNCT.test(type)) return null;\n\n    if (type.endsWith('.')) {\n      if (this.params.abbreviationTypes.has(type)) return null;\n      type = type.slice(0, -1);\n      isAdd = true;\n    } else {\n      if (!this.params.abbreviationTypes.has(type)) return null;\n      isAdd = false;\n    }\n\n    // Count how many periods & nonperiods are in the candidate type.\n    var periodsCount = (type.match(/\\./g) || []).length + 1,\n        nonPeriodsCount = type.length - periodsCount + 1;\n\n    // Let <a> be the candidate without the period, and <b> be the period.\n    // Find a log likelihood ratio that indicates whether <ab> occurs as a\n    // single unit (high value of ll), or as two independent units <a> and <b>\n    // (low value of ll)\n    var withPeriodCount = this.typeFdist.get(type + '.'),\n        withoutPeriodCount = this.typeFdist.get(type);\n\n    var ll = dunningLogLikelihood(withPeriodCount + withoutPeriodCount, this.periodTokenCount, withPeriodCount, this.typeFdist.N);\n\n    // Apply three scaling factors to \"tweak\" the basic log-likelihood ratio:\n    //   * fLength: long word => less likely to be an abbreviation\n    //   * fPeriods: more periods => more likely to be an abbreviation\n    //   * fPenalty: penalize occurences without a period\n    var fLength = Math.exp(-nonPeriodsCount),\n        fPeriods = periodsCount,\n        fPenalty = !IGNORE_ABBREV_PENALTY ? Math.pow(nonPeriodsCount, -withoutPeriodCount) : IGNORE_ABBREV_PENALTY;\n\n    var score = ll * fLength * fPeriods * fPenalty;\n\n    return [type, score, isAdd];\n  };\n\n  /**\n   * Method determining whether we stand before a rare abbreviation. A word\n   * type is counted as a rare abbreviation if:\n   *   - it's not already marked as an abbreviation\n   *   - it occurs fewer than ABBREV_BACKOFF times\n   *   - either it is followed by a sentence-internal punctuation mark, OR its\n   *     is followed by a lower-case word that sometimes appears with upper-case\n   *     but never occurs with lower case at the beginning of sentences.\n   *\n   * @param  {PunktToken} currentToken - The token.\n   * @param  {PunktToken} nextToken    - The next token.\n   * @return {boolean}\n   */\n\n\n  PunktTrainer.prototype._isRareAbbreviationType = function _isRareAbbreviationType(currentToken, nextToken) {\n    if (currentToken.abbreviation || !currentToken.sentenceBreak) return false;\n\n    // Find the case-normalized type of the token. If it's a sentence-final\n    // token, strip off the period.\n    var type = currentToken.typeNoSentencePeriod();\n\n    // Proceed only if the type hasn't been categorized as an abbreviation\n    // already, and is sufficiently rare.\n    var count = this.typeFdist.get(type) + this.typeFdist.get(type.slice(0, -1));\n\n    if (this.params.abbreviationTypes.has(type) || count >= ABBREV_BACKOFF) return false;\n\n    // Record this type as an abbreviation if the next token is a\n    // sentence-internal punctuation mark.\n    if (this.vars.internalPunctuation.has(nextToken.string[0])) return true;\n\n    // Record this type as an abbreviation if the next token:\n    //   (i) starts with a lower case letter,\n    //   (ii) sometimes occurs with an uppercase letter,\n    //   (iii) nevers occurs with an uppercase letter sentence-internally\n    else if (nextToken.firstLower()) {\n        var nextType = nextToken.typeNoSentencePeriod(),\n            context = this.params.orthographicContext[nextType];\n\n        if (context & ORTHO_BEG_UC && !(context & ORTHO_MID_UC)) return true;\n      }\n\n    return false;\n  };\n\n  /**---------------------------------------------------------------------------\n   * Collocation finder.\n   **---------------------------------------------------------------------------\n   */\n\n  /**\n   * Method used to determine whether the pair of tokens may form\n   * a collocation given log-likelihood statistics.\n   *\n   * @param  {PunktToken} firstToken  - first The token.\n   * @param  {PunktToken} secondToken - The second token.\n   * @return {boolean}\n   */\n\n\n  PunktTrainer.prototype._isPotentialCollocation = function _isPotentialCollocation(firstToken, secondToken) {\n    return (INCLUDE_ALL_COLLOCS || INCLUDE_ABBREV_COLLOCS && firstToken.abbreviation || firstToken.sentenceBreak && (firstToken.isNumber || firstToken.isInitial)) && firstToken.isNonPunctuation && secondToken.isNonPunctuation;\n  };\n\n  /**\n   * Method used to generate likely collocations and their log-likelihood.\n   *\n   * @return {array} - An array of results.\n   */\n\n\n  PunktTrainer.prototype._findCollocations = function _findCollocations() {\n    var types = this.collocationFdist.values(),\n        results = [];\n\n    for (var i = 0, l = types.length; i < l; i++) {\n      var hash = types[i];\n\n      // NOTE: beware memory reduction here!\n      // TODO: check that it works properly\n\n      var _hash$split = hash.split(SEP),\n          type1 = _hash$split[0],\n          type2 = _hash$split[1];\n\n      if (this.params.sentenceStarters.has(type2)) continue;\n\n      var colCount = this.collocationFdist.get(hash),\n          type1Count = this.typeFdist.get(type1) + this.typeFdist.get(type1 + '.'),\n          type2Count = this.typeFdist.get(type2) + this.typeFdist.get(type2 + '.');\n\n      if (type1Count > 1 && type2Count > 1 && MIN_COLLOC_FREQ < colCount && colCount <= Math.min(type1Count, type2Count)) {\n\n        var ll = colLogLikelihood(type1Count, type2Count, colCount, this.typeFdist.N);\n\n        if (ll >= COLLOCATION && this.typeFdist.N / type1Count > type2Count / colCount) results.push([hash, ll]);\n      }\n    }\n\n    return results;\n  };\n\n  /**---------------------------------------------------------------------------\n   * Sentence starter finder.\n   **---------------------------------------------------------------------------\n   */\n\n  /**\n   * Method returning whether, given a token and the token that precedes it if\n   * it seems clear that the token is beginning a sentence.\n   *\n   * @param  {PunktToken} token         - The token.\n   * @param  {PunktToken} previousToken - The previous token.\n   * @return {boolean}\n   */\n\n\n  PunktTrainer.prototype._isPotentialSentenceStarter = function _isPotentialSentenceStarter(token, previousToken) {\n\n    // If a token (i) is preceded by a sentence break that is not a potential\n    // ordinal number or initial, and (ii) is alphabetic, then it is a\n    // sentence starter.\n    return previousToken.sentenceBreak && !(previousToken.isNumber || previousToken.isInitial) && token.isAlpha;\n  };\n\n  /**\n   * Method using collocation heuristics for each candidate token to determine\n   * if it frequently starts sentences.\n   *\n   * @return {array} - An array of results.\n   */\n\n\n  PunktTrainer.prototype._findSentenceStarters = function _findSentenceStarters() {\n    var types = this.sentenceStarterFdist.values(),\n        results = [];\n\n    for (var i = 0, l = types.length; i < l; i++) {\n      var type = types[i];\n\n      if (!type) continue;\n\n      var typeAtBreakCount = this.sentenceStarterFdist.get(type),\n          typeCount = this.typeFdist.get(type);\n\n      // This is needed after memory reduction methods\n      if (typeCount < typeAtBreakCount) continue;\n\n      var ll = colLogLikelihood(this.sentenceBreakCount, typeCount, typeAtBreakCount, this.typeFdist.N);\n\n      if (ll >= SENT_STARTER && this.typeFdist.N / this.sentenceBreakCount > typeCount / typeAtBreakCount) {\n        results.push([type, ll]);\n      }\n    }\n\n    return results;\n  };\n\n  /**---------------------------------------------------------------------------\n   * Training methods.\n   **---------------------------------------------------------------------------\n   */\n\n  /**\n   * Method used to train a model based on the given text.\n   *\n   * @param  {string}  text     - The training text.\n   * @param  {boolean} finalize - Whether to finalize the training or not.\n   * @return {PunktTrainer}     - Returns itself for chaining purposes.\n   */\n\n\n  PunktTrainer.prototype.train = function train(text) {\n    var finalize = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n\n\n    // First we need to tokenize the words\n    var tokens = this.tokenizeWords(text);\n\n    this.finalized = false;\n\n    // Find the frequency of each case-normalized type.\n    // Also record the number of tokens ending in periods.\n    for (var i = 0, l = tokens.length; i < l; i++) {\n      var token = tokens[i],\n          type = token.type;\n\n      this.typeFdist.add(type);\n\n      if (token.periodFinal) this.periodTokenCount++;\n    }\n\n    // Look for new abbreviations, and for types that no longer are\n    var uniqueTypes = this.typeFdist.values();\n\n    for (var _i = 0, _l = uniqueTypes.length; _i < _l; _i++) {\n      var result = this._reclassifyAbbreviationType(uniqueTypes[_i]);\n\n      if (!result) continue;\n\n      var abbreviation = result[0],\n          score = result[1],\n          isAdd = result[2];\n\n\n      if (score >= ABBREV) {\n        if (isAdd) {\n          this.params.abbreviationTypes.add(abbreviation);\n\n          if (this.verbose) console.log('Added abbreviation: [' + score + '] ' + abbreviation);\n        }\n      } else {\n        if (!isAdd) {\n          this.params.abbreviationTypes.delete(abbreviation);\n\n          if (this.verbose) console.log('Remove abbreviation [' + score + '] ' + abbreviation);\n        }\n      }\n    }\n\n    // Make a preliminary pass through the document, marking likely sentence\n    // breaks, abbreviations, and ellipsis tokens.\n    this._annotateFirstPass(tokens);\n\n    // Check what context each word type can appear in, given the case of its\n    // first letter.\n    this._getOrthographyData(tokens);\n\n    // We need total number of sentence breaks to find sentence starters\n    for (var _i2 = 0, _l2 = tokens.length; _i2 < _l2; _i2++) {\n      if (tokens[_i2].sentenceBreak) this.sentenceBreakCount++;\n    }\n\n    // The remaining heuristics relate to pairs of tokens where the first ends\n    // in a period.\n    for (var _i3 = 0, _l3 = tokens.length; _i3 < _l3; _i3++) {\n      var currentToken = tokens[_i3],\n          nextToken = tokens[_i3 + 1];\n\n      if (!currentToken.periodFinal || !nextToken) continue;\n\n      // If the first token a rare abbreviation?\n      if (this._isRareAbbreviationType(currentToken, nextToken)) {\n        this.params.abbreviationTypes.add(currentToken.typeNoPeriod());\n\n        if (this.verbose) console.log('Rare abbreviation: ' + currentToken.type);\n      }\n\n      // Does the second token have a high likelihood of starting a sentence?\n      if (this._isPotentialSentenceStarter(nextToken, currentToken)) this.sentenceStarterFdist.add(nextToken.type);\n\n      // Is this bigram a potential collocation?\n      if (this._isPotentialCollocation(currentToken, nextToken)) {\n        var hashedBigram = [currentToken.typeNoPeriod(), nextToken.typeNoSentencePeriod()].join(SEP);\n\n        this.collocationFdist.add(hashedBigram);\n      }\n    }\n\n    // Should we finalize?\n    if (finalize) this.finalize();\n\n    return this;\n  };\n\n  /**\n   * Method using the data that has been gathered in training to determine\n   * likely collocations and sentence starters.\n   *\n   * @return {PunktTrainer} - Returns itself for chaining purposes.\n   */\n\n\n  PunktTrainer.prototype.finalize = function finalize() {\n    this.params.sentenceStarters.clear();\n    var sentenceStarters = this._findSentenceStarters();\n\n    for (var i = 0, l = sentenceStarters.length; i < l; i++) {\n      var _sentenceStarters$i = sentenceStarters[i],\n          type = _sentenceStarters$i[0],\n          ll = _sentenceStarters$i[1];\n\n      this.params.sentenceStarters.add(type);\n\n      if (this.verbose) console.log('Sentence starter: [' + ll + '] ' + type);\n    }\n\n    this.params.collocations.clear();\n    var collocations = this._findCollocations();\n\n    for (var _i4 = 0, _l4 = collocations.length; _i4 < _l4; _i4++) {\n      var _collocations$_i = collocations[_i4],\n          hash = _collocations$_i[0],\n          ll = _collocations$_i[1];\n\n\n      this.params.collocations.add(hash);\n\n      if (this.verbose) console.log('Collocation: [' + ll + '] (' + hash.split(SEP).join(', ') + ')');\n    }\n\n    this.finalized = true;\n    return this;\n  };\n\n  /**\n   * Method returning the parameters found by the trainer.\n   *\n   * @return {PunktParameters} - The parameters.\n   */\n\n\n  PunktTrainer.prototype.getParams = function getParams() {\n    if (!this.finalized) this.finalize();\n    return this.params;\n  };\n\n  return PunktTrainer;\n}(PunktBaseClass);\n\n/**\n * Class representing the Punkt sentence tokenizer.\n *\n * @constructor\n * @param {PunktParameters} params - Parameters to use to perform tokenization.\n */\n\n\nvar PunktSentenceTokenizer = exports.PunktSentenceTokenizer = function (_PunktBaseClass2) {\n  _inherits(PunktSentenceTokenizer, _PunktBaseClass2);\n\n  function PunktSentenceTokenizer(params) {\n    _classCallCheck(this, PunktSentenceTokenizer);\n\n    var _this2 = _possibleConstructorReturn(this, _PunktBaseClass2.call(this));\n\n    _this2.params = params;\n    return _this2;\n  }\n\n  /**---------------------------------------------------------------------------\n   * Annotation methods.\n   **---------------------------------------------------------------------------\n   */\n\n  /**\n   * Method used to decide whether the given token is the first token in a\n   * sentence.\n   *\n   * @param  {PunktToken}     token - The considered token.\n   * @return {boolean|string}       - The decision\n   */\n\n\n  PunktSentenceTokenizer.prototype._orthographicHeuristic = function _orthographicHeuristic(token) {\n\n    // Sentences don't start with punctuation marks\n    if (PUNCTUATION.has(token.string)) return false;\n\n    var context = this.params.orthographicContext[token.typeNoSentencePeriod()];\n\n    // If the word is capitalized, occurs at least once with a lower-case first\n    // letter, and never occurs with an upper-case first letter sentence\n    // internally, then it's a sentence starter.\n    if (token.firstUpper() && context & ORTHO_LC && !(context & ORTHO_MID_UC)) {\n      return true;\n    }\n\n    // If the word is lower-case, and either (a) we have seen it used with\n    // upper-case, or (b) we have never seen it used sentence-initially with\n    // lower-case, then it's not a sentence starter.\n    if (token.firstLower() && (context & ORTHO_UC || !(context & ORTHO_BEG_LC))) {\n      return false;\n    }\n\n    // Otherwise, we are not really sure\n    return 'unknown';\n  };\n\n  /**\n   * Method used to perform the second pass of annotation by performing\n   * a token-based classification (section 4) over the given tokens, making\n   * use of the orthographic heuristic (4.1.1), collocation heuristic (4.1.2)\n   * and frequent sentence starter heuristic (4.1.3).\n   *\n   * @param  {array}                  tokens - Tokens to annotate.\n   * @return {PunktSentenceTokenizer}        - Returns itself for chaining.\n   */\n\n\n  PunktSentenceTokenizer.prototype._annotateSecondPass = function _annotateSecondPass(tokens) {\n\n    for (var i = 0, l = tokens.length; i < l; i++) {\n      var currentToken = tokens[i],\n          nextToken = tokens[i + 1];\n\n      // Is it the last token? We can't do anything then.\n      if (!nextToken) return;\n\n      // We only care about words ending in periods.\n      if (!currentToken.periodFinal) continue;\n\n      var currentType = currentToken.typeNoPeriod(),\n          nextType = nextToken.typeNoSentencePeriod(),\n          tokenIsInitial = currentToken.isInitial;\n\n      // [4.1.2. Collocation Heuristic]: If there is a collocation between\n      // the word before and after the period, then label the token as an\n      // abbreviation and NOT a sentence break. Note that collocations with\n      // frequent sentence starters as their second word are excluded in\n      // training.\n      var hash = [currentType, nextType].join(SEP);\n      if (this.params.collocations.has(hash)) {\n        currentToken.sentenceBreak = false;\n        currentToken.abbreviation = true;\n        continue;\n      }\n\n      // [4.2. Token-Based Reclassification of Abbreviation]: If the token\n      // is an abbreviation or an ellipsis, then decide whether we should\n      // also classify it as a sentence break.\n      if ((currentToken.abbreviation || currentToken.ellipsis) && !tokenIsInitial) {\n\n        // [4.1.1. Orthographic Heuristic]: Check if there is orthographic\n        // evidence about whether the next word starts a sentence or not.\n        var isSentenceStarter = this._orthographicHeuristic(nextToken);\n\n        if (isSentenceStarter === true) {\n          currentToken.sentenceBreak = true;\n          continue;\n        }\n\n        // [4.1.3. Frequent Sentence Starter Heuristic]: If the next word\n        // is capitalized, and is a member of the frequent-sentence-starters\n        // list, then label token a sentence break.\n        if (nextToken.firstUpper() && this.params.sentenceStarters.has(nextType)) {\n          currentToken.sentenceBreak = true;\n          continue;\n        }\n      }\n\n      // [4.3. Token-Based Detection of Initials and Ordinals]: Check if any\n      // initials or ordinals tokens are marked as sentence breaks should be\n      // reclassified as abbreviations.\n      if (tokenIsInitial || currentType === '##number##') {\n\n        // [4.1.1. Orthographic Heuristic]: Check if there is orthographic\n        // evidence about whether the next word starts a sentence or not.\n        var _isSentenceStarter = this._orthographicHeuristic(nextToken);\n\n        if (_isSentenceStarter === false) {\n          currentToken.sentenceBreak = false;\n          currentToken.abbreviation = true;\n          continue;\n        }\n\n        // Special heuristic for initials: if orthographic heuristic is\n        // unknown, and next word is always capitalized, then mark as\n        // abbreviation (\"J. Bach\", for instance).\n        if (_isSentenceStarter === 'unknown' && tokenIsInitial && nextToken.firstUpper() && !(this.params.orthographicContext[nextType] & ORTHO_LC)) {\n          currentToken.sentenceBreak = false;\n          currentToken.abbreviation = true;\n        }\n      }\n    }\n  };\n\n  /**\n   * Given a set of tokens augmented with markers for line-start and\n   * paragraph-start, returns those tokens with full annotation including\n   * predicted sentence breaks.\n   *\n   * @param  {array}                  tokens - Tokens to annotate.\n   * @return {PunktSentenceTokenizer}        - Returns itself for chaining.\n   */\n\n\n  PunktSentenceTokenizer.prototype._annotateTokens = function _annotateTokens(tokens) {\n\n    // Make a preliminary pass through the document, marking likely sentence\n    // breaks, abbreviations, and ellipsis tokens.\n    this._annotateFirstPass(tokens);\n\n    // Make a second pass through the document, using token context info\n    // to change our preliminary decisions about where sentence breaks,\n    // abbreviations, and ellipsis occurs.\n    this._annotateSecondPass(tokens);\n\n    return this;\n  };\n\n  /**---------------------------------------------------------------------------\n   * Tokenization methods.\n   **---------------------------------------------------------------------------\n   */\n\n  /**\n   * Method returning whether the given text includes a sentence break.\n   *\n   * @param  {string}  text - Text to analyze.\n   * @return {boolean}\n   */\n\n\n  PunktSentenceTokenizer.prototype._textContainsSentenceBreak = function _textContainsSentenceBreak(text) {\n    var tokens = this.tokenizeWords(text);\n\n    // Let's annotate the tokens\n    this._annotateTokens(tokens);\n\n    // Ignoring last token (l - 1)\n    for (var i = 0, l = tokens.length - 1; i < l; i++) {\n      if (tokens[i].sentenceBreak) return true;\n    }\n\n    return false;\n  };\n\n  /**\n   * Method used to slice the given text according to the language variables.\n   *\n   * @param  {string} text - Text to slice.\n   * @return {array}       - The slices.\n   */\n\n\n  PunktSentenceTokenizer.prototype._slicesFromText = function _slicesFromText(text) {\n    var slices = [],\n        matches = (0, _helpers.findall)(this.vars.rePeriodContext, text);\n\n    var lastBreak = 0;\n\n    for (var i = 0, l = matches.length; i < l; i++) {\n      var match = matches[i],\n          afterToken = match[1],\n          nextToken = match[2],\n          context = match[0] + afterToken;\n\n      if (this._textContainsSentenceBreak(context)) {\n        slices.push([lastBreak, match.index + match[0].length]);\n\n        if (nextToken) {\n\n          // Next sentence starts after whitespace\n          lastBreak = match.index + match[0].length + 1;\n        } else {\n\n          // Next sentence starts at the following punctuation\n          lastBreak = match.index + match[0].length;\n        }\n      }\n    }\n\n    // Last slice\n    slices.push([lastBreak, text.length]);\n\n    return slices;\n  };\n\n  /**\n   * Method used to attempt to realign punctuation that falls after the period\n   * but should otherwise be included in the same sentence.\n   *\n   * Example: \"(Sent1.) Sent2.\" will otherwise be split as:\n   * [\"(Sent1.\", \") Sent2.\"] instead of [\"(Sent1.)\", \"Sent2.\"].\n   *\n   * @param  {string} text   - Text to realign.\n   * @param  {array}  slices - Slices of text.\n   * @return {array}         - Realigned pieces.\n   */\n\n\n  PunktSentenceTokenizer.prototype._realignBoundaries = function _realignBoundaries(text, slices) {\n    var realigned = [];\n\n    var realign = 0;\n\n    for (var i = 0, l = slices.length; i < l; i++) {\n      var slice1 = slices[i],\n          slice2 = slices[i + 1];\n\n      var realignedSlice = [slice1[0] + realign, slice1[1]];\n\n      if (!slice2) {\n        if (text.substring.apply(text, realignedSlice)) realigned.push(realignedSlice);\n        continue;\n      }\n\n      var match = text.substring.apply(text, _toConsumableArray(slice2)).match(this.vars.reBoundaryRealignment);\n\n      if (match) {\n        realigned.push([realignedSlice[0], slice2[0] + match[0].replace(/\\s*$/g, '').length]);\n        realign = match.index + match[0].length;\n      } else {\n        realign = 0;\n        if (text.substring.apply(text, realignedSlice)) realigned.push(realignedSlice);\n      }\n    }\n\n    return realigned;\n  };\n\n  /**\n   * Method returning a list of the spans of sentences in the text.\n   *\n   * @param  {string}  text               - Text to tokenize into sentences.\n   * @param  {boolean} realignBoundaries  - Should the tokenizer realign\n   *                                        boundaries?\n   * @return {array}                      - The array of sentences.\n   */\n\n\n  PunktSentenceTokenizer.prototype.spanTokenize = function spanTokenize(text) {\n    var realignBoundaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n\n    var slices = this._slicesFromText(text);\n\n    if (realignBoundaries) slices = this._realignBoundaries(text, slices);\n\n    return slices;\n  };\n\n  /**\n   * Method used to tokenize the given text.\n   *\n   * @param  {string}  text               - Text to tokenize into sentences.\n   * @param  {boolean} realignBoundaries  - Should the tokenizer realign\n   *                                        boundaries?\n   * @return {array}                      - The array of sentences.\n   */\n\n\n  PunktSentenceTokenizer.prototype.tokenize = function tokenize(text) {\n    var realignBoundaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n\n    var spans = this.spanTokenize(text, realignBoundaries),\n        sentences = [];\n\n    for (var i = 0, l = spans.length; i < l; i++) {\n      sentences.push(text.substring.apply(text, _toConsumableArray(spans[i])));\n    }return sentences;\n  };\n\n  return PunktSentenceTokenizer;\n}(PunktBaseClass);","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/syllables/legalipy.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.LegalipyTokenizer = undefined;\nexports.default = defaultTokenizer;\n\nvar _frequencies = require('../../stats/frequencies');\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } } /**\n                                                                                                                                                           * Talisman tokenizers/syllables/legalipy\n                                                                                                                                                           * =======================================\n                                                                                                                                                           *\n                                                                                                                                                           * Language-independent syllabification from raw text based on the Onset\n                                                                                                                                                           * Maximization Principle (principle of legality).\n                                                                                                                                                           *\n                                                                                                                                                           * [Reference]:\n                                                                                                                                                           * https://github.com/henchc/LegaliPy\n                                                                                                                                                           * http://syllabipy.com/index.php/legalipy-demo/\n                                                                                                                                                           *\n                                                                                                                                                           * [Author]:\n                                                                                                                                                           * Christopher Hench (UC Berkeley)\n                                                                                                                                                           */\n\n\n/**\n * Constants.\n */\nvar VOWELS_STRING = 'aeiouyàáâäæãåāèéêëēėęîïíīįìôöòóœøōõûüùúūůÿ',\n    VOWELS_RE = new RegExp('[' + VOWELS_STRING + ']', 'g'),\n    VOWELS = new Set(VOWELS_STRING),\n    PUNCTUATION_RE = /[\\u2000-\\u206F\\u2E00-\\u2E7F\\\\'!\"#$%&()*+,\\-.\\/:;<=>?@\\[\\]^_`{|}~]/g,\n    THRESHOLD = 0.0002;\n\n/**\n * Helpers.\n */\n\n/**\n * Function used to clean the word and prepare it for the trainer.\n *\n * @param  {string} word - The target word.\n * @return {string}      - The cleaned word.\n */\nfunction clean(word) {\n  return word.toLowerCase().replace(PUNCTUATION_RE, '').replace(/\\d/g, '');\n}\n\n/**\n * Class representing the Legalipy tokenizer. Must be trained before use by\n * providing text tokens in which we will search for relevant onsets.\n *\n * @constructor\n * @param {object} options - Possible options.\n */\n\nvar LegalipyTokenizer = exports.LegalipyTokenizer = function () {\n  function LegalipyTokenizer() {\n    _classCallCheck(this, LegalipyTokenizer);\n\n    // Properties\n    this.frequencies = {};\n    this.onsets = new Set();\n    this.finalized = false;\n  }\n\n  /**\n   * Method used to train the onsets.\n   *\n   * @param  {array}             tokens - Word tokens.\n   * @return {LegalipyTokenizer}        - Returns itself for chaining.\n   *\n   * @throws {Error} - Will throw if the tokenizer has finalized its training.\n   */\n\n\n  LegalipyTokenizer.prototype.train = function train(tokens) {\n\n    if (this.finalized) throw new Error('talisman/tokenizers/syllables/legalipy.train: the tokenizer has already finalized its training.');\n\n    var onsets = [];\n\n    // Iterating through the tokens\n    for (var i = 0, l = tokens.length; i < l; i++) {\n      var token = clean(tokens[i]);\n\n      if (token) {\n        var onset = '';\n\n        for (var j = 0, m = token.length; j < m; j++) {\n          var letter = token[j];\n\n          if (!VOWELS.has(letter)) onset += letter;else break;\n        }\n\n        if (onset) onsets.push(onset);\n      }\n    }\n\n    // Updating frequencies\n    this.frequencies = (0, _frequencies.updateFrequencies)(this.frequencies, onsets);\n\n    return this;\n  };\n\n  /**\n   * Method used to finalize the training.\n   *\n   * @return {LegalipyTokenizer} - Returns itself for chaining.\n   */\n\n\n  LegalipyTokenizer.prototype.finalize = function finalize() {\n    var _this = this;\n\n    this.finalized = true;\n\n    // Computing relative frequencies of the onsets\n    this.frequencies = (0, _frequencies.relative)(this.frequencies);\n\n    // Keeping onsets whose frequency is superior to threshold\n    for (var k in this.frequencies) {\n      if (this.frequencies[k] > THRESHOLD) this.onsets.add(k);\n    }\n\n    // Adding shorter subsets of onsets longer than 2 characters\n    this.onsets.forEach(function (onset) {\n      if (onset.length > 2) _this.onsets.add(onset.slice(-2));\n      if (onset.length > 3) _this.onsets.add(onset.slice(-3));\n    });\n\n    // Releasing frequencies from memory\n    this.frequencies = null;\n\n    return this;\n  };\n\n  /**\n   * Method used to tokenize words into syllables once trained.\n   *\n   * @param  {string} word - Target word.\n   * @return {array}       - An array of syllables.\n   *\n   * @throws {Error} - Will throw if the tokenizer hasn't finalized its training.\n   */\n\n\n  LegalipyTokenizer.prototype.tokenize = function tokenize(word) {\n    if (!this.finalized) throw new Error('talisman/tokenizers/syllables/legalipy.train: you should finalize the tokenizer\\'s training before being able to tokenize.');\n\n    var vowelCount = (word.match(VOWELS_RE) || []).length;\n\n    var syllables = [];\n\n    if (vowelCount <= 1) {\n      syllables.push(word);\n    } else {\n      var currentSyllable = '',\n          onsetBinary = false,\n          newSyllableBinary = true;\n\n      // Iterating on the letters in reverse\n      for (var i = word.length - 1; i >= 0; i--) {\n        var originalLetter = word[i],\n            letter = originalLetter.toLowerCase();\n\n        var syllable = currentSyllable.toLowerCase();\n\n        if (newSyllableBinary) {\n\n          currentSyllable = originalLetter + syllable;\n\n          if (VOWELS.has(letter)) {\n            newSyllableBinary = false;\n            continue;\n          }\n        } else if (!newSyllableBinary) {\n\n          if (!syllable) {\n            currentSyllable = originalLetter + syllable;\n          } else if (this.onsets.has(letter) && VOWELS.has(syllable[0]) || this.onsets.has(letter + syllable[0]) && VOWELS.has(syllable[1]) || this.onsets.has(letter + syllable.slice(0, 2)) && VOWELS.has(syllable[2]) || this.onsets.has(letter + syllable.slice(0, 3)) && VOWELS.has(syllable[3])) {\n            currentSyllable = originalLetter + syllable;\n            onsetBinary = true;\n          } else if (VOWELS.has(letter) && !onsetBinary) {\n            currentSyllable = originalLetter + syllable;\n          } else if (VOWELS.has(letter) && onsetBinary) {\n            syllables.unshift(syllable);\n            currentSyllable = originalLetter;\n          } else {\n            syllables.unshift(syllable);\n            currentSyllable = originalLetter;\n            newSyllableBinary = true;\n          }\n        }\n      }\n\n      syllables.unshift(currentSyllable);\n    }\n\n    return syllables;\n  };\n\n  /**\n   * Method used to export the tokenizer's onsets.\n   *\n   * @return {object} - An object containing the necessary metadata.\n   */\n\n\n  LegalipyTokenizer.prototype.export = function _export() {\n    return {\n      onsets: Array.from(this.onsets)\n    };\n  };\n\n  /**\n   * Method used to force JSON.stringify to format the tokenizer using the\n   * #.export method.\n   */\n\n\n  LegalipyTokenizer.prototype.toJSON = function toJSON() {\n    return this.export();\n  };\n\n  /**\n   * Method used to import an existing model instead of having to train the\n   * tokenizer.\n   *\n   * @param  {object}            model - The model to import.\n   * @return {LegalipyTokenizer}       - Returns itself for chaining.\n   */\n\n\n  LegalipyTokenizer.prototype.import = function _import(model) {\n    this.finalize();\n    this.onsets = new Set(model.onsets);\n  };\n\n  return LegalipyTokenizer;\n}();\n\n/**\n * Function that can be used to tokenize a series of word tokens on the fly.\n *\n * @param  {array} tokens - Word tokens.\n * @return {array}        - A list of word tokenized as syllables.\n */\n\n\nfunction defaultTokenizer(tokens) {\n  var tokenizer = new LegalipyTokenizer();\n  tokenizer.train(tokens);\n  tokenizer.finalize();\n\n  var newTokens = new Array(tokens.length);\n\n  for (var i = 0, l = tokens.length; i < l; i++) {\n    newTokens[i] = tokenizer.tokenize(tokens[i]);\n  }return newTokens;\n}\nmodule.exports = exports['default'];\nexports['default'].LegalipyTokenizer = exports.LegalipyTokenizer;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/syllables/sonoripy.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: false\n});\nexports.merge = merge;\nexports.createTokenizer = createTokenizer;\n/* eslint brace-style: 0 */\n/**\n * Talisman tokenizers/syllables/sonoripy\n * =======================================\n *\n * Language-independent syllabification algorithm following the sonority\n * sequencing principle. As opposed to LegaliPy, this algorithm doesn't need\n * to be trained on word tokens but must be provided with the target\n * language's sonority hierarchy.\n *\n * [Reference]:\n * https://github.com/henchc/SonoriPy\n *\n * [Authors]:\n * Christopher Hench (UC Berkeley)\n * Alex Estes\n */\n\n/**\n * Constants.\n */\nvar DEFAULT_HIERARCHY = ['aeiouy', // Vowels      3pts\n'lmnrw', // Nasals      2pts\n'zvsf', // Fricatives  1pts\n'bcdgtkpqxhj' // Stops       0pts\n];\n\n/**\n * Helpers.\n */\n\n/**\n * Function dropping some useless leading & trailing characters in the given\n * string.\n *\n * @param  {string} string - Target string.\n * @return {string}        - The stripped string.\n */\nfunction strip(string) {\n  return string.replace(/(?:^[.:;?!()'\"]+)|(?:[.:;?!()'\"]+$)/g, '');\n}\n\n/**\n * Function used to retokenize syllables tokens by avoiding parts that would\n * not have vowels at all by merging them with the precedent token.\n *\n * @param  {RegExp} vowelsRegex - The regex used to test the presence of\n *                                vowels in the syllables.\n * @param  {array}  syllables   - The tokens.\n * @return {array}              - The merged tokens.\n */\nfunction merge(vowelsRegex, syllables) {\n  var safeSyllables = [],\n      front = '';\n\n  for (var i = 0, l = syllables.length; i < l; i++) {\n    var syllable = syllables[i];\n\n    if (!vowelsRegex.test(syllable)) {\n      if (!safeSyllables.length) front += syllable;else safeSyllables = safeSyllables.slice(0, -1).concat(safeSyllables.slice(-1) + syllable);\n    } else {\n      if (!safeSyllables.length) safeSyllables.push(front + syllable);else safeSyllables.push(syllable);\n    }\n  }\n\n  return safeSyllables;\n}\n\n/**\n * Tokenizer function factory aiming at building the required function.\n *\n * @param  {object}   options              - Possible options:\n * @param  {array}    [options.hierarchy]  - Target language's hierarchy.\n * @return {function}                      - The tokenizer function.\n */\nfunction createTokenizer(options) {\n  options = options || {};\n\n  var hierarchy = options.hierarchy;\n\n  if (!hierarchy) throw new Error('talisman/tokenizers/syllables/sonoripy: a hierachy must be provided.');\n\n  var vowels = hierarchy[0],\n      vowelsSet = new Set(vowels);\n\n  // Creating the map of values\n  var map = {};\n\n  hierarchy.forEach(function (level, i) {\n    var letters = level.split(''),\n        value = hierarchy.length - i - 1;\n\n    letters.forEach(function (letter) {\n      return map[letter] = value;\n    });\n  });\n\n  // Creating a vowel regex\n  var vowelsRegex = new RegExp('[' + vowels + ']');\n\n  /**\n   * Created tokenizer function.\n   *\n   * @param  {string} word - The word to tokenize.\n   * @return {array}       - The syllables as tokens.\n   */\n  return function (word) {\n\n    // Normalizing the word\n    var normalizedWord = strip(word);\n\n    //-- 1) Tagging letters & counting vowels\n    var vowelCount = 0;\n    var taggedLetters = [];\n\n    for (var i = 0, l = normalizedWord.length; i < l; i++) {\n      var letter = normalizedWord[i],\n          lowerLetter = letter.toLowerCase();\n\n      if (vowelsSet.has(lowerLetter)) vowelCount++;\n\n      taggedLetters.push([letter, map[letter] || 0]);\n    }\n\n    //-- 2) Dividing the syllables\n    var syllables = [];\n\n    // If the word is monosyllabic, we can stop right there\n    if (vowelCount <= 1) return [word];\n\n    var syllable = taggedLetters[0][0];\n\n    for (var _i = 1, _l = taggedLetters.length; _i < _l; _i++) {\n      var _taggedLetters$_i = taggedLetters[_i],\n          _letter = _taggedLetters$_i[0],\n          value = _taggedLetters$_i[1],\n          valueBefore = (taggedLetters[_i - 1] || [])[1],\n          valueAfter = (taggedLetters[_i + 1] || [])[1];\n\n      // If we reached the end of the word\n\n      if (_i === _l - 1) {\n        syllable += _letter;\n        syllables.push(syllable);\n      }\n\n      // Cases triggering syllable break\n      else if (value === valueAfter && value === valueBefore || value === valueAfter && value < valueBefore) {\n          syllable += _letter;\n          syllables.push(syllable);\n          syllable = '';\n        } else if (value < valueAfter && value < valueBefore) {\n          syllables.push(syllable);\n          syllable = _letter;\n        }\n\n        // Cases that do not trigger syllable break\n        // (I dropped the condition & placed it as else because it hurts\n        // performance otherwise)\n        else /* if (\n             (value < valueAfter && value > valueBefore) ||\n             (value > valueAfter && value < valueBefore) ||\n             (value > valueAfter && value > valueBefore) ||\n             (value > valueAfter && value === valueBefore) ||\n             (value === valueAfter && value > valueBefore) ||\n             (value < valueAfter && value === valueBefore)\n             ) */{\n            syllable += _letter;\n          }\n    }\n\n    //-- 3) Ensuring we don't have a syllable without vowel\n    var safeSyllables = merge(vowelsRegex, syllables);\n\n    return safeSyllables;\n  };\n}\n\n/**\n * Exporting a default version of the tokenizer.\n */\nvar defaultTokenizer = createTokenizer({ hierarchy: DEFAULT_HIERARCHY });\nexports.default = defaultTokenizer;\nmodule.exports = exports['default'];\nexports['default'].merge = exports.merge;\nexports['default'].createTokenizer = exports.createTokenizer;","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/tweets/casual.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nexports.default = function (tweet) {\n\n  // Fixing HTML entities\n  tweet = ENTITIES.decode(tweet);\n\n  // Shorten problematic sequences of characters\n  var safeText = tweet.replace(HANG_RE, '$1$1$1');\n\n  // Actual tokenizing\n  var matches = (0, _helpers.findall)(WORD_RE, safeText);\n\n  var tokens = new Array(matches.length);\n\n  for (var i = 0, l = matches.length; i < l; i++) {\n    tokens[i] = matches[i][0];\n  }return tokens;\n};\n\nvar _helpers = require('../../helpers');\n\nvar _htmlEntities = require('html-entities');\n\n/**\n * Talisman tokenizers/tweets/casual\n * ==================================\n *\n * Implementation of the Casual tweets tokenizer from the nltk project.\n *\n * [Reference]:\n * http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.casual\n *\n * [Authors]:\n * Christopher Potts\n * Ewan Klein\n * Pierpaolo Pantone\n */\nvar ENTITIES = new _htmlEntities.AllHtmlEntities();\n\n/**\n * Regexes.\n */\nvar EMOTICONS = ['(?:', '[<>]?', '[:;=8]', '[\\\\-o*\\']?', '[)\\\\](\\\\[dDpP/:}{@|\\]', '|', '[)\\\\](\\\\[dDpP/:}{@|\\]', '[\\\\-o*\\']?', '[:;=8]', '[<>]?', '|', '<3', ')'].join('');\n\n// URL pattern due to John Gruber, modified by Tom Winzig. See\n// https://gist.github.com/winzig/8894715\nvar URLS = ['(?:', 'https?:', '(?:', '\\\\/{1,3}', '|', '[a-z0-9%]', ')', '|', '[a-z0-9.\\\\-]+[.]', '(?:[a-z]{2,13})', '\\\\/', ')', '(?:', '[^\\\\s()<>{}\\\\[\\\\]]+', '|', '\\\\([^\\\\s()]*?\\\\([^\\\\s()]+\\\\)[^\\\\s()]*?\\\\)', '|', '\\\\([^\\\\s]+?\\\\)', ')+', '(?:', '\\\\([^\\\\s()]*?\\\\([^\\\\s()]+\\\\)[^\\\\s()]*?\\\\)', '|', '\\\\([^\\\\s]+?\\\\)', '|', '[^\\\\s`!()\\\\[\\\\]{};:\\'\".,<>?«»“”‘’]', ')', '|', '(?:',\n// NOTE: Lookbehind doesn't work in JavaScript. Skipping this for now.\n// '(?<!@)',\n'[a-z0-9]+', '(?:[.\\\\-][a-z0-9]+)*', '[.]', '(?:[a-z]{2,13})', '\\\\b', '\\\\/?', '(?!@)', ')'].join('');\n\nvar REGEXPS = [URLS,\n\n// Phone numbers\n['(?:', '(?:', '\\\\+?[01]', '[\\\\-\\\\s.]*', ')?', '(?:', '[\\\\(]?', '\\\\d{3}', '[\\\\-\\\\s.)]*', ')?', '\\\\d{3}', '[\\\\-\\\\s.]*', '\\\\d{4}', ')'].join(''), EMOTICONS,\n\n// HTML Tags\n'<[^>\\\\s]+>',\n\n// ASCII Arrows\n'[\\\\-]+>|<[\\\\-]+',\n\n// Twitter Usernames\n'(?:@[\\\\w_]+)',\n\n// Twitter hashtags\n'(?:\\\\#+[\\\\w_]+[\\\\w\\'_\\\\-]*[\\\\w_]+)',\n\n// Email addresses\n'[\\\\w.+-]+@[\\\\w-]+\\\\.(?:[\\\\w-]\\\\.?)+[\\\\w-]',\n\n// Remaining word types\n['(?:[^\\\\W\\\\d_](?:[^\\\\W\\\\d_]|[\\'\\\\-_])+[^\\\\W\\\\d_])', '|', '(?:[+\\\\-]?\\d+[,/.:-]\\\\d+[+\\\\-]?)', '|', '(?:[\\\\w_]+)', '|', '(?:\\\\.(?:\\\\s*\\\\.){1,})', '|', '(?:\\\\S)'].join('')];\n\n// NOTE: build unicode support\n\nvar WORD_RE = new RegExp('(' + REGEXPS.join('|') + ')', 'ig'),\n    HANG_RE = /([^a-zA-Z0-9])\\1{3,}/g;\n\n/**\n * Function a single tweet into a sequence of tokens.\n *\n * @param  {string} tweet - The tweet to tokenize.\n * @return {array}        - The tokens.\n */\nmodule.exports = exports['default'];","/home/travis/build/npmtest/node-npmtest-talisman/node_modules/talisman/tokenizers/words/treebank.js":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = tokenize;\n/**\n * Talisman tokenizers/words/treebank\n * ===================================\n *\n * Implementation of the Treebank word tokenizer.\n *\n * [Original script]:\n * http://www.cis.upenn.edu/~treebank/tokenizer.sed\n */\n\n/**\n * Contractions.\n */\nvar CONTRACTIONS2 = [/\\b(can)(not)\\b/gi, /\\b(d)('ye)\\b/gi, /\\b(gim)(me)\\b/gi, /\\b(gon)(na)\\b/gi, /\\b(got)(ta)\\b/gi, /\\b(lem)(me)\\b/gi, /\\b(mor)('n)\\b/gi, /\\b(wan)(na) \"/gi];\n\nvar CONTRACTIONS3 = [/ ('t)(is)\\b/gi, / ('t)(was)\\b/gi];\n\nvar CONTRACTIONS4 = [/\\b(whad)(dd)(ya)\\b/gi, /\\b(wha)(t)(cha)\\b/gi];\n\nfunction applyContractions(contractions, replacement, text) {\n  for (var i = 0, l = contractions.length; i < l; i++) {\n    text = text.replace(contractions[i], replacement);\n  }return text;\n}\n\n/**\n * Rules.\n */\nvar STARTING_QUOTES = [[/^\"/g, '``'], [/(``)/g, ' $1 '], [/([ (\\[{<])\"/g, '$1 `` ']];\n\nvar PONCTUATION = [[/([:,])([^\\d])/g, ' $1 $2'], [/([:,]$)/g, ' $1 '], [/\\.\\.\\./g, ' ... '], [/([;@#$%&])/g, ' $1 '], [/([^\\.])(\\.)([\\]\\)}>\"']*)\\s*$/g, '$1 $2$3 '], [/([?!])/g, ' $1 '], [/([^'])' /g, '$1 \\' ']];\n\nvar PARENS_BRACKETS = [[/([\\]\\[\\(\\)\\{\\}\\<\\>])/g, ' $1 '], [/--/g, ' -- ']];\n\nvar ENDING_QUOTES = [[/\"/g, ' \\'\\' '], [/(\\S)('')/g, '$1 $2 '], [/([^' ])('[sS]|'[mM]|'[dD]|') /g, '$1 $2 '], [/([^' ])('ll|'LL|'re|'RE|'ve|'VE|n't|N'T) /g, '$1 $2 ']];\n\nfunction applyRules(rules, text) {\n  for (var i = 0, l = rules.length; i < l; i++) {\n    text = text.replace(rules[i][0], rules[i][1]);\n  }return text;\n}\n\n/**\n * Function tokenizing raw sentences into words.\n *\n * @param  {string} text       - The text to tokenize.\n * @return {array}             - The tokens.\n */\nfunction tokenize(text) {\n\n  //-- 1) Applying rules\n  text = applyRules(STARTING_QUOTES, text);\n  text = applyRules(PONCTUATION, text);\n  text = applyRules(PARENS_BRACKETS, text);\n\n  text = ' ' + text + ' ';\n\n  text = applyRules(ENDING_QUOTES, text);\n\n  //-- 2) Applying contractions\n  text = applyContractions(CONTRACTIONS2, ' $1 $2 ', text);\n  text = applyContractions(CONTRACTIONS3, ' $1 $2 ', text);\n  text = applyContractions(CONTRACTIONS4, ' $1 $2 $3 ', text);\n\n  var tokens = text.split(/\\s+/).map(function (token) {\n    return token.trim();\n  }).filter(function (token) {\n    return token;\n  });\n\n  return tokens;\n}\nmodule.exports = exports['default'];"}